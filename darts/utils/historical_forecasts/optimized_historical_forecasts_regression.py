"""
Optimized Historical Forecasts for SKLearnModel
-----------------------------------------------
"""

from collections.abc import Sequence
from typing import Any, Literal, Optional, Union

import numpy as np
import pandas as pd
from numpy.lib.stride_tricks import sliding_window_view

from darts import TimeSeries
from darts.logging import get_logger
from darts.utils import _build_tqdm_iterator
from darts.utils.data.tabularization import create_lagged_prediction_data
from darts.utils.historical_forecasts.utils import _get_historical_forecast_boundaries
from darts.utils.ts_utils import get_single_series
from darts.utils.utils import generate_index

logger = get_logger(__name__)


def _optimized_historical_forecasts_regression(
    model,
    series: Sequence[TimeSeries],
    past_covariates: Optional[Sequence[TimeSeries]] = None,
    future_covariates: Optional[Sequence[TimeSeries]] = None,
    num_samples: int = 1,
    start: Optional[Union[pd.Timestamp, float, int]] = None,
    start_format: Literal["position", "value"] = "value",
    forecast_horizon: int = 1,
    stride: int = 1,
    overlap_end: bool = False,
    show_warnings: bool = True,
    verbose: bool = False,
    predict_likelihood_parameters: bool = False,
    random_state: Optional[int] = None,
    predict_kwargs: Optional[dict[str, Any]] = None,
    last_points_only: bool = False,
) -> Union[TimeSeries, Sequence[TimeSeries], Sequence[Sequence[TimeSeries]]]:
    """
    Optimized historical forecasts for SKLearnModel.

    Rely on _check_optimizable_historical_forecasts() to check that the assumptions are verified.

    The data_transformers are applied in historical_forecasts (input and predictions)
    """
    multi_models = model.multi_models
    output_chunk_length = model.output_chunk_length
    output_chunk_shift = model.output_chunk_shift

    # get target lags and X positions for auto-regression
    if model._get_lags("target") is not None:
        if "target" in model.component_lags:
            target_lags = model.component_lags["target"].values()
        else:
            target_lags = [model.lags["target"]] * get_single_series(
                series
            ).n_components

        # map which target component lag belongs to which position in X
        counter = 0
        target_lag_positions = [[] for _ in range(len(target_lags))]
        for lag in range(min(model.lags["target"]), max(model.lags["target"]) + 1):
            for comp_idx, comp_lags in enumerate(target_lags):
                if lag in comp_lags:
                    target_lag_positions[comp_idx].append(counter)
                    counter += 1
    else:
        target_lags, target_lag_positions = [], []

    # get the output lags
    if multi_models:
        lags_output = np.array([i for i in range(output_chunk_length)])
    else:
        lags_output = np.array([output_chunk_length - 1])
    lags_output += output_chunk_shift

    # determine the forecast scenario
    is_auto_regression = forecast_horizon > output_chunk_length + output_chunk_shift

    # TODO: check the multivariate case that failed for Electr.DS
    # for auto-regression: final forecast is generated from multiple forecast iteration; `roll_size` gives the number of
    # time steps between two consecutive autoregressive forecast iterations
    if multi_models and (
        not is_auto_regression or forecast_horizon % output_chunk_length == 0
    ):
        # - for multi_models=True without auto-regression, or with "simple" autoregressive forecasts: the final forecast
        #   can be generated by only looking at iterations output_chunk_length steps apart from each other
        roll_size = output_chunk_length
    else:
        # - for multi-models=False: each output step is predicted in a dedicated forecast
        # - for multi-models=True with "complex" autoregressive forecasts:
        #   - predict output_chunk_length steps in each iteration
        #   - move ahead `roll_size=1` for the next iteration, so that the last output chunk ends at `forecast_horizon`
        roll_size = 1

    predict_kwargs = predict_kwargs or {}
    forecasts_list = []
    iterator = _build_tqdm_iterator(
        series, verbose, total=len(series), desc="historical forecasts"
    )
    for idx, series_ in enumerate(iterator):
        past_covariates_ = past_covariates[idx] if past_covariates is not None else None
        future_covariates_ = (
            future_covariates[idx] if future_covariates is not None else None
        )
        freq = series_.freq
        forecast_components = (
            model.likelihood.component_names(series=series_)
            if predict_likelihood_parameters
            else series_.columns
        )

        # obtain forecastable indexes boundaries, adjust target & covariates boundaries accordingly
        (
            hist_fct_start,
            hist_fct_end,
            hist_fct_tgt_start,
            hist_fct_tgt_end,
            hist_fct_pc_start,
            hist_fct_pc_end,
            hist_fct_fc_start,
            hist_fct_fc_end,
        ) = _get_historical_forecast_boundaries(
            model=model,
            series=series_,
            series_idx=idx,
            past_covariates=past_covariates_,
            future_covariates=future_covariates_,
            start=start,
            start_format=start_format,
            forecast_horizon=forecast_horizon,
            overlap_end=overlap_end,
            stride=stride,
            freq=freq,
            show_warnings=show_warnings,
        )

        # extract lagged features:
        # - without auto-regression: all steps can be predicted in a single forecast iteration `n_forecast_iters = 1`
        # - with auto-regression: requires multiple forecast iterations `n_forecast_iters > 1`
        #   - `roll_size` gives the number of steps between to consecutive forecast iterations
        # X shape: (n_forecasts, n_lagged_features, n_samples = 1, n_prediction_iterations)
        X, _ = create_lagged_prediction_data(
            output_chunk_length=output_chunk_length,
            output_chunk_shift=output_chunk_shift,
            target_series=(
                None
                if (not target_lags) and (not model.uses_static_covariates)
                else series_[hist_fct_tgt_start:hist_fct_tgt_end]
            ),
            past_covariates=(
                None
                if past_covariates_ is None
                else past_covariates_[hist_fct_pc_start:hist_fct_pc_end]
            ),
            future_covariates=(
                None
                if future_covariates_ is None
                else future_covariates_[hist_fct_fc_start:hist_fct_fc_end]
            ),
            lags=model._get_lags("target"),
            lags_past_covariates=model._get_lags("past"),
            lags_future_covariates=model._get_lags("future"),
            uses_static_covariates=model.uses_static_covariates,
            last_static_covariates_shape=model._static_covariates_shape,
            max_samples_per_ts=None,
            check_inputs=True,
            use_moving_windows=True,
            concatenate=False,
            show_warnings=False,
            multi_models=multi_models,
            forecast_horizon=forecast_horizon,
            roll_size=roll_size,
        )

        # -> (n_forecasts, n_lags, n_prediction_iterations)
        X = X[0][:, :, 0]

        if X.ndim == 2:
            # without autoregression, the last dimension was collapsed; bring back dimension
            X = X[:, :, np.newaxis]

        # stride can be applied directly in most cases; only with `multi_models=False` and `is_auto_regression=False`
        # all rows must be kept since the final forecast may include earlier forecasts (single model must step back to
        # produce all forecasts for `1 < horizon < n`
        if multi_models or is_auto_regression:
            X = X[::stride]

        # generate `num_samples` examples for probabilistic predictions
        # -> (n_forecasts * n_samples, n_lags, n_prediction_iterations)
        X = np.repeat(X, num_samples, axis=0)

        # generate forecasts for each forecast iteration (potential auto-regression)
        predictions = []
        t_pred = output_chunk_length if multi_models else 1
        for pred_idx in range(X.shape[-1]):
            # X for the current forecast iteration
            current_X = X[:, :, pred_idx]

            # forecast shape: (n_forecasts * num_samples, k, n_components),
            # where k = output_chunk length if multi_models, 1 otherwise
            forecast = model._predict(
                x=current_X,
                num_samples=num_samples,
                predict_likelihood_parameters=predict_likelihood_parameters,
                random_state=random_state,
                **predict_kwargs,
            )

            # for auto-regression: update history of future Xs with current forecast
            for auto_reg_idx in range(1, X.shape[-1] - pred_idx):
                # future iteration's lagged features
                next_X = X[:, :, pred_idx + auto_reg_idx]

                # determine which lags the forecasts correspond to in the future iteration
                lags_output_adjust = lags_output - (roll_size * auto_reg_idx)

                # find matches between forecasted components and component-specific lags of the future iteration
                take_y_indices = []
                update_x_indices = []
                for comp_idx, comp_lags in enumerate(target_lags):
                    for lag_idx, lag in enumerate(comp_lags):
                        y_pos = np.argwhere(lags_output_adjust == lag)
                        if len(y_pos) > 0:
                            update_x_indices.append(
                                target_lag_positions[comp_idx][lag_idx]
                            )
                            take_y_indices.append(
                                comp_idx + y_pos[0, 0] * series_.n_components
                            )

                # update future X with current matched predictions
                next_X[:, update_x_indices] = forecast.reshape(forecast.shape[0], -1)[
                    :, take_y_indices
                ]

            # reshape to separate forecasts and samples
            # -> (n_forecasts, output_chunk_length, n_components, n_samples)
            forecast = np.moveaxis(
                forecast.reshape(
                    X.shape[0] // num_samples,
                    num_samples,
                    output_chunk_length if multi_models else 1,
                    -1,
                ),
                1,
                -1,
            )

            if not multi_models and not is_auto_regression:
                # forecast horizon is given by multiple (previous) forecasts -> apply sliding window
                # -> (n_forecasts, 1, 1, k, n_components, n_samples)
                forecast = sliding_window_view(
                    forecast[:, 0],
                    (forecast_horizon, len(forecast_components), num_samples),
                )

                # remove the last windows, apply stride and extract horizon
                # -> (n_forecasts, k, n_components, n_samples)
                last_window = min(forecast_horizon - output_chunk_length, 0) or None
                forecast = forecast[:last_window:stride, 0, 0, :forecast_horizon, :, :]

            # store only the relevant forecast iterations (others were only used to update future Xs
            # for auto-regression)
            if (
                t_pred % (output_chunk_length if multi_models else 1) == 0
                or t_pred > forecast_horizon
            ):
                # - either one of the main forecast iterations at a round multiple of output_chunk_length
                # - or the first iteration if forecast_horizon < output_chunk_length
                predictions.append(forecast[:, :forecast_horizon])
            elif t_pred + output_chunk_shift == forecast_horizon:
                # - the last autoregressive forecast iteration when forecast_horizon is not a round multiple of
                #   output_chunk_length
                take_last_n = (
                    forecast_horizon - output_chunk_shift
                ) % output_chunk_length
                predictions.append(forecast[:, -take_last_n:])

            t_pred += roll_size

        # -> (n_forecasts, forecast_horizon, n_components, n_samples)
        forecast = np.concatenate(predictions, axis=1)

        if last_points_only:
            # a single TimeSeries with only the last points of each forecast
            # -> TimeSeries with shape: (n_forecasts, n_components, n_samples)
            new_times = generate_index(
                start=hist_fct_start
                + (forecast_horizon + output_chunk_shift - 1) * freq,
                length=forecast.shape[0],
                freq=freq * stride,
                name=series_._time_index.name,
            )
            forecasts_ = TimeSeries(
                times=new_times,
                values=forecast[:, -1],
                components=forecast_components,
                static_covariates=series_.static_covariates,
                hierarchy=series_.hierarchy,
                metadata=series_.metadata,
                copy=False,
            )
        else:
            # a list of TimeSeries with the complete forecasts
            # -> list[TimeSeries] each with shape: (forecast_horizon, n_components, n_samples)
            forecasts_ = []
            new_times = generate_index(
                start=hist_fct_start + output_chunk_shift * series_.freq,
                length=forecast_horizon + (forecast.shape[0] - 1) * stride,
                freq=freq,
                name=series_._time_index.name,
            )
            for idx_ftc, step_fct in enumerate(
                range(0, forecast.shape[0] * stride, stride)
            ):
                ts = TimeSeries(
                    times=new_times[step_fct : step_fct + forecast_horizon],
                    values=forecast[idx_ftc],
                    components=forecast_components,
                    static_covariates=series_.static_covariates,
                    hierarchy=series_.hierarchy,
                    metadata=series_.metadata,
                    copy=False,
                )
                forecasts_.append(ts)

        forecasts_list.append(forecasts_)
    return forecasts_list
