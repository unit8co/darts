{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from u8timeseries import TimeSeries\n",
    "from u8timeseries.preprocessing import ScalerWrapper\n",
    "from u8timeseries.models import RNNModel, ExponentialSmoothing\n",
    "from u8timeseries.metrics import mape\n",
    "from u8timeseries.utils.statistics import check_seasonality, plot_acf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of previous time stamps taken into account.\n",
    "SEQ_LENGTH = 12\n",
    "# Number of features in last hidden state\n",
    "HIDDEN_SIZE = 25\n",
    "# number of output time-steps to predict\n",
    "OUTPUT_LEN = 1\n",
    "# Number of stacked rnn layers.\n",
    "NUM_LAYERS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air Passenger Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data:\n",
    "df = pd.read_csv('AirPassengers.csv', delimiter=\",\")\n",
    "series = TimeSeries.from_dataframe(df, 'Month', '#Passengers')\n",
    "\n",
    "# Create training and validation sets:\n",
    "train, val = series.split_after(pd.Timestamp('19590101'))\n",
    "\n",
    "# Normalize the time series (note: we avoid fitting the transformer on the validation set)\n",
    "transformer = ScalerWrapper()\n",
    "train_transformed = transformer.fit_transform(train)\n",
    "val_transformed = transformer.transform(val)\n",
    "series_transformed = transformer.transform(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train an LSTM neural net. For using vanilla RNN or GRU instead, replace `'LSTM'` by `'RNN'` or `'GRU'`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_model = RNNModel('LSTM', OUTPUT_LEN, SEQ_LENGTH, HIDDEN_SIZE, NUM_LAYERS, \n",
    "                    batch_size=16, n_epochs=400, optimizer_kwargs={'lr': 1e-3}, \n",
    "                    model_name='Air_RNN', log_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.fit(train_transformed, val_transformed, verbose=True)  # 107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at predictions on the validation set\n",
    "Use the \"current\" model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    pred_series = model.predict(n=26)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    series_transformed.plot(label='actual')\n",
    "    pred_series.plot(label='forecast')\n",
    "    plt.title('MAPE: {}'.format(mape(pred_series.slice_intersect(val_transformed), val_transformed)))\n",
    "    plt.legend();\n",
    "    \n",
    "eval_model(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best model obtained over training, according to validation loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RNNModel.load_from_checkpoint(model_name='Air_RNN', best=True)\n",
    "eval_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from u8timeseries.backtesting import backtest_forecasting\n",
    "\n",
    "my_model = RNNModel('RNN', OUTPUT_LEN, SEQ_LENGTH, HIDDEN_SIZE, NUM_LAYERS, \n",
    "                    batch_size=32, n_epochs=200, optimizer_kwargs={'lr': 1e-3}, \n",
    "                    model_name='Air_RNN')\n",
    "\n",
    "# Perform the actual backtest\n",
    "backtest_series = backtest_forecasting(series_transformed, my_model, pd.Timestamp('19590101'), fcast_horizon_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "series_transformed.plot(label='actual', lw=2)\n",
    "backtest_series.plot(label='backtest', lw=2)\n",
    "plt.legend()\n",
    "plt.title('Backtest, starting Jan 1959, with a 6-months horizon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trials with a longer output length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_gru = RNNModel('GRU', OUTPUT_LEN*4, SEQ_LENGTH, HIDDEN_SIZE, NUM_LAYERS,\n",
    "                        batch_size=64, n_epochs=1500, model_name='Air_GRU_out12', log_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_gru.fit(train_transformed, val_series=val_transformed, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with horizon=28, and feeding predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_series = my_model_gru.predict(n=28)\n",
    "series_transformed.plot()\n",
    "pred_series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly sunspot\n",
    "Let's now try a more challenging time series; that of the monthly number of sunspots since 1749. First, we build the time series from the data, and check its periodicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('monthly-sunspots.csv', delimiter=\",\")\n",
    "series_sunspot = TimeSeries.from_dataframe(df2, 'Month', 'Sunspots')\n",
    "\n",
    "series_sunspot.plot()\n",
    "check_seasonality(series_sunspot, max_lag=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(series_sunspot, 125, max_lag=240) # ~11 years seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sp, val_sp = series_sunspot.split_after(pd.Timestamp('19401001'))\n",
    "\n",
    "transformer_sunspot = ScalerWrapper()\n",
    "train_sp_transformed = transformer_sunspot.fit_transform(train_sp)\n",
    "val_sp_transformed = transformer_sunspot.transform(val_sp)\n",
    "series_sp_transformed = transformer.transform(series_sunspot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 125\n",
    "HIDDEN_SIZE = 10\n",
    "# OUTPUT_LEN = 50\n",
    "OUTPUT_LEN = 10\n",
    "# NUM_LAYERS = 3\n",
    "NUM_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_model_sun = RNNModel('RNN', OUTPUT_LEN, SEQ_LENGTH, HIDDEN_SIZE, NUM_LAYERS,\n",
    "                        batch_size=64, n_epochs=300, model_name='sun_GRU', nr_epochs_val_period=1,\n",
    "                        optimizer_kwargs={'lr': 1e-3}, log_tensorboard=True)\n",
    "\n",
    "my_model_sun.fit(train_sp_transformed, val_series=val_sp_transformed, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of comparison, let's also fit an exponential smoothing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_ets = ExponentialSmoothing()\n",
    "my_model_ets.fit(train_sp_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the predictions with the two models (the RNN can be somewhat slow)\n",
    "pred_series = my_model_sun.predict(550)\n",
    "pred_series_ets = my_model_ets.predict(550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sp_transformed.plot(label='actual')\n",
    "pred_series.plot(label='our RNN')\n",
    "pred_series_ets.plot(label='ETS')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
