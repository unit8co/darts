{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Foundation Models for Time Series Forecasting\n\nThis notebook demonstrates zero-shot forecasting with pretrained foundation models.\n\n**Models:**\n- **TimesFM 2.5** (Google): Decoder-only transformer, 200M parameters\n- **Chronos 2** (Amazon): T5-based encoder-decoder, 120M parameters  \n- **Exponential Smoothing**: Traditional baseline for comparison\n\n**Datasets:**\n1. **Air Passengers**: Monthly data with clear seasonal patterns (1949-1960)\n2. **Energy Load**: Hourly electricity demand with complex multi-scale seasonality\n\nBoth foundation models provide probabilistic forecasts with uncertainty quantification. We'll compare their zero-shot performance against a traditional approach.\n\nFor architecture details and training methodology, see the [Foundation Models User Guide](../docs/userguide/foundation_models.md)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "Install Darts with foundation model support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install:\n",
    "# !pip install \"darts[timesfm,chronos]\"\n",
    "# or with uv:\n",
    "# !uv pip install \"darts[timesfm,chronos]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.datasets import AirPassengersDataset, EnergyDataset\n",
    "from darts.models import TimesFMModel, ChronosModel, ExponentialSmoothing\n",
    "from darts.metrics import mape\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Configuration\n",
    "SPLIT_RATIO = 0.8\n",
    "NUM_SAMPLES = 100\n",
    "\n",
    "# Define consistent color palette for all plots (using matplotlib default colors)\n",
    "TIMESFM_COLOR = 'C3'  # Red (distinct from ground truth black)\n",
    "CHRONOS_COLOR = 'C1'   # Orange\n",
    "EXP_COLOR = 'C2'       # Green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_median_comparison(val, forecasts, mapes, model_names, colors, dataset_name, ylabel):\n",
    "    \"\"\"Plot median forecast comparison across all models.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    \n",
    "    # Extract medians\n",
    "    medians = [fc.quantile(0.5) for fc in forecasts]\n",
    "    \n",
    "    # Plot ground truth\n",
    "    val.plot(ax=ax, label=\"ground truth\", color='black', linewidth=2.5)\n",
    "    \n",
    "    # Plot each model's median\n",
    "    for median, mape_val, name, color in zip(medians, mapes, model_names, colors):\n",
    "        median.plot(ax=ax, label=f\"{name} ({mape_val:.2f}% MAPE)\", \n",
    "                   color=color, linewidth=2)\n",
    "    \n",
    "    ax.set_title(f\"{dataset_name}: Median Forecast Comparison\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return medians  # Return for later use in residual analysis\n",
    "\n",
    "\n",
    "def plot_probabilistic_forecasts(val, forecasts, model_names, colors, dataset_name, ylabel):\n",
    "    \"\"\"Plot probabilistic forecasts with confidence intervals.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharex=True, sharey=True)\n",
    "    \n",
    "    for i, (fc, name, color) in enumerate(zip(forecasts, model_names, colors)):\n",
    "        val.plot(ax=axes[i], label=\"ground truth\", color='black', linewidth=2.5)\n",
    "        fc.plot(ax=axes[i], label=name, color=color)\n",
    "        \n",
    "        # Set title based on model type\n",
    "        if i == 0:\n",
    "            axes[i].set_title(f\"{name}: Probabilistic Forecast (Quantile Head)\")\n",
    "            axes[i].set_ylabel(ylabel)  # Only leftmost gets ylabel\n",
    "        elif i == 1:\n",
    "            axes[i].set_title(f\"{name}: Probabilistic Forecast (Sampling)\")\n",
    "        else:\n",
    "            axes[i].set_title(f\"{name}: Probabilistic Forecast\")\n",
    "        \n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_standardized_errors(val, medians, model_names, colors, dataset_name):\n",
    "    \"\"\"Plot standardized forecast errors with statistics table.\"\"\"\n",
    "    # Calculate standardized errors\n",
    "    std_errors_list = []\n",
    "    for median in medians:\n",
    "        errors = (val - median).values().flatten()\n",
    "        std_errors = errors / errors.std()\n",
    "        std_errors_list.append(std_errors)\n",
    "    \n",
    "    # Create boxplot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bp = ax.boxplot(std_errors_list, tick_labels=model_names, patch_artist=True,\n",
    "                    showmeans=True, meanline=True,\n",
    "                    medianprops=dict(color='black', linewidth=2),\n",
    "                    meanprops=dict(color='red', linewidth=2, linestyle='--'))\n",
    "    \n",
    "    # Color the boxes\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.6)\n",
    "    \n",
    "    ax.axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax.set_title(f'{dataset_name}: Standardized Forecast Errors')\n",
    "    ax.set_ylabel('Standardized Error (\u03c3)')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    quantiles = [0.05, 0.15, 0.25, 0.5, 0.75, 0.85, 0.95]\n",
    "    stats_data = []\n",
    "    \n",
    "    for errors, label in zip(std_errors_list, model_names):\n",
    "        stats = {\n",
    "            'Model': label,\n",
    "            'Mean': f'{errors.mean():.3f}',\n",
    "            'Std': f'{errors.std():.3f}',\n",
    "        }\n",
    "        for q in quantiles:\n",
    "            stats[f'Q{int(q*100)}'] = f'{np.percentile(errors, q*100):.3f}'\n",
    "        stats_data.append(stats)\n",
    "    \n",
    "    stats_df = pd.DataFrame(stats_data)\n",
    "    print(f\"\\n{dataset_name} - Standardized Error Distribution Statistics:\")\n",
    "    print(\"=\"*100)\n",
    "    print(stats_df.to_string(index=False))\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "air_series = AirPassengersDataset().load()\n",
    "air_train, air_val = air_series.split_before(SPLIT_RATIO)\n",
    "\n",
    "print(f\"Total length: {len(air_series)}\")\n",
    "print(f\"Training: {len(air_train)} points\")\n",
    "print(f\"Validation: {len(air_val)} points\")\n",
    "\n",
    "# Visualize with train/test split\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "air_series.plot(ax=ax, label=\"Historical\", color='black', linewidth=2)\n",
    "\n",
    "# Add train/test split line\n",
    "split_time = air_train.end_time()\n",
    "ax.axvline(split_time, color='red', linestyle='--', linewidth=2,\n",
    "           label='Train/Test Split', alpha=0.7)\n",
    "\n",
    "ax.set_title(\"Air Passengers Dataset: Train/Test Split (80/20)\")\n",
    "ax.set_ylabel(\"Passengers (thousands)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimesFM 2.5\n",
    "print(\"Generating TimesFM 2.5 forecast...\")\n",
    "timesfm_model = TimesFMModel(\n",
    "    context_length=512,\n",
    "    device='auto'\n",
    ")\n",
    "air_timesfm_forecast = timesfm_model.predict(n=len(air_val), series=air_train, num_samples=NUM_SAMPLES)\n",
    "air_timesfm_mape = mape(air_val, air_timesfm_forecast)\n",
    "print(f\"TimesFM 2.5 MAPE: {air_timesfm_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Chronos 2\nprint(\"Generating Chronos 2 forecast...\")\nchronos_model = ChronosModel(context_length=512)\nair_chronos_forecast = chronos_model.predict(n=len(air_val), series=air_train, num_samples=NUM_SAMPLES)\nair_chronos_mape = mape(air_val, air_chronos_forecast)\nprint(f\"Chronos 2 MAPE: {air_chronos_mape:.2f}%\")\n\n# Model display names for plots\ntimesfm_name = \"TimesFM 2.5 200M\"\nchronos_name = \"Chronos 2 Base\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Smoothing (Probabilistic)\n",
    "print(\"Generating Exponential Smoothing forecast...\")\n",
    "exp_model = ExponentialSmoothing()\n",
    "exp_model.fit(air_train)\n",
    "air_exp_forecast = exp_model.predict(n=len(air_val), num_samples=NUM_SAMPLES)\n",
    "air_exp_mape = mape(air_val, air_exp_forecast)\n",
    "print(f\"Exponential Smoothing MAPE: {air_exp_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Forecasts\n",
    "\n",
    "We compare the models in two ways:\n",
    "1. **Median Comparison**: Quick comparison of point forecasts across all models\n",
    "2. **Probabilistic Forecasts**: Individual uncertainty quantification with confidence intervals (50%, 75%, 90%, 95%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Comparison - All Models\n",
    "air_medians = plot_median_comparison(\n",
    "    air_val,\n",
    "    [air_timesfm_forecast, air_chronos_forecast, air_exp_forecast],\n",
    "    [air_timesfm_mape, air_chronos_mape, air_exp_mape],\n",
    "    [timesfm_name, chronos_name, 'Exp. Smoothing'],\n",
    "    [TIMESFM_COLOR, CHRONOS_COLOR, EXP_COLOR],\n",
    "    \"Air Passengers\",\n",
    "    \"Passengers (thousands)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistic Forecasts with Confidence Intervals\n",
    "plot_probabilistic_forecasts(\n",
    "    air_val,\n",
    "    [air_timesfm_forecast, air_chronos_forecast, air_exp_forecast],\n",
    "    [timesfm_name, chronos_name, 'Exp. Smoothing'],\n",
    "    [TIMESFM_COLOR, CHRONOS_COLOR, EXP_COLOR],\n",
    "    \"Air Passengers\",\n",
    "    \"Passengers (thousands)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance table\n",
    "air_results = pd.DataFrame({\n",
    "    'Model': [timesfm_name, chronos_name, 'Exponential Smoothing'],\n",
    "    'MAPE (%)': [air_timesfm_mape, air_chronos_mape, air_exp_mape]\n",
    "})\n",
    "air_results = air_results.sort_values('MAPE (%)')\n",
    "print(\"\\nAir Passengers Performance:\")\n",
    "print(air_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized Forecast Errors (Normalized Residuals)\n",
    "plot_standardized_errors(\n",
    "    air_val,\n",
    "    air_medians,\n",
    "    [timesfm_name, chronos_name, 'Exp. Smoothing'],\n",
    "    [TIMESFM_COLOR, CHRONOS_COLOR, EXP_COLOR],\n",
    "    \"Air Passengers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Analysis\n",
    "\n",
    "Understanding forecast errors helps identify model biases and reliability:\n",
    "- **Centered at zero:** Good - no systematic bias\n",
    "- **Symmetric distribution:** Good - balanced over/under-prediction\n",
    "- **Low variance:** Good - consistent accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset 2: Energy Load (Complex Hourly Patterns)\n",
    "\n",
    "Energy load data contains complex multi-scale seasonality (daily and weekly patterns) - testing how models handle hierarchical temporal structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (single component, subset for tutorial speed)\n",
    "energy = EnergyDataset().load()\n",
    "energy_series = energy['total load actual'][-1000:]  # Use last 1000 points\n",
    "energy_train, energy_val = energy_series.split_before(SPLIT_RATIO)\n",
    "\n",
    "print(f\"Total length: {len(energy_series)}\")\n",
    "print(f\"Training: {len(energy_train)} points\")\n",
    "print(f\"Validation: {len(energy_val)} points\")\n",
    "\n",
    "# Visualize with train/test split\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "energy_series.plot(ax=ax, label=\"Historical\", color='black', linewidth=2)\n",
    "\n",
    "# Add train/test split line\n",
    "split_time = energy_train.end_time()\n",
    "ax.axvline(split_time, color='red', linestyle='--', linewidth=2,\n",
    "           label='Train/Test Split', alpha=0.7)\n",
    "\n",
    "ax.set_title(\"Energy Load Dataset: Train/Test Split (80/20)\")\n",
    "ax.set_ylabel(\"Load (MW)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimesFM 2.5\n",
    "print(\"Generating TimesFM 2.5 forecast...\")\n",
    "energy_timesfm_forecast = timesfm_model.predict(n=len(energy_val), series=energy_train, num_samples=NUM_SAMPLES)\n",
    "energy_timesfm_mape = mape(energy_val, energy_timesfm_forecast)\n",
    "print(f\"TimesFM 2.5 MAPE: {energy_timesfm_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronos 2\n",
    "print(\"Generating Chronos 2 forecast...\")\n",
    "energy_chronos_forecast = chronos_model.predict(n=len(energy_val), series=energy_train, num_samples=NUM_SAMPLES)\n",
    "energy_chronos_mape = mape(energy_val, energy_chronos_forecast)\n",
    "print(f\"Chronos 2 MAPE: {energy_chronos_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos 2 with Time Covariates\n",
    "\n",
    "Chronos 2's architecture is optimized for **multivariate forecasting with covariates**. The paper states it achieves \"largest improvements with exogenous features.\"\n",
    "\n",
    "Energy load has strong temporal patterns:\n",
    "- **Daily cycles**: Business hours vs night\n",
    "- **Weekly patterns**: Weekday vs weekend  \n",
    "- **Seasonal variation**: Heating (winter) vs cooling (summer)\n",
    "\n",
    "Let's test whether adding time-based covariates (hour, day-of-week, month) unlocks Chronos 2's full potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_covariates(series: TimeSeries) -> TimeSeries:\n",
    "    \"\"\"\n",
    "    Create time-based covariates from series timestamps.\n",
    "    \n",
    "    Features:\n",
    "    - hour_sin, hour_cos: Cyclic encoding of hour (0-23)\n",
    "    - dow_sin, dow_cos: Cyclic encoding of day of week (0-6)\n",
    "    - month_sin, month_cos: Cyclic encoding of month (1-12)\n",
    "    \n",
    "    Cyclic encoding ensures continuity (hour 23 \u2192 0, Dec \u2192 Jan).\n",
    "    \"\"\"\n",
    "    df = series.to_dataframe()\n",
    "    index = df.index\n",
    "    \n",
    "    # Hour of day (0-23) - Daily cycles\n",
    "    hour = index.hour\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * hour / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * hour / 24)\n",
    "    \n",
    "    # Day of week (0=Monday, 6=Sunday) - Weekly patterns\n",
    "    dow = index.dayofweek\n",
    "    df['dow_sin'] = np.sin(2 * np.pi * dow / 7)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * dow / 7)\n",
    "    \n",
    "    # Month (1-12) - Seasonal variation\n",
    "    month = index.month\n",
    "    df['month_sin'] = np.sin(2 * np.pi * month / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * month / 12)\n",
    "    \n",
    "    # Keep only covariate columns\n",
    "    df = df.drop(columns=df.columns[0])\n",
    "    \n",
    "    return TimeSeries.from_dataframe(df)\n",
    "\n",
    "# Create covariates for full series (train + validation)\n",
    "energy_covariates = create_time_covariates(energy_series)\n",
    "\n",
    "# Split to match train/val split\n",
    "energy_cov_train = energy_covariates[:len(energy_train)]     # Past covariates\n",
    "energy_cov_future = energy_covariates[len(energy_train):]    # Future covariates\n",
    "\n",
    "print(f\"Created covariates: {energy_covariates.components.tolist()}\")\n",
    "print(f\"Covariate train: {len(energy_cov_train)} points\")\n",
    "print(f\"Covariate future: {len(energy_cov_future)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronos 2 WITH time covariates\n",
    "print(\"Generating Chronos 2 forecast WITH time covariates...\")\n",
    "energy_chronos_cov_forecast = chronos_model.predict(\n",
    "    n=len(energy_val),\n",
    "    series=energy_train,\n",
    "    past_covariates=energy_cov_train,      # Historical temporal features\n",
    "    future_covariates=energy_cov_future,   # Known future temporal features  \n",
    "    num_samples=NUM_SAMPLES\n",
    ")\n",
    "energy_chronos_cov_mape = mape(energy_val, energy_chronos_cov_forecast)\n",
    "print(f\"Chronos 2 (with covariates): {energy_chronos_cov_mape:.2f}% MAPE\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = energy_chronos_mape - energy_chronos_cov_mape\n",
    "improvement_pct = (improvement / energy_chronos_mape) * 100\n",
    "print(f\"\\nImprovement from covariates: {improvement:.2f}% MAPE ({improvement_pct:.1f}% reduction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Smoothing (Probabilistic)\n",
    "print(\"Generating Exponential Smoothing forecast...\")\n",
    "exp_model_energy = ExponentialSmoothing()\n",
    "exp_model_energy.fit(energy_train)\n",
    "energy_exp_forecast = exp_model_energy.predict(n=len(energy_val), num_samples=NUM_SAMPLES)\n",
    "energy_exp_mape = mape(energy_val, energy_exp_forecast)\n",
    "print(f\"Exponential Smoothing MAPE: {energy_exp_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Forecasts\n",
    "\n",
    "We compare the models in two ways:\n",
    "1. **Median Comparison**: Quick comparison of point forecasts across all models\n",
    "2. **Probabilistic Forecasts**: Individual uncertainty quantification with confidence intervals (50%, 75%, 90%, 95%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Comparison - All Models\n",
    "energy_medians = plot_median_comparison(\n",
    "    energy_val,\n",
    "    [energy_timesfm_forecast, energy_chronos_forecast, energy_exp_forecast],\n",
    "    [energy_timesfm_mape, energy_chronos_mape, energy_exp_mape],\n",
    "    [timesfm_name, chronos_name, 'Exp. Smoothing'],\n",
    "    [TIMESFM_COLOR, CHRONOS_COLOR, EXP_COLOR],\n",
    "    \"Energy Load\",\n",
    "    \"Load (MW)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistic Forecasts with Confidence Intervals\n",
    "plot_probabilistic_forecasts(\n",
    "    energy_val,\n",
    "    [energy_timesfm_forecast, energy_chronos_forecast, energy_exp_forecast],\n",
    "    [timesfm_name, chronos_name, 'Exp. Smoothing'],\n",
    "    [TIMESFM_COLOR, CHRONOS_COLOR, EXP_COLOR],\n",
    "    \"Energy Load\",\n",
    "    \"Load (MW)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized Forecast Errors (Normalized Residuals)\n",
    "plot_standardized_errors(\n",
    "    energy_val,\n",
    "    energy_medians,\n",
    "    [timesfm_name, chronos_name, 'Exp. Smoothing'],\n",
    "    [TIMESFM_COLOR, CHRONOS_COLOR, EXP_COLOR],\n",
    "    \"Energy Load\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Analysis\n",
    "\n",
    "Understanding standardized forecast errors helps identify model biases and reliability:\n",
    "\n",
    "**Boxplot interpretation:**\n",
    "- **Median near zero**: No systematic bias\n",
    "- **Symmetric distribution**: Balanced over/under-prediction\n",
    "- **Tight IQR (box)**: Consistent accuracy\n",
    "- **Few outliers**: Robust to unusual patterns\n",
    "\n",
    "**Comparison across models:**\n",
    "If TimesFM's box is much tighter than Chronos, it may suggest familiarity with similar grid load patterns (even if not explicitly in documented training data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance table\n",
    "energy_results = pd.DataFrame({\n",
    "    'Model': [\n",
    "        timesfm_name,\n",
    "        f'{chronos_name} (with covariates)',\n",
    "        chronos_name,\n",
    "        'Exponential Smoothing'\n",
    "    ],\n",
    "    'MAPE (%)': [\n",
    "        energy_timesfm_mape,\n",
    "        energy_chronos_cov_mape,\n",
    "        energy_chronos_mape,\n",
    "        energy_exp_mape\n",
    "    ]\n",
    "})\n",
    "energy_results = energy_results.sort_values('MAPE (%)')\n",
    "print(\"\\nEnergy Load Performance:\")\n",
    "print(energy_results.to_string(index=False))\n",
    "\n",
    "# Calculate improvement from covariates\n",
    "improvement_pct = ((energy_chronos_mape - energy_chronos_cov_mape) / energy_chronos_mape) * 100\n",
    "print(f\"\\n\u2728 Chronos 2 improved {improvement_pct:.1f}% with time covariates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Performance Summary Across All Datasets\n\nComparing model performance across different data patterns:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create comprehensive comparison table\nsummary = pd.DataFrame({\n    'Dataset': ['Air Passengers', 'Energy Load'],\n    f'{timesfm_name} MAPE (%)': [air_timesfm_mape, energy_timesfm_mape],\n    f'{chronos_name} MAPE (%)': [air_chronos_mape, energy_chronos_mape],\n    'Exp. Smoothing MAPE (%)': [air_exp_mape, energy_exp_mape]\n})\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"COMPREHENSIVE PERFORMANCE COMPARISON\")\nprint(\"=\"*70)\nprint(summary.to_string(index=False))\nprint(\"=\"*70)\n\n# Calculate average performance\navg_timesfm = summary[f'{timesfm_name} MAPE (%)'].mean()\navg_chronos = summary[f'{chronos_name} MAPE (%)'].mean()\navg_exp = summary['Exp. Smoothing MAPE (%)'].mean()\n\nprint(f\"\\nAverage MAPE Across Datasets:\")\nprint(f\"  {timesfm_name}:          {avg_timesfm:.2f}%\")\nprint(f\"  {chronos_name}:            {avg_chronos:.2f}%\")\nprint(f\"  Exp. Smoothing:       {avg_exp:.2f}%\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Key Takeaways\n\n**What We Learned:**\n\n1. **Zero-Shot Power**: Foundation models work immediately without training\n   - TimesFM 2.5 and Chronos 2 deliver competitive accuracy out-of-the-box\n   - No hyperparameter tuning required\n   - Ideal for rapid prototyping and cold-start scenarios\n\n2. **Model Specializations**:\n   - **TimesFM 2.5**: Fast, optimized for univariate forecasting with native quantile head\n   - **Chronos 2**: Benefits from time covariates on complex temporal patterns\n   - **Traditional models**: Remain valuable for explainability and simple patterns\n\n3. **Probabilistic Forecasting**: Both foundation models provide uncertainty quantification\n   - TimesFM 2.5: 10 quantiles via native quantile head (0.0-0.9)\n   - Chronos 2: 21 quantiles via sampling-based forecasting\n\n4. **Practical Trade-offs**:\n   - Foundation models require more memory (200M+ parameters)\n   - Inference time varies: TimesFM 2.5 fastest, Chronos moderate\n   - Complex patterns often favor foundation models over traditional approaches\n\n### Resources\n\n- **TimesFM Paper**: [Das et al., ICML 2024](https://arxiv.org/abs/2310.10688)\n- **Chronos Paper**: [Amazon Science, 2024](https://arxiv.org/abs/2403.07815)  \n- **Darts Documentation**: [User Guide](https://unit8co.github.io/darts/)\n- **Foundation Models Guide**: [Architecture Details](../docs/userguide/foundation_models.md)\n\n**Next Steps**: Experiment with your own data, try different context lengths, and explore ensemble approaches."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}