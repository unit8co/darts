
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Time Series Mixer (TSMixer) &#8212; darts  documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/docs-favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Ensembling Models" href="19-EnsembleModel-examples.html" />
    <link rel="prev" title="TimeSeries Deep Encoder" href="18-TiDE-examples.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/darts-logo-trim.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../README.html">
  Home
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../quickstart/00-quickstart.html">
  Quickstart
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../userguide.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../generated_api/darts.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../examples.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release_notes/RELEASE_NOTES.html">
  Release Notes
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/unit8co/darts" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/unit8co" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01-multi-time-series-and-covariates.html">
   Multiple Time Series, Pre-trained Models and Covariates
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="02-data-processing.html">
   Data (pre) processing using
   <code class="docutils literal notranslate">
    <span class="pre">
     DataTransformer
    </span>
   </code>
   and
   <code class="docutils literal notranslate">
    <span class="pre">
     Pipeline
    </span>
   </code>
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="15-static-covariates.html">
   Static Covariates
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="14-transfer-learning.html">
   Transfer Learning for Time Series Forecasting with Darts
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="16-hierarchical-reconciliation.html">
   Hierarchical Reconciliation - Example on the Australian Tourism Dataset
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="17-hyperparameter-optimization.html">
   Hyper-parameters Optimization for Electricity Load Forecasting
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="20-RegressionModel-examples.html">
   Regression Models
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="23-Conformal-Prediction-examples.html">
   Conformal Prediction Models
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="03-FFT-examples.html">
   Fast Fourier Transform Forecasting Model (FFT)
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="04-RNN-examples.html">
   Recurrent Neural Networks Models
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="05-TCN-examples.html">
   Temporal Convolutional Network
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="06-Transformer-examples.html">
   Transformer Model
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="07-NBEATS-examples.html">
   N-BEATS
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="08-DeepAR-examples.html">
   Probabilistic RNN
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="09-DeepTCN-examples.html">
   DeepTCN model
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="13-TFT-examples.html">
   Temporal Fusion Transformer
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="18-TiDE-examples.html">
   TimeSeries Deep Encoder
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Time Series Mixer (TSMixer)
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="19-EnsembleModel-examples.html">
   Ensembling Models
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="10-Kalman-filter-examples.html">
   Filtering and predicting using the darts filters
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="11-GP-filter-examples.html">
   Filtering and predicting using the Gaussian Process filter
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="22-anomaly-detection-examples.html">
   Anomaly Detection Darts Module
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="12-Dynamic-Time-Warping-example.html">
   Dynamic Time Warping (DTW)
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Time Series Mixer (TSMixer)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Data-Loading-and-preparation">
   Data Loading and preparation
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Model-Parameter-Setup">
   Model Parameter Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Model-configuration">
   Model configuration
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Model-Training">
   Model Training
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Backtest-the-probabilistic-models">
   Backtest the probabilistic models
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Results">
   Results
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="Time-Series-Mixer-(TSMixer)">
<h1>Time Series Mixer (TSMixer)<a class="headerlink" href="#Time-Series-Mixer-(TSMixer)" title="Permalink to this heading">¶</a></h1>
<p>This notebook walks through how to use Darts’ <code class="docutils literal notranslate"><span class="pre">TSMixerModel</span></code> and benchmarks it against <code class="docutils literal notranslate"><span class="pre">TiDEModel</span></code>.</p>
<p>TSMixer (Time-series Mixer) is an all-MLP architecture for time series forecasting.</p>
<p>It does so by integrating historical time series data, future known inputs, and static contextual information. The architecture uses a combination of conditional feature mixing and mixer layers to process and combine these different types of data for effective forecasting.</p>
<p>Translated to Darts, this model supports all types of covariates (past, future, and/or static).</p>
<p>See the original paper and model description <a class="reference external" href="https://arxiv.org/abs/2303.06053">here</a>.</p>
<p>According to the authors, the model outperforms several state-of-the-art models on multivariate forecasting tasks.</p>
<p>Let’s see how it performs against <code class="docutils literal notranslate"><span class="pre">TideModel</span></code> on the ETTh1 and ETTh2 datasets.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># fix python path if working locally</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">fix_pythonpath_if_working_locally</span>

<span class="n">fix_pythonpath_if_working_locally</span><span class="p">()</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>

<span class="n">logging</span><span class="o">.</span><span class="n">disable</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">CRITICAL</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.callbacks.early_stopping</span><span class="w"> </span><span class="kn">import</span> <span class="n">EarlyStopping</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">darts</span><span class="w"> </span><span class="kn">import</span> <span class="n">concatenate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.dataprocessing.transformers.scaler</span><span class="w"> </span><span class="kn">import</span> <span class="n">Scaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">ETTh1Dataset</span><span class="p">,</span> <span class="n">ETTh2Dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mql</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">TiDEModel</span><span class="p">,</span> <span class="n">TSMixerModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.utils.callbacks</span><span class="w"> </span><span class="kn">import</span> <span class="n">TFMProgressBar</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.utils.likelihood_models.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantileRegression</span>
</pre></div>
</div>
</div>
</section>
<section id="Data-Loading-and-preparation">
<h1>Data Loading and preparation<a class="headerlink" href="#Data-Loading-and-preparation" title="Permalink to this heading">¶</a></h1>
<p>We consider the ETTh1 and ETTh2 datasets which contain hourly multivariate data of an electricity transformer (load, oil temperature, …). You can find more information <a class="reference external" href="https://unit8co.github.io/darts/generated_api/darts.datasets.html#darts.datasets.ETTh1Dataset">here</a>.</p>
<p>We will add static information to each transformer time series, that identifies whether it is the <code class="docutils literal notranslate"><span class="pre">ETTh1</span></code> or <code class="docutils literal notranslate"><span class="pre">ETTh2</span></code> transformer. Both TSMixer and TiDE can levarage this information.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">series</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">ds</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">ETTh1Dataset</span><span class="p">,</span> <span class="n">ETTh2Dataset</span><span class="p">]):</span>
    <span class="n">trafo</span> <span class="o">=</span> <span class="n">ds</span><span class="p">()</span><span class="o">.</span><span class="n">load</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">trafo</span> <span class="o">=</span> <span class="n">trafo</span><span class="o">.</span><span class="n">with_static_covariates</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;transformer_id&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">idx</span><span class="p">]}))</span>
    <span class="n">series</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trafo</span><span class="p">)</span>
<span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>component</th>
      <th>HUFL</th>
      <th>HULL</th>
      <th>MUFL</th>
      <th>MULL</th>
      <th>LUFL</th>
      <th>LULL</th>
      <th>OT</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016-07-01 00:00:00</th>
      <td>5.827</td>
      <td>2.009</td>
      <td>1.599</td>
      <td>0.462</td>
      <td>4.203</td>
      <td>1.340</td>
      <td>30.531000</td>
    </tr>
    <tr>
      <th>2016-07-01 01:00:00</th>
      <td>5.693</td>
      <td>2.076</td>
      <td>1.492</td>
      <td>0.426</td>
      <td>4.142</td>
      <td>1.371</td>
      <td>27.787001</td>
    </tr>
    <tr>
      <th>2016-07-01 02:00:00</th>
      <td>5.157</td>
      <td>1.741</td>
      <td>1.279</td>
      <td>0.355</td>
      <td>3.777</td>
      <td>1.218</td>
      <td>27.787001</td>
    </tr>
    <tr>
      <th>2016-07-01 03:00:00</th>
      <td>5.090</td>
      <td>1.942</td>
      <td>1.279</td>
      <td>0.391</td>
      <td>3.807</td>
      <td>1.279</td>
      <td>25.044001</td>
    </tr>
    <tr>
      <th>2016-07-01 04:00:00</th>
      <td>5.358</td>
      <td>1.942</td>
      <td>1.492</td>
      <td>0.462</td>
      <td>3.868</td>
      <td>1.279</td>
      <td>21.948000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-06-26 15:00:00</th>
      <td>-1.674</td>
      <td>3.550</td>
      <td>-5.615</td>
      <td>2.132</td>
      <td>3.472</td>
      <td>1.523</td>
      <td>10.904000</td>
    </tr>
    <tr>
      <th>2018-06-26 16:00:00</th>
      <td>-5.492</td>
      <td>4.287</td>
      <td>-9.132</td>
      <td>2.274</td>
      <td>3.533</td>
      <td>1.675</td>
      <td>11.044000</td>
    </tr>
    <tr>
      <th>2018-06-26 17:00:00</th>
      <td>2.813</td>
      <td>3.818</td>
      <td>-0.817</td>
      <td>2.097</td>
      <td>3.716</td>
      <td>1.523</td>
      <td>10.271000</td>
    </tr>
    <tr>
      <th>2018-06-26 18:00:00</th>
      <td>9.243</td>
      <td>3.818</td>
      <td>5.472</td>
      <td>2.097</td>
      <td>3.655</td>
      <td>1.432</td>
      <td>9.778000</td>
    </tr>
    <tr>
      <th>2018-06-26 19:00:00</th>
      <td>10.114</td>
      <td>3.550</td>
      <td>6.183</td>
      <td>1.564</td>
      <td>3.716</td>
      <td>1.462</td>
      <td>9.567000</td>
    </tr>
  </tbody>
</table>
<p>17420 rows × 7 columns</p>
</div></div>
</div>
<p>Before training, we split the data into train, validation, and test sets. The model will learn from the train set, use the validation set to determine when to stop training, and finally be evaluated on the test set.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">trafo</span> <span class="ow">in</span> <span class="n">series</span><span class="p">:</span>
    <span class="n">train_</span><span class="p">,</span> <span class="n">temp</span> <span class="o">=</span> <span class="n">trafo</span><span class="o">.</span><span class="n">split_after</span><span class="p">(</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">val_</span><span class="p">,</span> <span class="n">test_</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">split_after</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_</span><span class="p">)</span>
    <span class="n">val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_</span><span class="p">)</span>
    <span class="n">test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Lets look at the splits for the first column “HUFL” for each transformer</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">show_col</span> <span class="o">=</span> <span class="s2">&quot;HUFL&quot;</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">train_</span><span class="p">,</span> <span class="n">val_</span><span class="p">,</span> <span class="n">test_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">test</span><span class="p">)):</span>
    <span class="n">train_</span><span class="p">[</span><span class="n">show_col</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;train_trafo_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">val_</span><span class="p">[</span><span class="n">show_col</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;val_trafo_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">test_</span><span class="p">[</span><span class="n">show_col</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;test_trafo_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_21-TSMixer-examples_9_0.png" src="../_images/examples_21-TSMixer-examples_9_0.png" />
</div>
</div>
<p>Now let’s scale the data. To avoid leaking information from the validation and test sets, we scale the data based on the properties of the train set.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">Scaler</span><span class="p">()</span>  <span class="c1"># default uses sklearn&#39;s MinMaxScaler</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Model-Parameter-Setup">
<h1>Model Parameter Setup<a class="headerlink" href="#Model-Parameter-Setup" title="Permalink to this heading">¶</a></h1>
<p>Boilerplate code is no fun, especially in the context of training multiple models to compare performance. To avoid this, we use a common configuration that can be used with any Darts <code class="docutils literal notranslate"><span class="pre">TorchForecastingModel</span></code>.</p>
<p>A few interesting things about these parameters:</p>
<ul class="simple">
<li><p><strong>Gradient clipping:</strong> Mitigates exploding gradients during backpropagation by setting an upper limit on the gradient for a batch.</p></li>
<li><p><strong>Learning rate:</strong> The majority of the learning done by a model is in the earlier epochs. As training goes on it is often helpful to reduce the learning rate to fine-tune the model. That being said, it can also lead to significant overfitting.</p></li>
<li><p><strong>Early stopping:</strong> To avoid overfitting, we can use early stopping. It monitors a metric on the validation set and stops training once the metric is not improving anymore based on a custom condition.</p></li>
<li><p><strong>Likelihood and Loss Functions:</strong> You can either make the model probabilistic with a <code class="docutils literal notranslate"><span class="pre">likelihood</span></code>, or deterministic with a <code class="docutils literal notranslate"><span class="pre">loss_fn</span></code>. In this notebook we train probabilistic models using QuantileRegression.</p></li>
<li><p><strong>Reversible Instance Normalization:</strong> Use <a class="reference external" href="https://openreview.net/forum?id=cGDAkQo1C0p">Reversible Instance Normalization</a> which in most of the cases improves model performance.</p></li>
<li><p><strong>Encoders:</strong> We can encode time axis/calendar information and use them as past or future covariates using <code class="docutils literal notranslate"><span class="pre">add_encoders</span></code>. Here, we’ll add cyclic encodings of the hour, day of the week, and month as future covariates</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">create_params</span><span class="p">(</span>
    <span class="n">input_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">output_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">full_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
    <span class="c1"># early stopping: this setting stops training once the the validation</span>
    <span class="c1"># loss has not decreased by more than 1e-5 for 10 epochs</span>
    <span class="n">early_stopper</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">min_delta</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># PyTorch Lightning Trainer arguments (you can add any custom callback)</span>
    <span class="k">if</span> <span class="n">full_training</span><span class="p">:</span>
        <span class="n">limit_train_batches</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">limit_val_batches</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">200</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">limit_train_batches</span> <span class="o">=</span> <span class="mi">20</span>
        <span class="n">limit_val_batches</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">40</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

    <span class="c1"># only show the training and prediction progress bars</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">TFMProgressBar</span><span class="p">(</span>
        <span class="n">enable_sanity_check_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">enable_validation_bar</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">pl_trainer_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;gradient_clip_val&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="n">max_epochs</span><span class="p">,</span>
        <span class="s2">&quot;limit_train_batches&quot;</span><span class="p">:</span> <span class="n">limit_train_batches</span><span class="p">,</span>
        <span class="s2">&quot;limit_val_batches&quot;</span><span class="p">:</span> <span class="n">limit_val_batches</span><span class="p">,</span>
        <span class="s2">&quot;accelerator&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="s2">&quot;callbacks&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">early_stopper</span><span class="p">,</span> <span class="n">progress_bar</span><span class="p">],</span>
    <span class="p">}</span>

    <span class="c1"># optimizer setup, uses Adam by default</span>
    <span class="c1"># optimizer_cls = torch.optim.Adam</span>
    <span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="c1"># learning rate scheduler</span>
    <span class="n">lr_scheduler_cls</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ExponentialLR</span>
    <span class="n">lr_scheduler_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="mf">0.999</span><span class="p">}</span>

    <span class="c1"># for probabilistic models, we use quantile regression, and set `loss_fn` to `None`</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">QuantileRegression</span><span class="p">()</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;input_chunk_length&quot;</span><span class="p">:</span> <span class="n">input_chunk_length</span><span class="p">,</span>  <span class="c1"># lookback window</span>
        <span class="s2">&quot;output_chunk_length&quot;</span><span class="p">:</span> <span class="n">output_chunk_length</span><span class="p">,</span>  <span class="c1"># forecast/lookahead window</span>
        <span class="s2">&quot;use_reversible_instance_norm&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;optimizer_kwargs&quot;</span><span class="p">:</span> <span class="n">optimizer_kwargs</span><span class="p">,</span>
        <span class="s2">&quot;pl_trainer_kwargs&quot;</span><span class="p">:</span> <span class="n">pl_trainer_kwargs</span><span class="p">,</span>
        <span class="s2">&quot;lr_scheduler_cls&quot;</span><span class="p">:</span> <span class="n">lr_scheduler_cls</span><span class="p">,</span>
        <span class="s2">&quot;lr_scheduler_kwargs&quot;</span><span class="p">:</span> <span class="n">lr_scheduler_kwargs</span><span class="p">,</span>
        <span class="s2">&quot;likelihood&quot;</span><span class="p">:</span> <span class="n">likelihood</span><span class="p">,</span>  <span class="c1"># use a `likelihood` for probabilistic forecasts</span>
        <span class="s2">&quot;loss_fn&quot;</span><span class="p">:</span> <span class="n">loss_fn</span><span class="p">,</span>  <span class="c1"># use a `loss_fn` for determinsitic model</span>
        <span class="s2">&quot;save_checkpoints&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># checkpoint to retrieve the best performing model state,</span>
        <span class="s2">&quot;force_reset&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
        <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
        <span class="s2">&quot;add_encoders&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;cyclic&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;future&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;dayofweek&quot;</span><span class="p">,</span> <span class="s2">&quot;month&quot;</span><span class="p">]</span>
            <span class="p">}</span>  <span class="c1"># add cyclic time axis encodings as future covariates</span>
        <span class="p">},</span>
    <span class="p">}</span>
</pre></div>
</div>
</div>
</section>
<section id="Model-configuration">
<h1>Model configuration<a class="headerlink" href="#Model-configuration" title="Permalink to this heading">¶</a></h1>
<p>Let’s use the last week of hourly data as lookback window (<code class="docutils literal notranslate"><span class="pre">input_chunk_length</span></code>) and train a probabilistic model to predict the next 24 hours directly (<code class="docutils literal notranslate"><span class="pre">output_chunk_length</span></code>). Additionally, we tell the model to use the static information. To keep the notebook simple, we’ll set <code class="docutils literal notranslate"><span class="pre">full_training=False</span></code>. To get even better performance, set <code class="docutils literal notranslate"><span class="pre">full_training=True</span></code>.</p>
<p>Apart from that, we use our helper function to set up all the common model arguments.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">input_chunk_length</span> <span class="o">=</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">24</span>
<span class="n">output_chunk_length</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">use_static_covariates</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">full_training</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># create the models</span>
<span class="n">model_tsm</span> <span class="o">=</span> <span class="n">TSMixerModel</span><span class="p">(</span>
    <span class="o">**</span><span class="n">create_params</span><span class="p">(</span>
        <span class="n">input_chunk_length</span><span class="p">,</span>
        <span class="n">output_chunk_length</span><span class="p">,</span>
        <span class="n">full_training</span><span class="o">=</span><span class="n">full_training</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">use_static_covariates</span><span class="o">=</span><span class="n">use_static_covariates</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;tsm&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model_tide</span> <span class="o">=</span> <span class="n">TiDEModel</span><span class="p">(</span>
    <span class="o">**</span><span class="n">create_params</span><span class="p">(</span>
        <span class="n">input_chunk_length</span><span class="p">,</span>
        <span class="n">output_chunk_length</span><span class="p">,</span>
        <span class="n">full_training</span><span class="o">=</span><span class="n">full_training</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">use_static_covariates</span><span class="o">=</span><span class="n">use_static_covariates</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;tide&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;TSM&quot;</span><span class="p">:</span> <span class="n">model_tsm</span><span class="p">,</span>
    <span class="s2">&quot;TiDE&quot;</span><span class="p">:</span> <span class="n">model_tide</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</section>
<section id="Model-Training">
<h1>Model Training<a class="headerlink" href="#Model-Training" title="Permalink to this heading">¶</a></h1>
<p>Now let’s train all of the models. When using early stopping it is important to save checkpoints. This allows us to continue past the best model configuration and then restore the optimal weights once training has been completed.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># train the models and load the model from its best state/checkpoint</span>
<span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">series</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
        <span class="n">val_series</span><span class="o">=</span><span class="n">val</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># load from checkpoint returns a new model object, we store it in the models dict</span>
    <span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="n">best</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "1ab2f4e3c6a14b4687d70b402b9920ac", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c8efee5bcaef467499408860f691509d", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="Backtest-the-probabilistic-models">
<h1>Backtest the probabilistic models<a class="headerlink" href="#Backtest-the-probabilistic-models" title="Permalink to this heading">¶</a></h1>
<p>Let’s configure the prediction. For this example, we will:</p>
<ul class="simple">
<li><p>generate <strong>historical forecasts</strong> on the test set using the <strong>pre-trained models</strong>. Each forecast covers a 24 hour horizon, and the time between two consecutive forecasts is also 24 hours. This will give us <strong>276 multivariate forecasts per transformer</strong> to evaluate the model!</p></li>
<li><p>generate <strong>500 stochastic samples</strong> for each prediction point (since we have trained probabilistic models)</p></li>
<li><p>evaluate/<strong>backtest</strong> the probabilistic historical forecasts for some quantiles <strong>using the Mean Quantile Loss</strong> (<code class="docutils literal notranslate"><span class="pre">mql()</span></code>).</p></li>
</ul>
<p>And we’ll create some helper functions to generate the forecasts, compute the backtest, and to visualize the predictions.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># configure the probabilistic prediction</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">forecast_horizon</span> <span class="o">=</span> <span class="n">output_chunk_length</span>

<span class="c1"># compute the Mean Quantile Loss over these quantiles</span>
<span class="n">evaluate_quantiles</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">historical_forecasts</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates probabilistic historical forecasts for each transformer</span>
<span class="sd">    and returns the inverse transformed results.</span>

<span class="sd">    Each forecast covers 24h (forecast_horizon). The time between two forecasts</span>
<span class="sd">    (stride) is also 24 hours.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">hfc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">historical_forecasts</span><span class="p">(</span>
        <span class="n">series</span><span class="o">=</span><span class="n">test</span><span class="p">,</span>
        <span class="n">forecast_horizon</span><span class="o">=</span><span class="n">forecast_horizon</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">forecast_horizon</span><span class="p">,</span>
        <span class="n">last_points_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">retrain</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">hfc</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">backtest</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">hfc</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluates probabilistic historical forecasts using the Mean Quantile</span>
<span class="sd">    Loss (MQL) over a set of quantiles.&quot;&quot;&quot;</span>
    <span class="c1"># add metric specific kwargs</span>
    <span class="n">metric_kwargs</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;q&quot;</span><span class="p">:</span> <span class="n">q</span><span class="p">}</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">evaluate_quantiles</span><span class="p">]</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="n">mql</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">evaluate_quantiles</span><span class="p">))]</span>
    <span class="n">bt</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">backtest</span><span class="p">(</span>
        <span class="n">series</span><span class="o">=</span><span class="n">series</span><span class="p">,</span>
        <span class="n">historical_forecasts</span><span class="o">=</span><span class="n">hfc</span><span class="p">,</span>
        <span class="n">last_points_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
        <span class="n">metric_kwargs</span><span class="o">=</span><span class="n">metric_kwargs</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">bt</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">bt</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;q_</span><span class="si">{</span><span class="n">q</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">evaluate_quantiles</span><span class="p">],</span>
        <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">trafo</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">trafo</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;ETTh1&quot;</span><span class="p">,</span> <span class="s2">&quot;ETTh2&quot;</span><span class="p">]],</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">bt</span>


<span class="k">def</span><span class="w"> </span><span class="nf">generate_plots</span><span class="p">(</span><span class="n">n_days</span><span class="p">,</span> <span class="n">hfcs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot the probabilistic forecasts for each model, transformer and transformer</span>
<span class="sd">    feature against the ground truth.&quot;&quot;&quot;</span>
    <span class="c1"># concatenate historical forecasts into contiguous time series</span>
    <span class="c1"># (works because forecast_horizon=stride)</span>
    <span class="n">hfcs_plot</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">hfc_model</span> <span class="ow">in</span> <span class="n">hfcs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">hfcs_plot</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">concatenate</span><span class="p">(</span><span class="n">hfc_series</span><span class="p">[</span><span class="o">-</span><span class="n">n_days</span><span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">hfc_series</span> <span class="ow">in</span> <span class="n">hfc_model</span>
        <span class="p">]</span>

    <span class="c1"># remember start and end points for plotting the target series</span>
    <span class="n">hfc_</span> <span class="o">=</span> <span class="n">hfcs_plot</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">hfc_</span><span class="o">.</span><span class="n">start_time</span><span class="p">(),</span> <span class="n">hfc_</span><span class="o">.</span><span class="n">end_time</span><span class="p">()</span>

    <span class="c1"># for each target column...</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
        <span class="c1"># ... and for each transformer...</span>
        <span class="k">for</span> <span class="n">trafo_idx</span><span class="p">,</span> <span class="n">trafo</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">series</span><span class="p">):</span>
            <span class="n">trafo</span><span class="p">[</span><span class="n">col</span><span class="p">][</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;ground truth&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">trafo_idx</span><span class="p">])</span>
            <span class="c1"># ... plot the historical forecasts for each model</span>
            <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">hfc</span> <span class="ow">in</span> <span class="n">hfcs_plot</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">hfc</span><span class="p">[</span><span class="n">trafo_idx</span><span class="p">][</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                    <span class="n">label</span><span class="o">=</span><span class="n">model_name</span> <span class="o">+</span> <span class="s2">&quot;_q0.05-q0.95&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">trafo_idx</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">trafo_idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ETTh</span><span class="si">{</span><span class="n">trafo_idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Okay, now we’re ready to evaluate the models</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">bts</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">hfcs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generating historical forecasts..&quot;</span><span class="p">)</span>
    <span class="n">hfcs</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">historical_forecasts</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluating historical forecasts..&quot;</span><span class="p">)</span>
    <span class="n">bts</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">backtest</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">],</span> <span class="n">hfcs</span><span class="p">[</span><span class="n">model_name</span><span class="p">],</span> <span class="n">model_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: TSM
Generating historical forecasts..
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "809ff39dfd7b4192b102d9151b2c1417", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Evaluating historical forecasts..
Model: TiDE
Generating historical forecasts..
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ca2e5b2a7d634d7ea619998ce8a11dd7", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Evaluating historical forecasts..
</pre></div></div>
</div>
<p>Let’s see how they performed.</p>
<blockquote>
<div><p><strong>Note:</strong> These results are likely to improve/change when setting <code class="docutils literal notranslate"><span class="pre">full_training=True</span></code></p>
</div></blockquote>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">bt_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">bts</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
<span class="n">bt_df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>q_0.05</th>
      <th>q_0.1</th>
      <th>q_0.2</th>
      <th>q_0.5</th>
      <th>q_0.8</th>
      <th>q_0.9</th>
      <th>q_0.95</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ETTh1_TSM</th>
      <td>0.501772</td>
      <td>0.769545</td>
      <td>1.136141</td>
      <td>1.568439</td>
      <td>1.098847</td>
      <td>0.721835</td>
      <td>0.442062</td>
    </tr>
    <tr>
      <th>ETTh1_TiDE</th>
      <td>0.573716</td>
      <td>0.885452</td>
      <td>1.298672</td>
      <td>1.671870</td>
      <td>1.151501</td>
      <td>0.727515</td>
      <td>0.446724</td>
    </tr>
    <tr>
      <th>ETTh2_TSM</th>
      <td>0.659187</td>
      <td>1.030655</td>
      <td>1.508628</td>
      <td>1.932923</td>
      <td>1.317960</td>
      <td>0.857147</td>
      <td>0.524620</td>
    </tr>
    <tr>
      <th>ETTh2_TiDE</th>
      <td>0.627251</td>
      <td>0.982114</td>
      <td>1.450893</td>
      <td>1.897117</td>
      <td>1.323661</td>
      <td>0.862239</td>
      <td>0.528638</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>The backtest gives us the Mean Quantile Loss for the selected quantiles over all transformer features per transformer and model. The lower the value, the better. The <code class="docutils literal notranslate"><span class="pre">q_0.5</span></code> is identical to the Mean Absolute Error (MAE) between the median prediction and the ground truth.</p>
<p>Both models seem to have performed comparably well. And how does it look on average over all quantiles?</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">bt_df</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ETTh1_TSM     0.891234
ETTh1_TiDE    0.965064
ETTh2_TSM     1.118732
ETTh2_TiDE    1.095988
dtype: float64
</pre></div></div>
</div>
<p>Here the results are also very similar. It seems that TSMixer performed better for ETTh1, and TiDEModel for ETTh2.</p>
<p>And last but not least, let’s have look at the predictions for the last <code class="docutils literal notranslate"><span class="pre">n_days=3</span></code> days in the test set.</p>
<blockquote>
<div><p>Note: The prediction intervals are expected to get narrower when <code class="docutils literal notranslate"><span class="pre">full_training=True</span></code></p>
</div></blockquote>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">generate_plots</span><span class="p">(</span><span class="n">n_days</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">hfcs</span><span class="o">=</span><span class="n">hfcs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_21-TSMixer-examples_29_0.png" src="../_images/examples_21-TSMixer-examples_29_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_21-TSMixer-examples_29_1.png" src="../_images/examples_21-TSMixer-examples_29_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_21-TSMixer-examples_29_2.png" src="../_images/examples_21-TSMixer-examples_29_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_21-TSMixer-examples_29_3.png" src="../_images/examples_21-TSMixer-examples_29_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_21-TSMixer-examples_29_4.png" src="../_images/examples_21-TSMixer-examples_29_4.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_21-TSMixer-examples_29_5.png" src="../_images/examples_21-TSMixer-examples_29_5.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_21-TSMixer-examples_29_6.png" src="../_images/examples_21-TSMixer-examples_29_6.png" />
</div>
</div>
</section>
<section id="Results">
<h1>Results<a class="headerlink" href="#Results" title="Permalink to this heading">¶</a></h1>
<p>In this case, <code class="docutils literal notranslate"><span class="pre">TSMixer</span></code> and <code class="docutils literal notranslate"><span class="pre">TiDEModel</span></code> both perform similarly well. Keep in mind that we performed only partial training on the data, and that we used the default model parameters without any hyperparameter tuning.</p>
<p>Here are some ways to further improve the performance:</p>
<ul class="simple">
<li><p>set <code class="docutils literal notranslate"><span class="pre">full_training=True</span></code></p></li>
<li><p>perform hyperparameter tuning</p></li>
<li><p>add more covariates (we have only added cyclic encodings of calendar information)</p></li>
<li><p>…</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="18-TiDE-examples.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">TimeSeries Deep Encoder</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="19-EnsembleModel-examples.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Ensembling Models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2020 - 2025, Unit8 SA (Apache 2.0 License).<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.0.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>