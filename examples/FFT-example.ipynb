{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFT Model demonstration\n",
    "#### The following is a brief demonstration of the newly created FFT forecasting model. This model is especially suited for data that is very seasonal. The datasets chosen for this demonstration were selected accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from u8timeseries import TimeSeries\n",
    "from u8timeseries.models import (\n",
    "    FFT,\n",
    "    AutoARIMA,\n",
    "    ExponentialSmoothing,\n",
    "    Prophet,\n",
    "    Theta\n",
    ")\n",
    "from u8timeseries.metrics import mape\n",
    "from u8timeseries.utils.missing_values import auto_fillna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data and fill gaps (you can safely ignore this part, it was not made to look nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series\n",
    "df = pd.read_csv('temps.csv')\n",
    "dates = df['Daily minimum temperatures'].str.replace('^[^\\d]*', '').astype(float)\n",
    "dates.index = pd.to_datetime(df['Date'])\n",
    "\n",
    "# find missing dates\n",
    "delta = pd.date_range(start = '1981-01-01', end = '1990-12-31' ).difference(dates.index)\n",
    "\n",
    "# add missing dates\n",
    "delta_vals = pd.Series([np.mean(dates)] * len(delta))\n",
    "delta_vals.index = delta\n",
    "dates = dates.append(delta_vals)\n",
    "dates = dates.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing our TimeSeries instance and a train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TimeSeries.from_times_and_values(dates.index, dates)\n",
    "train, val = ts.split_after(pd.Timestamp('19850701'))\n",
    "train.plot()\n",
    "val.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic FFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFT(required_matches=set(), nr_freqs_to_keep=None)\n",
    "model.fit(train)\n",
    "pred_val = model.predict(len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "#### The plot below shows us that a simple DFT with a random train-test split will most likely lead to bad results. Upon closer inspection we can see that the prediction (in green) simply repeats the training set (blue). This is the standard behavior of the DFT, and by itself it is quite useless, since repeating our training set could be done much more efficiently. Two improvements were made to this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot()\n",
    "val.plot()\n",
    "pred_val.plot()\n",
    "print(\"MAPE:\", mape(pred_val, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement 1: Crop the training set\n",
    "#### The first improvement consists of cropping the training set before feeding it to the FFT algorithm such that the first timestamp in the cropped series matches the first timestamp to be predicted in terms of seasonality, i.e. it has the same month, day, weekday, time of day, etc. We can achieve this by passing the optional argument 'required_matches' to the FFT constructor that explicitly tells our model which timestamp attributes are relevant. If we don't set it manually, the model will attempt to automatically find the pd.Timestamp attributes that are relevant and crop the training set accordingly (which we will do here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFT(nr_freqs_to_keep=None)\n",
    "model.fit(train)\n",
    "pred_val = model.predict(len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "#### We can see that the results look like the seasonality of the predictions nicely aligns with the seasonality of the validation set. However, we are still just repeating the training set, including all of the noise. Looking at the error we can see that this is still a very bad forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot()\n",
    "val.plot()\n",
    "pred_val.plot()\n",
    "print(\"MAPE:\", mape(pred_val, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement 2: Filtering out low-amplitude waves\n",
    "#### The decomposition of the DFT into the frequency domain allows us to selectively filter out waves with low amplitudes. This allows us to keep strong seasonal trends while discarding some noise. This is achieved in the FFT model by passing the optional argument 'filter_first_n'. This argument represents the total number of frequencies that will be kept. For instance, if a value of 20 is passed, only the 20 frequencies with the highest amplitudes will be utilized. The default value is set to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFT(nr_freqs_to_keep=20)\n",
    "model.fit(train)\n",
    "pred_val = model.predict(len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "#### We get a signal that is less noisy. Depending on the data set, this might be a better forecast. Looking at the error metric, we can see that this model performs significantly better than the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot()\n",
    "val.plot()\n",
    "pred_val.plot()\n",
    "print(\"MAPE:\", mape(pred_val, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Data: Monthly Air Passengers\n",
    "#### Let's try out a different data set that has a global upward trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AirPassengers.csv', delimiter=\",\")\n",
    "ts_2 = TimeSeries.from_dataframe(df, 'Month', '#Passengers')\n",
    "train, val = ts_2.split_after(pd.Timestamp('19551201'))\n",
    "train.plot()\n",
    "val.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFT()\n",
    "model.fit(train)\n",
    "pred_val = model.predict(len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clearly, our model fails completely at incorporating the upward trend. Due to the trend, our model also fails to recognize the monthly seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot()\n",
    "val.plot()\n",
    "pred_val.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This problem can be solved by setting the optional trend argument to either 'poly' or 'exp', which fits a polynomial or exponential funtion to the data and subtracts it before moving on to DFT. When predicting, the trend is added again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFT(trend='poly')\n",
    "model.fit(train)\n",
    "pred_val = model.predict(len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "#### We have a much better prediction now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot()\n",
    "val.plot()\n",
    "pred_val.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Data: Hourly Nuclear Energy Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('energy_dataset.csv', delimiter=\",\")\n",
    "df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "df['time']= df.time.dt.tz_localize(None)\n",
    "\n",
    "ts_3 = TimeSeries.from_dataframe(df, 'time', 'generation nuclear')\n",
    "ts_3 = auto_fillna(ts_3)\n",
    "train, val = ts_3.split_after(pd.Timestamp('2017-07-01'))\n",
    "train.plot()\n",
    "val.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting Performance:\n",
    "#### Instead of simply looking at the performance of the FFT model, l decided to look at how each of the currently implemented forecasting models performs on this new data set in terms of MAPE. Surprisingly, on this dataset, the FFT model outperforms all of the others. Granted, this dataset was specifically chosen because of its highly seasonal nature. However, this shows us that there definitely are use cases for FFT. Furthermore, the FFT model has a much shorter running time than the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    AutoARIMA(),\n",
    "    Prophet(),\n",
    "    ExponentialSmoothing(),\n",
    "    Theta(),\n",
    "    FFT()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(train)\n",
    "    pred_val = model.predict(len(val))\n",
    "    print(str(model) + \" MAPE: \" + str(mape(pred_val, val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
