
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>&lt;no title&gt; &#8212; darts  documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../_static/docs-favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Facebook Prophet" href="darts.models.forecasting.prophet_model.html" />
    <link rel="prev" title="N-Linear" href="darts.models.forecasting.nlinear.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/darts-logo-trim.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../README.html">
  Home
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../quickstart/00-quickstart.html">
  Quickstart
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../userguide.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="darts.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../examples.html">
  Examples
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/unit8co/darts" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/unit8co" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.ad.html">
   Anomaly Detection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.ad.aggregators.html">
     Anomaly Aggregators
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.aggregators.and_aggregator.html">
       AND Aggregator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.aggregators.ensemble_sklearn_aggregator.html">
       Ensemble scikit-learn aggregator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.aggregators.or_aggregator.html">
       OR Aggregator
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.ad.anomaly_model.html">
     Anomaly Models
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.anomaly_model.filtering_am.html">
       Filtering Anomaly Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.anomaly_model.forecasting_am.html">
       Forecasting Anomaly Model
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.ad.detectors.html">
     Anomaly Detectors
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.detectors.quantile_detector.html">
       Quantile Detector
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.detectors.threshold_detector.html">
       Threshold Detector
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.ad.scorers.html">
     Anomaly Scorers
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.difference_scorer.html">
       Difference Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.kmeans_scorer.html">
       k-means Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_cauchy_scorer.html">
       NLL Cauchy Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_exponential_scorer.html">
       NLL Exponential Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_gamma_scorer.html">
       NLL Gamma Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_gaussian_scorer.html">
       NLL Gaussian Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_laplace_scorer.html">
       NLL Laplace Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_poisson_scorer.html">
       NLL Poisson Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.norm_scorer.html">
       Norm Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.pyod_scorer.html">
       PyODScorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.wasserstein_scorer.html">
       WassersteinScorer
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.ad.utils.html">
     Utils for Anomaly Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.dataprocessing.html">
   Data Processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.dataprocessing.dtw.html">
     Dynamic Time Warping (DTW)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.dtw.dtw.html">
       Dynamic Time Warping (DTW)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.dtw.window.html">
       DTW Windows
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.dataprocessing.encoders.html">
     Time Axis Encoders
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.encoders.encoder_base.html">
       Encoder Base Classes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.encoders.encoders.html">
       Time Axes Encoders
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.dataprocessing.transformers.html">
     Data Transformers
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.base_data_transformer.html">
       Data Transformer Base Class
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.boxcox.html">
       Box-Cox Transformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.diff.html">
       Differencing Transformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.fittable_data_transformer.html">
       Fittable Data Transformer Base Class
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.invertible_data_transformer.html">
       Invertible Data Transformer Base Class
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.mappers.html">
       Mapper and InvertibleMapper
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.midas.html">
       Mixed-data sampling (MIDAS) Transformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.missing_values_filler.html">
       Missing Values Filler
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.reconciliation.html">
       Hierarchical Reconciliation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.scaler.html">
       Scaler
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.static_covariates_transformer.html">
       Static Covariates Transformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.window_transformer.html">
       Window Transformer
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.dataprocessing.pipeline.html">
     Pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.datasets.html">
   Datasets
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.explainability.html">
   Explainability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.explainability.explainability_result.html">
     Explainability Result
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.explainability.shap_explainer.html">
     Shap Explainer for RegressionModels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.explainability.tft_explainer.html">
     TFT Explainer for Temporal Fusion Transformer (TFTModel)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.metrics.html">
   Metrics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.metrics.metrics.html">
     Metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.models.html">
   Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.models.filtering.html">
     Filtering Models
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.filtering.gaussian_process_filter.html">
       Gaussian Processes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.filtering.kalman_filter.html">
       Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.filtering.moving_average_filter.html">
       Moving Average
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.models.forecasting.html">
     Forecasting Models
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.arima.html">
       ARIMA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.auto_arima.html">
       AutoARIMA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.baselines.html">
       Baseline Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.block_rnn_model.html">
       Block Recurrent Neural Networks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.catboost_model.html">
       CatBoost model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.croston.html">
       Croston method
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.dlinear.html">
       D-Linear
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.exponential_smoothing.html">
       Exponential Smoothing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.fft.html">
       Fast Fourier Transform
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.kalman_forecaster.html">
       Kalman Filter Forecaster
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.lgbm.html">
       LightGBM Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.linear_regression_model.html">
       Linear Regression model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.nbeats.html">
       N-BEATS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.nhits.html">
       N-HiTS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.nlinear.html">
       N-Linear
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.prophet_model.html">
       Facebook Prophet
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.random_forest.html">
       Random Forest
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.regression_ensemble_model.html">
       Regression ensemble model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.regression_model.html">
       Regression Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.rnn_model.html">
       Recurrent Neural Networks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.sf_auto_arima.html">
       StatsForecastAutoARIMA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.sf_auto_ces.html">
       StatsForecastAutoCES
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.sf_auto_ets.html">
       StatsForecastAutoETS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.sf_auto_theta.html">
       StatsForecastAutoTheta
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.tbats_model.html">
       BATS and TBATS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.tcn_model.html">
       Temporal Convolutional Network
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.tft_model.html">
       Temporal Fusion Transformer (TFT)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.theta.html">
       Theta Method
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.tide_model.html">
       Time-series Dense Encoder (TiDE)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.transformer_model.html">
       Transformer Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.varima.html">
       VARIMA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.xgboost.html">
       XGBoost Model
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.utils.html">
   Utils
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.utils.data.html">
     TimeSeries Datasets
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.utils.data.horizon_based_dataset.html">
       Horizon-Based Training Dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.utils.data.inference_dataset.html">
       Inference Dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.utils.data.sequential_dataset.html">
       Sequential Training Dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.utils.data.shifted_dataset.html">
       Shifted Training Dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.utils.data.training_dataset.html">
       Training Datasets Base Classes
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.likelihood_models.html">
     Likelihood Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.losses.html">
     PyTorch Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.missing_values.html">
     Utils for filling missing values
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.model_selection.html">
     Model selection utilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.statistics.html">
     Time Series Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.timeseries_generation.html">
     Utils for time series generation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.torch.html">
     Utils for Pytorch and its usage
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.utils.html">
     Additional util functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="darts.timeseries.html">
   Timeseries
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="simple visible nav section-nav flex-column">
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <span class="target" id="module-darts.models.forecasting.pl_forecasting_module"></span><p>This file contains abstract classes for deterministic and probabilistic PyTorch Lightning Modules</p>
<dl class="py class">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">darts.models.forecasting.pl_forecasting_module.</span></span><span class="sig-name descname"><span class="pre">PLDualCovariatesModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_sample_shape=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn=MSELoss()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_metrics=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_cls=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_cls=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_reversible_instance_norm=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLDualCovariatesModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">darts.models.forecasting.pl_forecasting_module.PLForecastingModule</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>PyTorch Lightning-based Forecasting Module.</p>
<p>This class is meant to be inherited to create a new PyTorch Lightning-based forecasting module.
When subclassing this class, please make sure to add the following methods with the given signatures:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.__init__()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.forward()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._produce_train_output()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._get_batch_prediction()</span></code></p></li>
</ul>
</div></blockquote>
<p>In subclass <cite>MyModel</cite>’s <code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code> function call <code class="docutils literal notranslate"><span class="pre">super(MyModel,</span> <span class="pre">self).__init__(**kwargs)</span></code> where
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> are the parameters of <code class="xref py py-class docutils literal notranslate"><span class="pre">PLTorchForecastingModel</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps in the past to take as a model input (per chunk). Applies to the target
series, and past and/or future covariates (if the model supports it).</p></li>
<li><p><strong>output_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps predicted at once (per chunk) by the internal model. Also, the number of future values
from future covariates to use as a model input (if the model supports future covariates). It is not the same
as forecast horizon <cite>n</cite> used in <cite>predict()</cite>, which is the desired number of prediction points generated
using either a one-shot- or auto-regressive forecast. Setting <cite>n &lt;= output_chunk_length</cite> prevents
auto-regression. This is useful when the covariates don’t extend far enough into the future, or to prohibit
the model from using future values of past and / or future covariates for prediction (depending on the
model’s covariate support).</p></li>
<li><p><strong>train_sample_shape</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Shape of the model’s input, used to instantiate model without calling <code class="docutils literal notranslate"><span class="pre">fit_from_dataset</span></code> and
perform sanity check on new training/inference datasets used for re-training or prediction.</p></li>
<li><p><strong>loss_fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code>) – PyTorch loss function used for training.
This parameter will be ignored for probabilistic models if the <code class="docutils literal notranslate"><span class="pre">likelihood</span></code> parameter is specified.
Default: <code class="docutils literal notranslate"><span class="pre">torch.nn.MSELoss()</span></code>.</p></li>
<li><p><strong>torch_metrics</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – A torch metric or a <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code> used for evaluation. A full list of available metrics can be found
at <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/">https://torchmetrics.readthedocs.io/en/latest/</a>. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>likelihood</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code></a>]) – One of Darts’ <a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Likelihood</span></code></a> models to be used for
probabilistic forecasts. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>optimizer_cls</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The PyTorch optimizer class to be used. Default: <code class="docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code>.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch optimizer (e.g., <code class="docutils literal notranslate"><span class="pre">{'lr':</span> <span class="pre">1e-3}</span></code>
for specifying a learning rate). Otherwise the default values of the selected <code class="docutils literal notranslate"><span class="pre">optimizer_cls</span></code>
will be used. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_cls</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_LRScheduler</span></code>]) – Optionally, the PyTorch learning rate scheduler class to be used. Specifying <code class="docutils literal notranslate"><span class="pre">None</span></code> corresponds
to using a constant learning rate. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch learning rate scheduler. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>use_reversible_instance_norm</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to use reversible instance normalization <cite>RINorm</cite> against distribution shift as shown in <a class="reference internal" href="#r4e8a8bfbd3c9-1" id="id1">[1]</a>.
It is only applied to the features of the target series and not the covariates.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r4e8a8bfbd3c9-1"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>T. Kim et al. “Reversible Instance Normalization for Accurate Time-Series Forecasting against
Distribution Shift”, <a class="reference external" href="https://openreview.net/forum?id=cGDAkQo1C0p">https://openreview.net/forum?id=cGDAkQo1C0p</a></p>
</dd>
</dl>
<p class="rubric">Attributes</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.automatic_optimization" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.automatic_optimization"><code class="xref py py-obj docutils literal notranslate"><span class="pre">automatic_optimization</span></code></a></p></td>
<td><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.current_epoch" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.current_epoch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">current_epoch</span></code></a></p></td>
<td><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.example_input_array"><code class="xref py py-obj docutils literal notranslate"><span class="pre">example_input_array</span></code></a></p></td>
<td><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.global_rank" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.global_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_rank</span></code></a></p></td>
<td><p>The index of the current process across all nodes and devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.global_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.global_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_step</span></code></a></p></td>
<td><p>Total training batches seen across all epochs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams_initial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams_initial</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.local_rank" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.local_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">local_rank</span></code></a></p></td>
<td><p>The index of the current process within a single node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.logger" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.logger"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logger</span></code></a></p></td>
<td><p>Reference to the logger object in the Trainer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.loggers" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.loggers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">loggers</span></code></a></p></td>
<td><p>Reference to the list of loggers in the Trainer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_gpu" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_gpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_gpu</span></code></a></p></td>
<td><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.output_chunk_length" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.output_chunk_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_chunk_length</span></code></a></p></td>
<td><p>Number of time steps predicted at once by the model.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>device</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>dtype</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>epochs_trained</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>fabric</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>trainer</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.add_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_module</span></code></a>(name, module)</p></td>
<td><p>Adds a child module to the current module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.all_gather" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.all_gather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">all_gather</span></code></a>(data[, group, sync_grads])</p></td>
<td><p>Gather tensors or collections of tensors from multiple processes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.apply" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.backward" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.bfloat16" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.bfloat16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfloat16</span></code></a>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.buffers" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">buffers</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.children" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.clip_gradients" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.clip_gradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip_gradients</span></code></a>(optimizer[, ...])</p></td>
<td><p>Handles gradient clipping internally.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.compile" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(*args, **kwargs)</p></td>
<td><p>Compile this Module's forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_callbacks" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_callbacks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_callbacks</span></code></a>()</p></td>
<td><p>Configure model-specific callbacks.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_gradient_clipping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_gradient_clipping</span></code></a>(optimizer[, ...])</p></td>
<td><p>Perform gradient clipping for the optimizer parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_model" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_model</span></code></a>()</p></td>
<td><p>Hook to create modules in a strategy and precision aware context.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_optimizers" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_optimizers</span></code></a>()</p></td>
<td><p>configures optimizers and learning rate schedulers for model optimization.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_sharded_model" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_sharded_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_sharded_model</span></code></a>()</p></td>
<td><p>Deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_torch_metrics" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_torch_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_torch_metrics</span></code></a>(torch_metrics)</p></td>
<td><p>process the torch_metrics parameter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cpu" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cuda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.double" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.double"><code class="xref py py-obj docutils literal notranslate"><span class="pre">double</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.eval" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code></a>()</p></td>
<td><p>Sets the module in evaluation mode.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.extra_repr" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.extra_repr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extra_repr</span></code></a>()</p></td>
<td><p>Set the extra representation of the module</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(*args, **kwargs)</p></td>
<td><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.freeze" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.freeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">freeze</span></code></a>()</p></td>
<td><p>Freeze all params for inference.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_buffer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_buffer</span></code></a>(target)</p></td>
<td><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_extra_state</span></code></a>()</p></td>
<td><p>Returns any extra state to include in the module's state_dict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_parameter" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_parameter</span></code></a>(target)</p></td>
<td><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_submodule" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_submodule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_submodule</span></code></a>(target)</p></td>
<td><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.half" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.half"><code class="xref py py-obj docutils literal notranslate"><span class="pre">half</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.ipu" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.ipu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ipu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the IPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_from_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_from_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code></a>([map_location, ...])</p></td>
<td><p>Primary way of loading a model from a checkpoint.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>(state_dict[, strict, assign])</p></td>
<td><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.log" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log</span></code></a>(name, value[, prog_bar, logger, ...])</p></td>
<td><p>Log a key, value pair.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.log_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.log_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_dict</span></code></a>(dictionary[, prog_bar, logger, ...])</p></td>
<td><p>Log a dictionary of values at once.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.lr_scheduler_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.lr_scheduler_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_scheduler_step</span></code></a>(scheduler, metric)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls each scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.lr_schedulers" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.lr_schedulers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_schedulers</span></code></a>()</p></td>
<td><p>Returns the learning rate scheduler(s) that are being used during training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.manual_backward" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.manual_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">manual_backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.modules" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">modules</span></code></a>()</p></td>
<td><p>Returns an iterator over all modules in the network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_buffers" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_buffers</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_children" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_modules" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_modules</span></code></a>([memo, prefix, remove_duplicate])</p></td>
<td><p>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_parameters" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_after_backward" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_after_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_backward</span></code></a>()</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_after_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_backward" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_backward</span></code></a>(loss)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code></a>(optimizer)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_zero_grad</span></code></a>(optimizer)</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_fit_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_fit_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_end</span></code></a>()</p></td>
<td><p>Called at the very end of fit.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_fit_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_fit_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_start</span></code></a>()</p></td>
<td><p>Called at the very beginning of fit.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_load_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_load_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_load_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning to restore your model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the predict loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the predict loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the predict loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_save_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_save_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to save.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the test loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the test loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_end</span></code></a>()</p></td>
<td><p>Called at the end of testing.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_end</span></code></a>()</p></td>
<td><p>Called in the test loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_start</span></code></a>()</p></td>
<td><p>Called in the test loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the test loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_model_train" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the test loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_start</span></code></a>()</p></td>
<td><p>Called at the beginning of testing.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the training loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the training loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_end</span></code></a>()</p></td>
<td><p>Called at the end of training before logger experiment is closed.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_end</span></code></a>()</p></td>
<td><p>Called in the training loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_start</span></code></a>()</p></td>
<td><p>Called in the training loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_start</span></code></a>()</p></td>
<td><p>Called at the beginning of training after sanity check.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_end</span></code></a>(outputs, batch, ...)</p></td>
<td><p>Called in the validation loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the validation loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_end</span></code></a>()</p></td>
<td><p>Called at the end of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_end</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_start</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the val loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_train" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the val loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_zero_grad</span></code></a>()</p></td>
<td><p>Called by the training loop to release gradients before entering the validation loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_start" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_start</span></code></a>()</p></td>
<td><p>Called at the beginning of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_step</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls the optimizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizer_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizer_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_zero_grad</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizers" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizers</span></code></a>([use_pl_optimizer])</p></td>
<td><p>Returns the optimizer(s) that are being used during training.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.parameters" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.predict_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.predict_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying prediction samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.predict_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.predict_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_step</span></code></a>(batch, batch_idx[, dataloader_idx])</p></td>
<td><p>performs the prediction step</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare_data</span></code></a>()</p></td>
<td><p>Use this to download and prepare data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.print" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.print"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print</span></code></a>(*args, **kwargs)</p></td>
<td><p>Prints only from process 0.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_backward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_buffer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_buffer</span></code></a>(name, tensor[, persistent])</p></td>
<td><p>Adds a buffer to the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_forward_hook" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook, *[, prepend, ...])</p></td>
<td><p>Registers a forward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_forward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook, *[, ...])</p></td>
<td><p>Registers a forward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_full_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_full_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_full_backward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_full_backward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_pre_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_load_state_dict_post_hook" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_load_state_dict_post_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_load_state_dict_post_hook</span></code></a>(hook)</p></td>
<td><p>Registers a post hook to be run after module's <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> is called.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_module" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_module</span></code></a>(name, module)</p></td>
<td><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_parameter" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_parameter</span></code></a>(name, param)</p></td>
<td><p>Adds a parameter to the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_state_dict_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_state_dict_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_state_dict_pre_hook</span></code></a>(hook)</p></td>
<td><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>, and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.requires_grad_" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.requires_grad_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad_</span></code></a>([requires_grad])</p></td>
<td><p>Change if autograd should record operations on parameters in this module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_hyperparameters</span></code></a>(*args[, ignore, frame, ...])</p></td>
<td><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_extra_state</span></code></a>(state)</p></td>
<td><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state found within the <cite>state_dict</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_predict_parameters" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_predict_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_predict_parameters</span></code></a>(n, num_samples, ...)</p></td>
<td><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>(stage)</p></td>
<td><p>Called at the beginning of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.share_memory" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.share_memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_memory</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code></a>(*args[, destination, prefix, ...])</p></td>
<td><p>Returns a dictionary containing references to the whole state of the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.teardown" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.teardown"><code class="xref py py-obj docutils literal notranslate"><span class="pre">teardown</span></code></a>(stage)</p></td>
<td><p>Called at the end of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying test samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_step</span></code></a>(*args, **kwargs)</p></td>
<td><p>Operates on a single batch of data from the test set.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_dtype" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_dtype</span></code></a>(dtype)</p></td>
<td><p>Cast module precision (float32 by default) to another precision.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_empty" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_empty</span></code></a>(*, device[, recurse])</p></td>
<td><p>Moves the parameters and buffers to the specified device without copying storage.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_onnx" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_onnx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_onnx</span></code></a>(file_path[, input_sample])</p></td>
<td><p>Saves the model in ONNX format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_torchscript" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_torchscript"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_torchscript</span></code></a>([file_path, method, ...])</p></td>
<td><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.toggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">toggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Makes sure only the gradients of the current optimizer's parameters are calculated in the training step to prevent dangling gradients in multiple-optimizer setup.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.train" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>([mode])</p></td>
<td><p>Sets the module in training mode.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.train_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.train_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying training samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">training_step</span></code></a>(train_batch, batch_idx)</p></td>
<td><p>performs the training step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.transfer_batch_to_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transfer_batch_to_device</span></code></a>(batch, device, ...)</p></td>
<td><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data structure.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.type" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code></a>(dst_type)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.unfreeze" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.unfreeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unfreeze</span></code></a>()</p></td>
<td><p>Unfreeze all parameters for training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.untoggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">untoggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.val_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.val_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">val_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying validation samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.validation_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">validation_step</span></code></a>(val_batch, batch_idx)</p></td>
<td><p>performs the validation step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.xpu" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.xpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xpu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the XPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>([set_to_none])</p></td>
<td><p>Resets gradients of all model parameters.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>__call__</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_mc_dropout</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.CHECKPOINT_HYPER_PARAMS_KEY">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_KEY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hyper_parameters'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.CHECKPOINT_HYPER_PARAMS_KEY" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.CHECKPOINT_HYPER_PARAMS_NAME">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_name'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.CHECKPOINT_HYPER_PARAMS_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.CHECKPOINT_HYPER_PARAMS_TYPE">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_TYPE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_type'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.CHECKPOINT_HYPER_PARAMS_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.T_destination">
<span class="sig-name descname"><span class="pre">T_destination</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.T_destination" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of TypeVar(‘T_destination’, bound=<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>])</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.add_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the child module. The child module can be
accessed from this module using the given name</p></li>
<li><p><strong>module</strong> (<em>Module</em>) – child module to be added to the module.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.all_gather">
<span class="sig-name descname"><span class="pre">all_gather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.all_gather" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather tensors or collections of tensors from multiple processes.</p>
<p>This method needs to be called on all processes and the tensors need to have the same shape across all
processes, otherwise your program will stall forever.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – int, float, tensor of shape (batch, …), or a (possibly nested) collection thereof.</p></li>
<li><p><strong>group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the process group to gather results from. Defaults to all processes (world)</p></li>
<li><p><strong>sync_grads</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – flag that allows users to synchronize gradients for the all_gather operation</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor of shape (world_size, batch, …), or if the input was a collection
the output will also be a collection with tensors of this shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>)
as well as self. Typical use includes initializing the parameters of a model
(see also <span class="xref std std-ref">nn-init-doc</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> -&gt; None) – function to be applied to each submodule</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.automatic_optimization">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">automatic_optimization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.automatic_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. Override this hook with your own
implementation if you need to.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The loss tensor returned by <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. If gradient accumulation is used, the loss here
holds the normalized value (scaled by 1 / accumulation steps).</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.bfloat16">
<span class="sig-name descname"><span class="pre">bfloat16</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.bfloat16" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.buffers">
<span class="sig-name descname"><span class="pre">buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – module buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.call_super_init">
<span class="sig-name descname"><span class="pre">call_super_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.call_super_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a child module</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.clip_gradients">
<span class="sig-name descname"><span class="pre">clip_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.clip_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Handles gradient clipping internally.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Do not override this method. If you want to customize gradient clipping, consider using
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_gradient_clipping"><code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_gradient_clipping()</span></code></a> method.</p></li>
<li><p>For manual optimization (<code class="docutils literal notranslate"><span class="pre">self.automatic_optimization</span> <span class="pre">=</span> <span class="pre">False</span></code>), if you want to use
gradient clipping, consider calling
<code class="docutils literal notranslate"><span class="pre">self.clip_gradients(opt,</span> <span class="pre">gradient_clip_val=0.5,</span> <span class="pre">gradient_clip_algorithm=&quot;norm&quot;)</span></code>
manually in the training step.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. Pass <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;value&quot;</span></code>
to clip by value, and <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;norm&quot;</span></code> to clip by norm.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.compile" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile this Module’s forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>This Module’s <cite>__call__</cite> method is compiled and all arguments are passed as-is
to <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>See <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code> for details on the arguments for this function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_callbacks">
<span class="sig-name descname"><span class="pre">configure_callbacks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_callbacks" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure model-specific callbacks. When the model gets attached, e.g., when <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> or <code class="docutils literal notranslate"><span class="pre">.test()</span></code> gets
called, the list or a callback returned here will be merged with the list of callbacks passed to the Trainer’s
<code class="docutils literal notranslate"><span class="pre">callbacks</span></code> argument. If a callback returned here has the same type as one or several callbacks already
present in the Trainer’s callbacks list, it will take priority and replace them. In addition, Lightning will
make sure <code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> callbacks run last.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A callback or a list of callbacks which will extend the list of callbacks in the Trainer.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">early_stop</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_gradient_clipping">
<span class="sig-name descname"><span class="pre">configure_gradient_clipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_gradient_clipping" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform gradient clipping for the optimizer parameters. Called before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizer_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients. By default, value passed in Trainer
will be available here.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. By default, value
passed in Trainer will be available here.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_gradient_clipping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="p">,</span> <span class="n">gradient_clip_algorithm</span><span class="p">):</span>
    <span class="c1"># Implement your own custom logic to clip gradients</span>
    <span class="c1"># You can call `self.clip_gradients` with your settings:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="o">=</span><span class="n">gradient_clip_val</span><span class="p">,</span>
        <span class="n">gradient_clip_algorithm</span><span class="o">=</span><span class="n">gradient_clip_algorithm</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_model">
<span class="sig-name descname"><span class="pre">configure_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook to create modules in a strategy and precision aware context.</p>
<p>This is particularly useful for when using sharded strategies (FSDP and DeepSpeed), where we’d like to shard
the model instantly to save memory and initialization time.
For non-sharded strategies, you can choose to override this hook or to initialize your model under the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">init_module()</span></code> context manager.</p>
<p>This hook is called during each of fit/val/test/predict stages in the same process, so ensure that
implementation of this hook is idempotent.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>configures optimizers and learning rate schedulers for model optimization.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_sharded_model">
<span class="sig-name descname"><span class="pre">configure_sharded_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_sharded_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Deprecated.</p>
<p>Use <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_model()</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_torch_metrics">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">configure_torch_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">torch_metrics</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.configure_torch_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>process the torch_metrics parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cuda" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the GPU. This also makes associated parameters and buffers
different objects. So it should be called before constructing optimizer if the module will live on GPU while
being optimized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If specified, all parameters will be copied to that device. If <cite>None</cite>, the current CUDA device
index will be used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.current_epoch">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">current_epoch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.current_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.device</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.device" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.double" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.dtype</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.dtype" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dtype</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.dump_patches">
<span class="sig-name descname"><span class="pre">dump_patches</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.dump_patches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.epochs_trained">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">epochs_trained</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.epochs_trained" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code>.</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.eval()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.example_input_array">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">example_input_array</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.example_input_array" title="Permalink to this definition">¶</a></dt>
<dd><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method. The
return type is interpreted as follows:</p>
<ul class="simple">
<li><p>Single tensor: It is assumed the model takes a single argument, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(model.example_input_array)</span></code></p></li>
<li><p>Tuple: The input array should be interpreted as a sequence of positional arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(*model.example_input_array)</span></code></p></li>
<li><p>Dict: The input array represents named keyword arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(**model.example_input_array)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.fabric">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fabric</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.fabric.Fabric</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.fabric" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fabric</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Whatever you decide to pass into the forward method.</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments are also possible.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Your model’s output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.freeze">
<span class="sig-name descname"><span class="pre">freeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze all params for inference.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the buffer
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The buffer referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not a
buffer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns any extra state to include in the module’s state_dict.
Implement this and a corresponding <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_extra_state()</span></code></a> for your module
if you need to store extra state. This function is called when building the
module’s <cite>state_dict()</cite>.</p>
<p>Note that extra state should be picklable to ensure working serialization
of the state_dict. We only provide provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Any extra state to store in the module’s state_dict</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_parameter">
<span class="sig-name descname"><span class="pre">get_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the Parameter
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Parameter referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To check whether or not we have the <code class="docutils literal notranslate"><span class="pre">linear</span></code> submodule, we
would call <code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.linear&quot;)</span></code>. To check whether
we have the <code class="docutils literal notranslate"><span class="pre">conv</span></code> submodule, we would call
<code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.net_c.conv&quot;)</span></code>.</p>
<p>The runtime of <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> is bounded by the degree
of module nesting in <code class="docutils literal notranslate"><span class="pre">target</span></code>. A query against
<code class="docutils literal notranslate"><span class="pre">named_modules</span></code> achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists, <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> should always be
used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The submodule referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.global_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.global_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process across all nodes and devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.global_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.global_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Total training batches seen across all epochs.</p>
<p>If no Trainer is attached, this propery is 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.half" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">MutableMapping</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. It is mutable by the user. For
the frozen set of initial hyperparameters, use <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams_initial"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams_initial</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">AttributeDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MutableMapping</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mutable hyperparameters dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams_initial">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams_initial</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams_initial" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. These contents are read-only.
Manual updates to the saved hyperparameters can instead be performed through <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.hparams"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>immutable initial hyperparameters</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>AttributeDict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.ipu">
<span class="sig-name descname"><span class="pre">ipu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.ipu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the IPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on IPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_from_checkpoint">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_from_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments
passed to <code class="docutils literal notranslate"><span class="pre">__init__</span></code>  in the checkpoint under <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<p>Any arguments specified through **kwargs will override args stored in <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">IO</span></code>]) – Path to checkpoint. This can also be a URL, or file-like object</p></li>
<li><p><strong>map_location</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If your checkpoint saved a GPU model and you now load on CPUs
or a different number of GPUs, use this to map to the new setup.
The behaviour is the same as in <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code>.</p></li>
<li><p><strong>hparams_file</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optional path to a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> or <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file with hierarchical structure
as in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">drop_prob</span><span class="p">:</span> <span class="mf">0.2</span>
<span class="n">dataloader</span><span class="p">:</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="mi">32</span>
</pre></div>
</div>
<p>You most likely won’t need this since Lightning will always save the hyperparameters
to the checkpoint.
However, if your checkpoint weights don’t have the hyperparameters saved,
use this method to pass in a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file with the hparams you’d like to use.
These will be converted into a <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> and passed into your
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> for use.</p>
<p>If your model’s <code class="docutils literal notranslate"><span class="pre">hparams</span></code> argument is <code class="xref py py-class docutils literal notranslate"><span class="pre">Namespace</span></code>
and <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file has hierarchical structure, you need to refactor your model to treat
<code class="docutils literal notranslate"><span class="pre">hparams</span></code> as <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>.</p>
</p></li>
<li><p><strong>strict</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to strictly enforce that the keys in <code class="xref py py-attr docutils literal notranslate"><span class="pre">checkpoint_path</span></code> match the keys
returned by this module’s state dict.</p></li>
<li><p><strong>**kwargs</strong> – Any extra keyword args needed to init the model. Can also be used to override saved
hyperparameter values.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance with loaded weights and hyperparameters (if available).</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code> is a <strong>class</strong> method. You should use your <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code>
<strong>class</strong> to call it instead of the <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance, or a
<code class="docutils literal notranslate"><span class="pre">TypeError</span></code> will be raised.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load weights without mapping ...</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">)</span>

<span class="c1"># or load weights mapping all weights from GPU 1 to GPU 0 ...</span>
<span class="n">map_location</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span>
<span class="p">)</span>

<span class="c1"># or load weights and hyperparameters from separate files.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">hparams_file</span><span class="o">=</span><span class="s1">&#39;/path/to/hparams_file.yaml&#39;</span>
<span class="p">)</span>

<span class="c1"># override some of the params with new values</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="n">PATH</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">pretrained_ckpt_path</span><span class="o">=</span><span class="n">NEW_PATH</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># predict</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">pretrained_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into
this module and its descendants. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> the optimizer must be created after
the call to <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>dict</em>) – a dict containing parameters and
persistent buffers.</p></li>
<li><p><strong>strict</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to strictly enforce that the keys
in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this module’s
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>assign</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to assign items in the state
dictionary to their corresponding keys in the module instead
of copying them inplace into the module’s current parameters and buffers.
When <code class="docutils literal notranslate"><span class="pre">False</span></code>, the properties of the tensors in the current
module are preserved while when <code class="docutils literal notranslate"><span class="pre">True</span></code>, the properties of the
Tensors in the state dict are preserved.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>missing_keys</strong> is a list of str containing the missing keys</p></li>
<li><p><strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a parameter or buffer is registered as <code class="docutils literal notranslate"><span class="pre">None</span></code> and its corresponding key
exists in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> will raise a
<code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code>.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.local_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">local_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.local_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process within a single node.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_attribute</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a key, value pair.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>The default behavior per hook is documented here: <span class="xref std std-ref">extensions/logging:Automatic Logging</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – key to log.</p></li>
<li><p><strong>value</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]) – value to log. Can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, or a <code class="docutils literal notranslate"><span class="pre">Metric</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress bar.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto detach the graph.</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across devices. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the DDP group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple dataloaders). If False, user needs to give unique names for
each dataloader to not mix the values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch_size. This will be directly inferred from the loaded batch,
but for some data structures you might need to explicitly provide it.</p></li>
<li><p><strong>metric_attribute</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – To restore the metric state, Lightning requires the reference of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code> in your model. This is found automatically if it is a model attribute.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.log_dict">
<span class="sig-name descname"><span class="pre">log_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dictionary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.log_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a dictionary of values at once.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="s1">&#39;metric_n&#39;</span><span class="p">:</span> <span class="n">metric_n</span><span class="p">}</span>
<span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dictionary</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>]) – key value pairs.
The values can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">Metric</span></code>, or <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress base.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for training_step but not validation/test_step.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for val/test step but not <code class="docutils literal notranslate"><span class="pre">training_step</span></code>.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto-detach the graph</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across GPUs/TPUs. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the ddp group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple). If <code class="docutils literal notranslate"><span class="pre">False</span></code>, user needs to give unique names for
each dataloader to not mix values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch size. This will be directly inferred from the loaded batch,
but some data structures might need to explicitly provide it.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.logger">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.logger" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the logger object in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.loggers">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">loggers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.loggers" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the list of loggers in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.lr_scheduler_step">
<span class="sig-name descname"><span class="pre">lr_scheduler_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.lr_scheduler_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
each scheduler. By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and as shown in the example for each scheduler based on
its <code class="docutils literal notranslate"><span class="pre">interval</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scheduler</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]) – Learning rate scheduler.</p></li>
<li><p><strong>metric</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Value of the monitor used for schedulers like <code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>

<span class="c1"># Alternative way to update schedulers if it requires an epoch value</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.lr_schedulers">
<span class="sig-name descname"><span class="pre">lr_schedulers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.lr_schedulers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the learning rate scheduler(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A single scheduler, or a list of schedulers in case multiple ones are present, or <code class="docutils literal notranslate"><span class="pre">None</span></code> if no
schedulers were returned in <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_optimizers()</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.manual_backward">
<span class="sig-name descname"><span class="pre">manual_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.manual_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually. By using this,
Lightning can ensure that all the proper scaling gets applied when using mixed precision.</p>
<p>See <span class="xref std std-ref">manual optimization</span> for more examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># automatically applies scaling, etc...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The tensor on which to compute gradients. Must have a graph attached.</p></li>
<li><p><strong>*args</strong> – Additional positional arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a module in the network</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all buffer names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module. Defaults to True.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated buffers in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, torch.Tensor)</em> – Tuple containing the name and buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_children">
<span class="sig-name descname"><span class="pre">named_children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>(str, Module)</em> – Tuple containing a name and child module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_modules">
<span class="sig-name descname"><span class="pre">named_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>memo</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Set</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]) – a memo to store the set of modules already added to the result</p></li>
<li><p><strong>prefix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – a prefix that will be added to the name of the module</p></li>
<li><p><strong>remove_duplicate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – whether to remove the duplicated module instances in the result
or not</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Module)</em> – Tuple of name and module</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated
parameters in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Parameter)</em> – Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_after_backward">
<span class="sig-name descname"><span class="pre">on_after_backward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_after_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If using native AMP, the gradients will not be unscaled at this point.
Use the <code class="docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code> if you need the unscaled gradients.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_after_batch_transfer">
<span class="sig-name descname"><span class="pre">on_after_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_after_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gpu_transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_before_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_backward">
<span class="sig-name descname"><span class="pre">on_before_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Loss divided by number of batches for gradient accumulation and scaled if using AMP.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_batch_transfer">
<span class="sig-name descname"><span class="pre">on_before_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_after_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_after_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_optimizer_step">
<span class="sig-name descname"><span class="pre">on_before_optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p>
<p>If using gradient accumulation, the hook is called once the gradients have been accumulated.
See: <a href="#id2"><span class="problematic" id="id3">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.accumulate_grad_batches`</span></a>.</p>
<p>If using AMP, the loss will be unscaled before calling this hook.
See these <a class="reference external" href="https://pytorch.org/docs/stable/notes/amp_examples.html#working-with-unscaled-gradients">docs</a>
for more information on the scaling of gradients.</p>
<p>If clipping gradients, the gradients will not have been clipped yet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="c1"># example to inspect gradient information in tensorboard</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># don&#39;t make the tf file huge</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
                <span class="n">tag</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span>
            <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_zero_grad">
<span class="sig-name descname"><span class="pre">on_before_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_before_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<p>Called in the training loop after taking an optimizer step and before zeroing grads.
Good place to inspect weight information with weights updated.</p>
<p>This is where it is called:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">on_before_zero_grad</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span> <span class="c1"># &lt; ---- called here</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The optimizer for which grads should be zeroed.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_fit_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very end of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_fit_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very beginning of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_gpu">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">on_gpu</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_gpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p>
<p>Useful to set flags around the LightningModule for different CPU vs GPU behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_load_checkpoint">
<span class="sig-name descname"><span class="pre">on_load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_load_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning to restore your model. If you saved something with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_save_checkpoint"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_save_checkpoint()</span></code></a> this is
your chance to restore this.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Loaded checkpoint</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of the time you don&#39;t need to implement this method</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">something_cool_i_want_to_save</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning auto-restores global step, epoch, and train state including amp scaling.
There is no need for you to restore anything regarding training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_batch_end">
<span class="sig-name descname"><span class="pre">on_predict_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The outputs of predict_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the prediction DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_batch_start">
<span class="sig-name descname"><span class="pre">on_predict_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_end">
<span class="sig-name descname"><span class="pre">on_predict_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_epoch_end">
<span class="sig-name descname"><span class="pre">on_predict_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_epoch_start">
<span class="sig-name descname"><span class="pre">on_predict_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_model_eval">
<span class="sig-name descname"><span class="pre">on_predict_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the predict loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_start">
<span class="sig-name descname"><span class="pre">on_predict_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_predict_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_save_checkpoint">
<span class="sig-name descname"><span class="pre">on_save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to
save.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The full checkpoint dictionary before it gets dumped to a file.
Implementations of this hook can insert additional data into this dictionary.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of use cases you don&#39;t need to implement this method</span>
    <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_cool_pickable_object</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning saves all aspects of training (epoch, global step, etc…)
including amp scaling.
There is no need for you to store anything about training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_batch_end">
<span class="sig-name descname"><span class="pre">on_test_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of test_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_batch_start">
<span class="sig-name descname"><span class="pre">on_test_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_end">
<span class="sig-name descname"><span class="pre">on_test_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_epoch_end">
<span class="sig-name descname"><span class="pre">on_test_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_epoch_start">
<span class="sig-name descname"><span class="pre">on_test_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_model_eval">
<span class="sig-name descname"><span class="pre">on_test_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_model_train">
<span class="sig-name descname"><span class="pre">on_test_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_start">
<span class="sig-name descname"><span class="pre">on_test_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_test_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_batch_end">
<span class="sig-name descname"><span class="pre">on_train_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of training_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_batch_start">
<span class="sig-name descname"><span class="pre">on_train_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop before anything happens for that batch.</p>
<p>If you return -1 here, you will skip training for the rest of the current epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_end">
<span class="sig-name descname"><span class="pre">on_train_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of training before logger experiment is closed.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very end of the epoch.</p>
<p>To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> and access them in this hook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyLightningModule</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># do something with all training_step outputs, for example:</span>
        <span class="n">epoch_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;training_epoch_mean&quot;</span><span class="p">,</span> <span class="n">epoch_mean</span><span class="p">)</span>
        <span class="c1"># free up the memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_epoch_start">
<span class="sig-name descname"><span class="pre">on_train_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_start">
<span class="sig-name descname"><span class="pre">on_train_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_train_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of training after sanity check.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_batch_end">
<span class="sig-name descname"><span class="pre">on_validation_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of validation_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_batch_start">
<span class="sig-name descname"><span class="pre">on_validation_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_end">
<span class="sig-name descname"><span class="pre">on_validation_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_epoch_end">
<span class="sig-name descname"><span class="pre">on_validation_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_epoch_start">
<span class="sig-name descname"><span class="pre">on_validation_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_eval">
<span class="sig-name descname"><span class="pre">on_validation_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_train">
<span class="sig-name descname"><span class="pre">on_validation_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_zero_grad">
<span class="sig-name descname"><span class="pre">on_validation_model_zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_model_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by the training loop to release gradients before entering the validation loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_start">
<span class="sig-name descname"><span class="pre">on_validation_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.on_validation_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizer_step">
<span class="sig-name descname"><span class="pre">optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
the optimizer.</p>
<p>By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code> as shown in the example.
This method (and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code>) won’t be called during the accumulation phase when
<code class="docutils literal notranslate"><span class="pre">Trainer(accumulate_grad_batches</span> <span class="pre">!=</span> <span class="pre">1)</span></code>. Overriding this hook has no benefit with manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – A PyTorch optimizer</p></li>
<li><p><strong>optimizer_closure</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[], <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]]) – The optimizer closure. This closure must be executed as it includes the
calls to <code class="docutils literal notranslate"><span class="pre">training_step()</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>, and <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

<span class="c1"># Learning rate warm-up</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="c1"># update params</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

    <span class="c1"># manually warm up lr without a scheduler</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">&lt;</span> <span class="mi">500</span><span class="p">:</span>
        <span class="n">lr_scale</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">500.0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">pg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_scale</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizer_zero_grad">
<span class="sig-name descname"><span class="pre">optimizer_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizer_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – A PyTorch optimizer</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="c1"># Set gradients to `None` instead of zero to improve performance (not required on `torch&gt;=2.0.0`).</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for the explanation of the above example.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizers">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the optimizer(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_pl_optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will wrap the optimizer(s) in a
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code> for automatic handling of precision,
profiling, and counting of step calls for proper logging and checkpointing. It specifically wraps the
<code class="docutils literal notranslate"><span class="pre">step</span></code> method and custom optimizers that don’t have this method are not supported.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A single optimizer, or a list of optimizers in case multiple ones are present.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.output_chunk_length">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_chunk_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.output_chunk_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of time steps predicted at once by the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>Parameter</em> – module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.predict_dataloader">
<span class="sig-name descname"><span class="pre">predict_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.predict_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying prediction samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code> or a sequence of them specifying prediction samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.predict_step">
<span class="sig-name descname"><span class="pre">predict_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.predict_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the prediction step</p>
<dl class="simple">
<dt>batch</dt><dd><p>output of Darts’ <code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceDataset</span></code> - tuple of <code class="docutils literal notranslate"><span class="pre">(past_target,</span> <span class="pre">past_covariates,</span>
<span class="pre">historic_future_covariates,</span> <span class="pre">future_covariates,</span> <span class="pre">future_past_covariates,</span> <span class="pre">input_timeseries)</span></code></p>
</dd>
<dt>batch_idx</dt><dd><p>the batch index of the current batch</p>
</dd>
<dt>dataloader_idx</dt><dd><p>the dataloader index</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data">
<span class="sig-name descname"><span class="pre">prepare_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Use this to download and prepare data. Downloading and saving data with multiple processes (distributed
settings) will result in corrupted data. Lightning ensures this method is called only within a single process,
so you can safely add your downloading logic within.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>DO NOT set state to the model (use <code class="docutils literal notranslate"><span class="pre">setup</span></code> instead)
since this is NOT called on every device</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># good</span>
    <span class="n">download_data</span><span class="p">()</span>
    <span class="n">tokenize</span><span class="p">()</span>
    <span class="n">etc</span><span class="p">()</span>

    <span class="c1"># bad</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">data_split</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">some_state</span> <span class="o">=</span> <span class="n">some_other_state</span><span class="p">()</span>
</pre></div>
</div>
<p>In a distributed environment, <code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> can be called in two ways
(using <span class="xref std std-ref">prepare_data_per_node</span>)</p>
<ol class="arabic simple">
<li><p>Once per node. This is the default and is only called on LOCAL_RANK=0.</p></li>
<li><p>Once in total. Only called on GLOBAL_RANK=0.</p></li>
</ol>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="c1"># called once per node on LOCAL_RANK=0 of that node</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># call on GLOBAL_RANK=0 (great for shared file systems)</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>This is called before requesting the dataloaders:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">initialize_distributed</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_dataloader</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.print">
<span class="sig-name descname"><span class="pre">print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.print" title="Permalink to this definition">¶</a></dt>
<dd><p>Prints only from process 0. Use this in any distributed mode to log only once.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – The thing to print. The same as for Python’s built-in print function.</p></li>
<li><p><strong>**kwargs</strong> – The same as for Python’s built-in print function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;in forward&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>This function is deprecated in favor of <code class="xref py py-meth docutils literal notranslate"><span class="pre">register_full_backward_hook()</span></code> and
the behavior of this function will change in future versions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the module’s state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">persistent</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the buffer. The buffer can be accessed
from this module using the given name</p></li>
<li><p><strong>tensor</strong> (<em>Tensor</em><em> or </em><em>None</em>) – buffer to be registered. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations
that run on buffers, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>, are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
the buffer is <strong>not</strong> included in the module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>) – whether the buffer is part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">always_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_forward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
output. It can modify the input inplace but it will not have effect on
forward since this is called after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called. The hook
should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the forward hook will be passed the
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> given to the forward function and be expected to return the
output possibly modified. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired
before all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_hook()</span></code> will fire before all hooks
registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the
kwargs given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>always_call</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be run regardless of
whether an exception is raised while calling the Module.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_forward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is false or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
input. User can either return a tuple or a single modified value in the
hook. We will wrap the value into a tuple if a single value is returned
(unless that value is already a tuple). The hook should have the
following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is true, the forward pre-hook will be passed the
kwargs given to the forward function. And if the hook modifies the
input, both the args and kwargs should be returned. The hook should have
the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">a</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">modified</span> <span class="nb">input</span> <span class="ow">and</span> <span class="n">kwargs</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_pre_hook()</span></code> will fire before all
hooks registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If true, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the kwargs
given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_full_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to a module
are computed, i.e. the hook will execute if and only if the gradients with
respect to module outputs are computed. The hook should have the following
signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in
subsequent computations. <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for all non-Tensor
arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_full_backward_pre_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_full_backward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward pre-hook on the module.</p>
<p>The hook will be called every time the gradients for the module are computed.
The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> is a tuple. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the output that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> in
subsequent computations. Entries in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for
all non-Tensor arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_pre_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_load_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_load_state_dict_post_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a post hook to be run after module’s <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code>
is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, incompatible_keys) -&gt; None</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">module</span></code> argument is the current module that this hook is registered
on, and the <code class="docutils literal notranslate"><span class="pre">incompatible_keys</span></code> argument is a <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> consisting
of attributes <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>. <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code>
is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the missing keys and
<code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the unexpected keys.</p>
<p>The given incompatible_keys can be modified inplace if needed.</p>
<p>Note that the checks performed when calling <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">strict=True</span></code> are affected by modifications the hook makes to
<code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> or <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>, as expected. Additions to either
set of keys will result in an error being thrown when <code class="docutils literal notranslate"><span class="pre">strict=True</span></code>, and
clearing out both missing and unexpected keys will avoid an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_module">
<span class="sig-name descname"><span class="pre">register_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_parameter">
<span class="sig-name descname"><span class="pre">register_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the parameter. The parameter can be accessed
from this module using the given name</p></li>
<li><p><strong>param</strong> (<em>Parameter</em><em> or </em><em>None</em>) – parameter to be added to the module. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations that run on parameters, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>,
are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the parameter is <strong>not</strong> included in the
module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.register_state_dict_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>,
and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>. The registered
hooks can be used to perform pre-processing before the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>
call is made.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.requires_grad_" title="Permalink to this definition">¶</a></dt>
<dd><p>Change if autograd should record operations on parameters in this
module.</p>
<p>This method sets the parameters’ <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.requires_grad_()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<em>bool</em>) – whether autograd should record operations on
parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters">
<span class="sig-name descname"><span class="pre">save_hyperparameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.save_hyperparameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – single object of <cite>dict</cite>, <cite>NameSpace</cite> or <cite>OmegaConf</cite>
or string names or arguments from class <code class="docutils literal notranslate"><span class="pre">__init__</span></code></p></li>
<li><p><strong>ignore</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – an argument name or a list of argument names from
class <code class="docutils literal notranslate"><span class="pre">__init__</span></code> to be ignored</p></li>
<li><p><strong>frame</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">frame</span></code>]) – a frame object. Default is None</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to send the hyperparameters to the logger. Default: True</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Example::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign arguments</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="s1">&#39;arg1&#39;</span><span class="p">,</span> <span class="s1">&#39;arg3&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AutomaticArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># equivalent automatic</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutomaticArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg2&quot;: abc</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">SingleArgModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign single argument</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleArgModel</span><span class="p">(</span><span class="n">Namespace</span><span class="p">(</span><span class="n">p1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p2</span><span class="o">=</span><span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="n">p3</span><span class="o">=</span><span class="mf">3.14</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;p1&quot;: 1</span>
<span class="go">&quot;p2&quot;: abc</span>
<span class="go">&quot;p3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># pass argument(s) to ignore as a string or in a list</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="s1">&#39;arg2&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state
found within the <cite>state_dict</cite>. Implement this function and a corresponding
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.get_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_extra_state()</span></code></a> for your module if you need to store extra state within its
<cite>state_dict</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>dict</em>) – Extra state from the <cite>state_dict</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_mc_dropout">
<span class="sig-name descname"><span class="pre">set_mc_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">active</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_mc_dropout" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_predict_parameters">
<span class="sig-name descname"><span class="pre">set_predict_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roll_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.set_predict_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you
need to build models dynamically or adjust something about them. This hook is called on every process when
using DDP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">download_data</span><span class="p">()</span>
        <span class="n">tokenize</span><span class="p">()</span>

        <span class="c1"># don&#39;t do this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">something</span> <span class="o">=</span> <span class="k">else</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.share_memory">
<span class="sig-name descname"><span class="pre">share_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.share_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>~T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary containing references to the whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to <code class="docutils literal notranslate"><span class="pre">None</span></code> are not included.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned object is a shallow copy. It contains references
to the module’s parameters and buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> also accepts positional arguments for
<code class="docutils literal notranslate"><span class="pre">destination</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> in order. However,
this is being deprecated and keyword arguments will be enforced in
future releases.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please avoid the use of argument <code class="docutils literal notranslate"><span class="pre">destination</span></code> as it is not
designed for end-users.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>destination</strong> (<em>dict</em><em>, </em><em>optional</em>) – If provided, the state of module will
be updated into the dict and the same object is returned.
Otherwise, an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> will be created and returned.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em>) – a prefix added to parameter and buffer
names to compose the keys in state_dict. Default: <code class="docutils literal notranslate"><span class="pre">''</span></code>.</p></li>
<li><p><strong>keep_vars</strong> (<em>bool</em><em>, </em><em>optional</em>) – by default the <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> s
returned in the state dict are detached from autograd. If it’s
set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, detaching will not be performed.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary containing a whole state of the module</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.teardown">
<span class="sig-name descname"><span class="pre">teardown</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.teardown" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of fit (train + validate), validate, test, or predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_dataloader">
<span class="sig-name descname"><span class="pre">test_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying test samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">test()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a test dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a>, you don’t need to implement
this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the test set. In this step you’d normally generate examples or
calculate anything of interest such as accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your data iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><strong>batch_idx</strong> – The index of this batch.</p></li>
<li><p><strong>dataloader_idx</strong> – The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Skip to the next batch.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one test dataloader:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="o">...</span>

<span class="c1"># if you have multiple test dataloaders:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single test dataset</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple test dataloaders, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple test dataloaders</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="o">...</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need to test you don’t need to implement this method.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> is called, the model has been put in eval mode and
PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
to training mode and gradients are enabled.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_dtype">
<span class="sig-name descname"><span class="pre">to_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Cast module precision (float32 by default) to another precision.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_empty" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves the parameters and buffers to the specified device without copying storage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>) – The desired device of the parameters
and buffers in this module.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – Whether parameters and buffers of submodules should
be recursively moved to the specified device.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_onnx">
<span class="sig-name descname"><span class="pre">to_onnx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_onnx" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the model in ONNX format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>]) – The path of the file the onnx model should be saved to.</p></li>
<li><p><strong>input_sample</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input for tracing. Default: None (Use self.example_input_array)</p></li>
<li><p><strong>**kwargs</strong> – Will be passed to torch.onnx.export function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">input_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">(</span><span class="s2">&quot;export.onnx&quot;</span><span class="p">,</span> <span class="n">input_sample</span><span class="p">,</span> <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_torchscript">
<span class="sig-name descname"><span class="pre">to_torchscript</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'script'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.to_torchscript" title="Permalink to this definition">¶</a></dt>
<dd><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>. If you want to use tracing,
please provided the argument <code class="docutils literal notranslate"><span class="pre">method='trace'</span></code> and make sure that either the <cite>example_inputs</cite> argument is
provided, or the model has <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a> set. If you would like to customize the modules that are
scripted you should override this method. In case you want to return multiple modules, we recommend using a
dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Path where to save the torchscript. Default: None (no file saved).</p></li>
<li><p><strong>method</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Whether to use TorchScript’s script or trace method. Default: ‘script’</p></li>
<li><p><strong>example_inputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input to be used to do tracing when method is set to ‘trace’.
Default: None (uses <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments that will be passed to the <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.script()</span></code> or
<code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.trace()</span></code> function.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Requires the implementation of the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> method.</p></li>
<li><p>The exported script will be set to evaluation mode.</p></li>
<li><p>It is recommended that you install the latest supported version of PyTorch
to use this feature without limitations. See also the <code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.jit</span></code>
documentation for supported features.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span>
    <span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model_trace.pt&quot;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;trace&#39;</span><span class="p">,</span> <span class="n">example_inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>]]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>This LightningModule as a torchscript, regardless of whether <cite>file_path</cite> is
defined or not.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.toggle_optimizer">
<span class="sig-name descname"><span class="pre">toggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.toggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Makes sure only the gradients of the current optimizer’s parameters are calculated in the training step to
prevent dangling gradients in multiple-optimizer setup.</p>
<p>It works with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.untoggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">untoggle_optimizer()</span></code></a> to make sure <code class="docutils literal notranslate"><span class="pre">param_requires_grad_state</span></code> is properly reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to toggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.train_dataloader">
<span class="sig-name descname"><span class="pre">train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.train_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying training samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id4"><span class="problematic" id="id5">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.trainer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">trainer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.trainer.trainer.Trainer</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.trainer" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the training step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.transfer_batch_to_device">
<span class="sig-name descname"><span class="pre">transfer_batch_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.transfer_batch_to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data
structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code> or anything that implements <cite>.to(…)</cite></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, …).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook should only transfer the data and not modify it, nor should it move the data to
any other device than the one passed in as argument (unless you know what you are doing).
To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be transferred to a new device.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>) – The target device as defined in PyTorch.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A reference to the data on the new device.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">CustomBatch</span><span class="p">):</span>
        <span class="c1"># move all tensors in your custom data structure to the device</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># skip device transfer for the first dataloader or anything you wish</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transfer_batch_to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">move_data_to_device()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_to_collection()</span></code></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.type">
<span class="sig-name descname"><span class="pre">type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.type" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.unfreeze">
<span class="sig-name descname"><span class="pre">unfreeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze all parameters for training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.untoggle_optimizer">
<span class="sig-name descname"><span class="pre">untoggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.untoggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to untoggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.val_dataloader">
<span class="sig-name descname"><span class="pre">val_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.val_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying validation samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id6"><span class="problematic" id="id7">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">validate()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a validation dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a>, you don’t need to
implement this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the validation step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.xpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the XPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLDualCovariatesModule.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets gradients of all model parameters. See similar function
under <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code> for more context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>set_to_none</strong> (<em>bool</em>) – instead of setting to zero, set the grads to None.
See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for details.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">darts.models.forecasting.pl_forecasting_module.</span></span><span class="sig-name descname"><span class="pre">PLForecastingModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_sample_shape=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn=MSELoss()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_metrics=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_cls=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_cls=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_reversible_instance_norm=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pytorch_lightning.core.module.LightningModule</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>PyTorch Lightning-based Forecasting Module.</p>
<p>This class is meant to be inherited to create a new PyTorch Lightning-based forecasting module.
When subclassing this class, please make sure to add the following methods with the given signatures:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.__init__()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.forward()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._produce_train_output()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._get_batch_prediction()</span></code></p></li>
</ul>
</div></blockquote>
<p>In subclass <cite>MyModel</cite>’s <code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code> function call <code class="docutils literal notranslate"><span class="pre">super(MyModel,</span> <span class="pre">self).__init__(**kwargs)</span></code> where
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> are the parameters of <code class="xref py py-class docutils literal notranslate"><span class="pre">PLTorchForecastingModel</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps in the past to take as a model input (per chunk). Applies to the target
series, and past and/or future covariates (if the model supports it).</p></li>
<li><p><strong>output_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps predicted at once (per chunk) by the internal model. Also, the number of future values
from future covariates to use as a model input (if the model supports future covariates). It is not the same
as forecast horizon <cite>n</cite> used in <cite>predict()</cite>, which is the desired number of prediction points generated
using either a one-shot- or auto-regressive forecast. Setting <cite>n &lt;= output_chunk_length</cite> prevents
auto-regression. This is useful when the covariates don’t extend far enough into the future, or to prohibit
the model from using future values of past and / or future covariates for prediction (depending on the
model’s covariate support).</p></li>
<li><p><strong>train_sample_shape</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Shape of the model’s input, used to instantiate model without calling <code class="docutils literal notranslate"><span class="pre">fit_from_dataset</span></code> and
perform sanity check on new training/inference datasets used for re-training or prediction.</p></li>
<li><p><strong>loss_fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code>) – PyTorch loss function used for training.
This parameter will be ignored for probabilistic models if the <code class="docutils literal notranslate"><span class="pre">likelihood</span></code> parameter is specified.
Default: <code class="docutils literal notranslate"><span class="pre">torch.nn.MSELoss()</span></code>.</p></li>
<li><p><strong>torch_metrics</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – A torch metric or a <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code> used for evaluation. A full list of available metrics can be found
at <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/">https://torchmetrics.readthedocs.io/en/latest/</a>. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>likelihood</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code></a>]) – One of Darts’ <a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Likelihood</span></code></a> models to be used for
probabilistic forecasts. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>optimizer_cls</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The PyTorch optimizer class to be used. Default: <code class="docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code>.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch optimizer (e.g., <code class="docutils literal notranslate"><span class="pre">{'lr':</span> <span class="pre">1e-3}</span></code>
for specifying a learning rate). Otherwise the default values of the selected <code class="docutils literal notranslate"><span class="pre">optimizer_cls</span></code>
will be used. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_cls</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_LRScheduler</span></code>]) – Optionally, the PyTorch learning rate scheduler class to be used. Specifying <code class="docutils literal notranslate"><span class="pre">None</span></code> corresponds
to using a constant learning rate. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch learning rate scheduler. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>use_reversible_instance_norm</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to use reversible instance normalization <cite>RINorm</cite> against distribution shift as shown in <a class="reference internal" href="#r2cae03939c19-1" id="id8">[1]</a>.
It is only applied to the features of the target series and not the covariates.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r2cae03939c19-1"><span class="brackets"><a class="fn-backref" href="#id8">1</a></span></dt>
<dd><p>T. Kim et al. “Reversible Instance Normalization for Accurate Time-Series Forecasting against
Distribution Shift”, <a class="reference external" href="https://openreview.net/forum?id=cGDAkQo1C0p">https://openreview.net/forum?id=cGDAkQo1C0p</a></p>
</dd>
</dl>
<p class="rubric">Attributes</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.automatic_optimization" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.automatic_optimization"><code class="xref py py-obj docutils literal notranslate"><span class="pre">automatic_optimization</span></code></a></p></td>
<td><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.current_epoch" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.current_epoch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">current_epoch</span></code></a></p></td>
<td><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.example_input_array"><code class="xref py py-obj docutils literal notranslate"><span class="pre">example_input_array</span></code></a></p></td>
<td><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.global_rank" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.global_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_rank</span></code></a></p></td>
<td><p>The index of the current process across all nodes and devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.global_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.global_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_step</span></code></a></p></td>
<td><p>Total training batches seen across all epochs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams_initial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams_initial</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.local_rank" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.local_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">local_rank</span></code></a></p></td>
<td><p>The index of the current process within a single node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.logger" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.logger"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logger</span></code></a></p></td>
<td><p>Reference to the logger object in the Trainer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.loggers" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.loggers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">loggers</span></code></a></p></td>
<td><p>Reference to the list of loggers in the Trainer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_gpu" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_gpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_gpu</span></code></a></p></td>
<td><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.output_chunk_length" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.output_chunk_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_chunk_length</span></code></a></p></td>
<td><p>Number of time steps predicted at once by the model.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>device</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>dtype</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>epochs_trained</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>fabric</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>trainer</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.add_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_module</span></code></a>(name, module)</p></td>
<td><p>Adds a child module to the current module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.all_gather" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.all_gather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">all_gather</span></code></a>(data[, group, sync_grads])</p></td>
<td><p>Gather tensors or collections of tensors from multiple processes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.apply" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.backward" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.bfloat16" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.bfloat16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfloat16</span></code></a>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.buffers" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">buffers</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.children" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.clip_gradients" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.clip_gradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip_gradients</span></code></a>(optimizer[, ...])</p></td>
<td><p>Handles gradient clipping internally.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.compile" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(*args, **kwargs)</p></td>
<td><p>Compile this Module's forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_callbacks" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_callbacks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_callbacks</span></code></a>()</p></td>
<td><p>Configure model-specific callbacks.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_gradient_clipping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_gradient_clipping</span></code></a>(optimizer[, ...])</p></td>
<td><p>Perform gradient clipping for the optimizer parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_model" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_model</span></code></a>()</p></td>
<td><p>Hook to create modules in a strategy and precision aware context.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_optimizers" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_optimizers</span></code></a>()</p></td>
<td><p>configures optimizers and learning rate schedulers for model optimization.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_sharded_model" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_sharded_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_sharded_model</span></code></a>()</p></td>
<td><p>Deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_torch_metrics" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_torch_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_torch_metrics</span></code></a>(torch_metrics)</p></td>
<td><p>process the torch_metrics parameter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cpu" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cuda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.double" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.double"><code class="xref py py-obj docutils literal notranslate"><span class="pre">double</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.eval" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code></a>()</p></td>
<td><p>Sets the module in evaluation mode.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.extra_repr" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.extra_repr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extra_repr</span></code></a>()</p></td>
<td><p>Set the extra representation of the module</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(*args, **kwargs)</p></td>
<td><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.freeze" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.freeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">freeze</span></code></a>()</p></td>
<td><p>Freeze all params for inference.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_buffer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_buffer</span></code></a>(target)</p></td>
<td><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_extra_state</span></code></a>()</p></td>
<td><p>Returns any extra state to include in the module's state_dict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_parameter" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_parameter</span></code></a>(target)</p></td>
<td><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_submodule" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_submodule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_submodule</span></code></a>(target)</p></td>
<td><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.half" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.half"><code class="xref py py-obj docutils literal notranslate"><span class="pre">half</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.ipu" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.ipu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ipu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the IPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_from_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_from_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code></a>([map_location, ...])</p></td>
<td><p>Primary way of loading a model from a checkpoint.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>(state_dict[, strict, assign])</p></td>
<td><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.log" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log</span></code></a>(name, value[, prog_bar, logger, ...])</p></td>
<td><p>Log a key, value pair.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.log_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.log_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_dict</span></code></a>(dictionary[, prog_bar, logger, ...])</p></td>
<td><p>Log a dictionary of values at once.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.lr_scheduler_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.lr_scheduler_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_scheduler_step</span></code></a>(scheduler, metric)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls each scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.lr_schedulers" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.lr_schedulers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_schedulers</span></code></a>()</p></td>
<td><p>Returns the learning rate scheduler(s) that are being used during training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.manual_backward" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.manual_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">manual_backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.modules" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">modules</span></code></a>()</p></td>
<td><p>Returns an iterator over all modules in the network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_buffers" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_buffers</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_children" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_modules" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_modules</span></code></a>([memo, prefix, remove_duplicate])</p></td>
<td><p>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_parameters" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_after_backward" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_after_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_backward</span></code></a>()</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_after_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_backward" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_backward</span></code></a>(loss)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code></a>(optimizer)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_zero_grad</span></code></a>(optimizer)</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_fit_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_fit_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_end</span></code></a>()</p></td>
<td><p>Called at the very end of fit.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_fit_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_fit_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_start</span></code></a>()</p></td>
<td><p>Called at the very beginning of fit.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_load_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_load_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_load_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning to restore your model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the predict loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the predict loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the predict loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_save_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_save_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to save.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the test loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the test loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_end</span></code></a>()</p></td>
<td><p>Called at the end of testing.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_end</span></code></a>()</p></td>
<td><p>Called in the test loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_start</span></code></a>()</p></td>
<td><p>Called in the test loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the test loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_model_train" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the test loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_start</span></code></a>()</p></td>
<td><p>Called at the beginning of testing.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the training loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the training loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_end</span></code></a>()</p></td>
<td><p>Called at the end of training before logger experiment is closed.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_end</span></code></a>()</p></td>
<td><p>Called in the training loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_start</span></code></a>()</p></td>
<td><p>Called in the training loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_start</span></code></a>()</p></td>
<td><p>Called at the beginning of training after sanity check.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_end</span></code></a>(outputs, batch, ...)</p></td>
<td><p>Called in the validation loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the validation loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_end</span></code></a>()</p></td>
<td><p>Called at the end of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_end</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_start</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the val loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_train" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the val loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_zero_grad</span></code></a>()</p></td>
<td><p>Called by the training loop to release gradients before entering the validation loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_start" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_start</span></code></a>()</p></td>
<td><p>Called at the beginning of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_step</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls the optimizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizer_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizer_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_zero_grad</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizers" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizers</span></code></a>([use_pl_optimizer])</p></td>
<td><p>Returns the optimizer(s) that are being used during training.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.parameters" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.predict_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.predict_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying prediction samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.predict_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.predict_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_step</span></code></a>(batch, batch_idx[, dataloader_idx])</p></td>
<td><p>performs the prediction step</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare_data</span></code></a>()</p></td>
<td><p>Use this to download and prepare data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.print" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.print"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print</span></code></a>(*args, **kwargs)</p></td>
<td><p>Prints only from process 0.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_backward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_buffer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_buffer</span></code></a>(name, tensor[, persistent])</p></td>
<td><p>Adds a buffer to the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_forward_hook" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook, *[, prepend, ...])</p></td>
<td><p>Registers a forward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_forward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook, *[, ...])</p></td>
<td><p>Registers a forward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_full_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_full_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_full_backward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_full_backward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_pre_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_load_state_dict_post_hook" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_load_state_dict_post_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_load_state_dict_post_hook</span></code></a>(hook)</p></td>
<td><p>Registers a post hook to be run after module's <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> is called.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_module" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_module</span></code></a>(name, module)</p></td>
<td><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_parameter" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_parameter</span></code></a>(name, param)</p></td>
<td><p>Adds a parameter to the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_state_dict_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_state_dict_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_state_dict_pre_hook</span></code></a>(hook)</p></td>
<td><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>, and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.requires_grad_" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.requires_grad_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad_</span></code></a>([requires_grad])</p></td>
<td><p>Change if autograd should record operations on parameters in this module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_hyperparameters</span></code></a>(*args[, ignore, frame, ...])</p></td>
<td><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_extra_state</span></code></a>(state)</p></td>
<td><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state found within the <cite>state_dict</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_predict_parameters" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_predict_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_predict_parameters</span></code></a>(n, num_samples, ...)</p></td>
<td><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>(stage)</p></td>
<td><p>Called at the beginning of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.share_memory" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.share_memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_memory</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code></a>(*args[, destination, prefix, ...])</p></td>
<td><p>Returns a dictionary containing references to the whole state of the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.teardown" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.teardown"><code class="xref py py-obj docutils literal notranslate"><span class="pre">teardown</span></code></a>(stage)</p></td>
<td><p>Called at the end of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying test samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_step</span></code></a>(*args, **kwargs)</p></td>
<td><p>Operates on a single batch of data from the test set.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_dtype" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_dtype</span></code></a>(dtype)</p></td>
<td><p>Cast module precision (float32 by default) to another precision.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_empty" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_empty</span></code></a>(*, device[, recurse])</p></td>
<td><p>Moves the parameters and buffers to the specified device without copying storage.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_onnx" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_onnx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_onnx</span></code></a>(file_path[, input_sample])</p></td>
<td><p>Saves the model in ONNX format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_torchscript" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_torchscript"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_torchscript</span></code></a>([file_path, method, ...])</p></td>
<td><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.toggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">toggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Makes sure only the gradients of the current optimizer's parameters are calculated in the training step to prevent dangling gradients in multiple-optimizer setup.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.train" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>([mode])</p></td>
<td><p>Sets the module in training mode.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.train_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.train_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying training samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">training_step</span></code></a>(train_batch, batch_idx)</p></td>
<td><p>performs the training step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.transfer_batch_to_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transfer_batch_to_device</span></code></a>(batch, device, ...)</p></td>
<td><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data structure.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.type" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code></a>(dst_type)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.unfreeze" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.unfreeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unfreeze</span></code></a>()</p></td>
<td><p>Unfreeze all parameters for training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.untoggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">untoggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.val_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.val_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">val_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying validation samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.validation_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">validation_step</span></code></a>(val_batch, batch_idx)</p></td>
<td><p>performs the validation step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.xpu" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.xpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xpu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the XPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>([set_to_none])</p></td>
<td><p>Resets gradients of all model parameters.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>__call__</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_mc_dropout</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.CHECKPOINT_HYPER_PARAMS_KEY">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_KEY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hyper_parameters'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.CHECKPOINT_HYPER_PARAMS_KEY" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.CHECKPOINT_HYPER_PARAMS_NAME">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_name'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.CHECKPOINT_HYPER_PARAMS_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.CHECKPOINT_HYPER_PARAMS_TYPE">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_TYPE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_type'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.CHECKPOINT_HYPER_PARAMS_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.T_destination">
<span class="sig-name descname"><span class="pre">T_destination</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.T_destination" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of TypeVar(‘T_destination’, bound=<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>])</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.add_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the child module. The child module can be
accessed from this module using the given name</p></li>
<li><p><strong>module</strong> (<em>Module</em>) – child module to be added to the module.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.all_gather">
<span class="sig-name descname"><span class="pre">all_gather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.all_gather" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather tensors or collections of tensors from multiple processes.</p>
<p>This method needs to be called on all processes and the tensors need to have the same shape across all
processes, otherwise your program will stall forever.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – int, float, tensor of shape (batch, …), or a (possibly nested) collection thereof.</p></li>
<li><p><strong>group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the process group to gather results from. Defaults to all processes (world)</p></li>
<li><p><strong>sync_grads</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – flag that allows users to synchronize gradients for the all_gather operation</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor of shape (world_size, batch, …), or if the input was a collection
the output will also be a collection with tensors of this shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>)
as well as self. Typical use includes initializing the parameters of a model
(see also <span class="xref std std-ref">nn-init-doc</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> -&gt; None) – function to be applied to each submodule</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.automatic_optimization">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">automatic_optimization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.automatic_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. Override this hook with your own
implementation if you need to.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The loss tensor returned by <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. If gradient accumulation is used, the loss here
holds the normalized value (scaled by 1 / accumulation steps).</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.bfloat16">
<span class="sig-name descname"><span class="pre">bfloat16</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.bfloat16" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.buffers">
<span class="sig-name descname"><span class="pre">buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – module buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.call_super_init">
<span class="sig-name descname"><span class="pre">call_super_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.call_super_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a child module</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.clip_gradients">
<span class="sig-name descname"><span class="pre">clip_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.clip_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Handles gradient clipping internally.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Do not override this method. If you want to customize gradient clipping, consider using
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_gradient_clipping"><code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_gradient_clipping()</span></code></a> method.</p></li>
<li><p>For manual optimization (<code class="docutils literal notranslate"><span class="pre">self.automatic_optimization</span> <span class="pre">=</span> <span class="pre">False</span></code>), if you want to use
gradient clipping, consider calling
<code class="docutils literal notranslate"><span class="pre">self.clip_gradients(opt,</span> <span class="pre">gradient_clip_val=0.5,</span> <span class="pre">gradient_clip_algorithm=&quot;norm&quot;)</span></code>
manually in the training step.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. Pass <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;value&quot;</span></code>
to clip by value, and <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;norm&quot;</span></code> to clip by norm.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.compile" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile this Module’s forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>This Module’s <cite>__call__</cite> method is compiled and all arguments are passed as-is
to <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>See <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code> for details on the arguments for this function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_callbacks">
<span class="sig-name descname"><span class="pre">configure_callbacks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_callbacks" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure model-specific callbacks. When the model gets attached, e.g., when <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> or <code class="docutils literal notranslate"><span class="pre">.test()</span></code> gets
called, the list or a callback returned here will be merged with the list of callbacks passed to the Trainer’s
<code class="docutils literal notranslate"><span class="pre">callbacks</span></code> argument. If a callback returned here has the same type as one or several callbacks already
present in the Trainer’s callbacks list, it will take priority and replace them. In addition, Lightning will
make sure <code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> callbacks run last.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A callback or a list of callbacks which will extend the list of callbacks in the Trainer.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">early_stop</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_gradient_clipping">
<span class="sig-name descname"><span class="pre">configure_gradient_clipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_gradient_clipping" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform gradient clipping for the optimizer parameters. Called before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizer_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients. By default, value passed in Trainer
will be available here.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. By default, value
passed in Trainer will be available here.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_gradient_clipping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="p">,</span> <span class="n">gradient_clip_algorithm</span><span class="p">):</span>
    <span class="c1"># Implement your own custom logic to clip gradients</span>
    <span class="c1"># You can call `self.clip_gradients` with your settings:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="o">=</span><span class="n">gradient_clip_val</span><span class="p">,</span>
        <span class="n">gradient_clip_algorithm</span><span class="o">=</span><span class="n">gradient_clip_algorithm</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_model">
<span class="sig-name descname"><span class="pre">configure_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook to create modules in a strategy and precision aware context.</p>
<p>This is particularly useful for when using sharded strategies (FSDP and DeepSpeed), where we’d like to shard
the model instantly to save memory and initialization time.
For non-sharded strategies, you can choose to override this hook or to initialize your model under the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">init_module()</span></code> context manager.</p>
<p>This hook is called during each of fit/val/test/predict stages in the same process, so ensure that
implementation of this hook is idempotent.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.configure_optimizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>configures optimizers and learning rate schedulers for model optimization.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_sharded_model">
<span class="sig-name descname"><span class="pre">configure_sharded_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_sharded_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Deprecated.</p>
<p>Use <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_model()</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_torch_metrics">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">configure_torch_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">torch_metrics</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.configure_torch_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_torch_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>process the torch_metrics parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cuda" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the GPU. This also makes associated parameters and buffers
different objects. So it should be called before constructing optimizer if the module will live on GPU while
being optimized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If specified, all parameters will be copied to that device. If <cite>None</cite>, the current CUDA device
index will be used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.current_epoch">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">current_epoch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.current_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.device</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.device" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.double" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.dtype</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.dtype" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dtype</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.dump_patches">
<span class="sig-name descname"><span class="pre">dump_patches</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.dump_patches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.epochs_trained">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">epochs_trained</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.epochs_trained" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code>.</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.eval()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.example_input_array">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">example_input_array</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.example_input_array" title="Permalink to this definition">¶</a></dt>
<dd><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method. The
return type is interpreted as follows:</p>
<ul class="simple">
<li><p>Single tensor: It is assumed the model takes a single argument, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(model.example_input_array)</span></code></p></li>
<li><p>Tuple: The input array should be interpreted as a sequence of positional arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(*model.example_input_array)</span></code></p></li>
<li><p>Dict: The input array represents named keyword arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(**model.example_input_array)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.fabric">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fabric</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.fabric.Fabric</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.fabric" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fabric</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Whatever you decide to pass into the forward method.</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments are also possible.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Your model’s output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.freeze">
<span class="sig-name descname"><span class="pre">freeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze all params for inference.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the buffer
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The buffer referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not a
buffer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns any extra state to include in the module’s state_dict.
Implement this and a corresponding <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_extra_state()</span></code></a> for your module
if you need to store extra state. This function is called when building the
module’s <cite>state_dict()</cite>.</p>
<p>Note that extra state should be picklable to ensure working serialization
of the state_dict. We only provide provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Any extra state to store in the module’s state_dict</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_parameter">
<span class="sig-name descname"><span class="pre">get_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the Parameter
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Parameter referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To check whether or not we have the <code class="docutils literal notranslate"><span class="pre">linear</span></code> submodule, we
would call <code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.linear&quot;)</span></code>. To check whether
we have the <code class="docutils literal notranslate"><span class="pre">conv</span></code> submodule, we would call
<code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.net_c.conv&quot;)</span></code>.</p>
<p>The runtime of <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> is bounded by the degree
of module nesting in <code class="docutils literal notranslate"><span class="pre">target</span></code>. A query against
<code class="docutils literal notranslate"><span class="pre">named_modules</span></code> achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists, <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> should always be
used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The submodule referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.global_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.global_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process across all nodes and devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.global_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.global_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Total training batches seen across all epochs.</p>
<p>If no Trainer is attached, this propery is 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.half" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">MutableMapping</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. It is mutable by the user. For
the frozen set of initial hyperparameters, use <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams_initial"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams_initial</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">AttributeDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MutableMapping</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mutable hyperparameters dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams_initial">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams_initial</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams_initial" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. These contents are read-only.
Manual updates to the saved hyperparameters can instead be performed through <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.hparams"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>immutable initial hyperparameters</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>AttributeDict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.ipu">
<span class="sig-name descname"><span class="pre">ipu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.ipu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the IPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on IPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_from_checkpoint">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_from_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments
passed to <code class="docutils literal notranslate"><span class="pre">__init__</span></code>  in the checkpoint under <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<p>Any arguments specified through **kwargs will override args stored in <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">IO</span></code>]) – Path to checkpoint. This can also be a URL, or file-like object</p></li>
<li><p><strong>map_location</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If your checkpoint saved a GPU model and you now load on CPUs
or a different number of GPUs, use this to map to the new setup.
The behaviour is the same as in <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code>.</p></li>
<li><p><strong>hparams_file</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optional path to a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> or <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file with hierarchical structure
as in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">drop_prob</span><span class="p">:</span> <span class="mf">0.2</span>
<span class="n">dataloader</span><span class="p">:</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="mi">32</span>
</pre></div>
</div>
<p>You most likely won’t need this since Lightning will always save the hyperparameters
to the checkpoint.
However, if your checkpoint weights don’t have the hyperparameters saved,
use this method to pass in a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file with the hparams you’d like to use.
These will be converted into a <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> and passed into your
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> for use.</p>
<p>If your model’s <code class="docutils literal notranslate"><span class="pre">hparams</span></code> argument is <code class="xref py py-class docutils literal notranslate"><span class="pre">Namespace</span></code>
and <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file has hierarchical structure, you need to refactor your model to treat
<code class="docutils literal notranslate"><span class="pre">hparams</span></code> as <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>.</p>
</p></li>
<li><p><strong>strict</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to strictly enforce that the keys in <code class="xref py py-attr docutils literal notranslate"><span class="pre">checkpoint_path</span></code> match the keys
returned by this module’s state dict.</p></li>
<li><p><strong>**kwargs</strong> – Any extra keyword args needed to init the model. Can also be used to override saved
hyperparameter values.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance with loaded weights and hyperparameters (if available).</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code> is a <strong>class</strong> method. You should use your <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code>
<strong>class</strong> to call it instead of the <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance, or a
<code class="docutils literal notranslate"><span class="pre">TypeError</span></code> will be raised.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load weights without mapping ...</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">)</span>

<span class="c1"># or load weights mapping all weights from GPU 1 to GPU 0 ...</span>
<span class="n">map_location</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span>
<span class="p">)</span>

<span class="c1"># or load weights and hyperparameters from separate files.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">hparams_file</span><span class="o">=</span><span class="s1">&#39;/path/to/hparams_file.yaml&#39;</span>
<span class="p">)</span>

<span class="c1"># override some of the params with new values</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="n">PATH</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">pretrained_ckpt_path</span><span class="o">=</span><span class="n">NEW_PATH</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># predict</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">pretrained_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into
this module and its descendants. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> the optimizer must be created after
the call to <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>dict</em>) – a dict containing parameters and
persistent buffers.</p></li>
<li><p><strong>strict</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to strictly enforce that the keys
in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this module’s
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>assign</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to assign items in the state
dictionary to their corresponding keys in the module instead
of copying them inplace into the module’s current parameters and buffers.
When <code class="docutils literal notranslate"><span class="pre">False</span></code>, the properties of the tensors in the current
module are preserved while when <code class="docutils literal notranslate"><span class="pre">True</span></code>, the properties of the
Tensors in the state dict are preserved.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>missing_keys</strong> is a list of str containing the missing keys</p></li>
<li><p><strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a parameter or buffer is registered as <code class="docutils literal notranslate"><span class="pre">None</span></code> and its corresponding key
exists in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> will raise a
<code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code>.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.local_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">local_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.local_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process within a single node.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_attribute</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a key, value pair.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>The default behavior per hook is documented here: <span class="xref std std-ref">extensions/logging:Automatic Logging</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – key to log.</p></li>
<li><p><strong>value</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]) – value to log. Can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, or a <code class="docutils literal notranslate"><span class="pre">Metric</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress bar.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto detach the graph.</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across devices. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the DDP group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple dataloaders). If False, user needs to give unique names for
each dataloader to not mix the values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch_size. This will be directly inferred from the loaded batch,
but for some data structures you might need to explicitly provide it.</p></li>
<li><p><strong>metric_attribute</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – To restore the metric state, Lightning requires the reference of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code> in your model. This is found automatically if it is a model attribute.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.log_dict">
<span class="sig-name descname"><span class="pre">log_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dictionary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.log_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a dictionary of values at once.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="s1">&#39;metric_n&#39;</span><span class="p">:</span> <span class="n">metric_n</span><span class="p">}</span>
<span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dictionary</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>]) – key value pairs.
The values can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">Metric</span></code>, or <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress base.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for training_step but not validation/test_step.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for val/test step but not <code class="docutils literal notranslate"><span class="pre">training_step</span></code>.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto-detach the graph</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across GPUs/TPUs. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the ddp group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple). If <code class="docutils literal notranslate"><span class="pre">False</span></code>, user needs to give unique names for
each dataloader to not mix values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch size. This will be directly inferred from the loaded batch,
but some data structures might need to explicitly provide it.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.logger">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.logger" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the logger object in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.loggers">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">loggers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.loggers" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the list of loggers in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.lr_scheduler_step">
<span class="sig-name descname"><span class="pre">lr_scheduler_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.lr_scheduler_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
each scheduler. By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and as shown in the example for each scheduler based on
its <code class="docutils literal notranslate"><span class="pre">interval</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scheduler</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]) – Learning rate scheduler.</p></li>
<li><p><strong>metric</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Value of the monitor used for schedulers like <code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>

<span class="c1"># Alternative way to update schedulers if it requires an epoch value</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.lr_schedulers">
<span class="sig-name descname"><span class="pre">lr_schedulers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.lr_schedulers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the learning rate scheduler(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A single scheduler, or a list of schedulers in case multiple ones are present, or <code class="docutils literal notranslate"><span class="pre">None</span></code> if no
schedulers were returned in <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_optimizers()</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.manual_backward">
<span class="sig-name descname"><span class="pre">manual_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.manual_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually. By using this,
Lightning can ensure that all the proper scaling gets applied when using mixed precision.</p>
<p>See <span class="xref std std-ref">manual optimization</span> for more examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># automatically applies scaling, etc...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The tensor on which to compute gradients. Must have a graph attached.</p></li>
<li><p><strong>*args</strong> – Additional positional arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a module in the network</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all buffer names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module. Defaults to True.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated buffers in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, torch.Tensor)</em> – Tuple containing the name and buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_children">
<span class="sig-name descname"><span class="pre">named_children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>(str, Module)</em> – Tuple containing a name and child module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_modules">
<span class="sig-name descname"><span class="pre">named_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>memo</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Set</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]) – a memo to store the set of modules already added to the result</p></li>
<li><p><strong>prefix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – a prefix that will be added to the name of the module</p></li>
<li><p><strong>remove_duplicate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – whether to remove the duplicated module instances in the result
or not</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Module)</em> – Tuple of name and module</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated
parameters in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Parameter)</em> – Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_after_backward">
<span class="sig-name descname"><span class="pre">on_after_backward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_after_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If using native AMP, the gradients will not be unscaled at this point.
Use the <code class="docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code> if you need the unscaled gradients.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_after_batch_transfer">
<span class="sig-name descname"><span class="pre">on_after_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_after_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gpu_transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_before_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_backward">
<span class="sig-name descname"><span class="pre">on_before_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Loss divided by number of batches for gradient accumulation and scaled if using AMP.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_batch_transfer">
<span class="sig-name descname"><span class="pre">on_before_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_after_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_after_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_optimizer_step">
<span class="sig-name descname"><span class="pre">on_before_optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p>
<p>If using gradient accumulation, the hook is called once the gradients have been accumulated.
See: <a href="#id9"><span class="problematic" id="id10">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.accumulate_grad_batches`</span></a>.</p>
<p>If using AMP, the loss will be unscaled before calling this hook.
See these <a class="reference external" href="https://pytorch.org/docs/stable/notes/amp_examples.html#working-with-unscaled-gradients">docs</a>
for more information on the scaling of gradients.</p>
<p>If clipping gradients, the gradients will not have been clipped yet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="c1"># example to inspect gradient information in tensorboard</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># don&#39;t make the tf file huge</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
                <span class="n">tag</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span>
            <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_zero_grad">
<span class="sig-name descname"><span class="pre">on_before_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_before_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<p>Called in the training loop after taking an optimizer step and before zeroing grads.
Good place to inspect weight information with weights updated.</p>
<p>This is where it is called:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">on_before_zero_grad</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span> <span class="c1"># &lt; ---- called here</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The optimizer for which grads should be zeroed.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_fit_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very end of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_fit_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very beginning of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_gpu">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">on_gpu</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_gpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p>
<p>Useful to set flags around the LightningModule for different CPU vs GPU behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_load_checkpoint">
<span class="sig-name descname"><span class="pre">on_load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.on_load_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_load_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning to restore your model. If you saved something with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_save_checkpoint"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_save_checkpoint()</span></code></a> this is
your chance to restore this.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Loaded checkpoint</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of the time you don&#39;t need to implement this method</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">something_cool_i_want_to_save</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning auto-restores global step, epoch, and train state including amp scaling.
There is no need for you to restore anything regarding training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_batch_end">
<span class="sig-name descname"><span class="pre">on_predict_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The outputs of predict_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the prediction DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_batch_start">
<span class="sig-name descname"><span class="pre">on_predict_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_end">
<span class="sig-name descname"><span class="pre">on_predict_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_epoch_end">
<span class="sig-name descname"><span class="pre">on_predict_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_epoch_start">
<span class="sig-name descname"><span class="pre">on_predict_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_model_eval">
<span class="sig-name descname"><span class="pre">on_predict_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the predict loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_start">
<span class="sig-name descname"><span class="pre">on_predict_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_save_checkpoint">
<span class="sig-name descname"><span class="pre">on_save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.on_save_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to
save.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The full checkpoint dictionary before it gets dumped to a file.
Implementations of this hook can insert additional data into this dictionary.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of use cases you don&#39;t need to implement this method</span>
    <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_cool_pickable_object</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning saves all aspects of training (epoch, global step, etc…)
including amp scaling.
There is no need for you to store anything about training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_batch_end">
<span class="sig-name descname"><span class="pre">on_test_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of test_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_batch_start">
<span class="sig-name descname"><span class="pre">on_test_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_end">
<span class="sig-name descname"><span class="pre">on_test_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_epoch_end">
<span class="sig-name descname"><span class="pre">on_test_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_epoch_start">
<span class="sig-name descname"><span class="pre">on_test_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_model_eval">
<span class="sig-name descname"><span class="pre">on_test_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_model_train">
<span class="sig-name descname"><span class="pre">on_test_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_start">
<span class="sig-name descname"><span class="pre">on_test_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_test_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_batch_end">
<span class="sig-name descname"><span class="pre">on_train_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of training_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_batch_start">
<span class="sig-name descname"><span class="pre">on_train_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop before anything happens for that batch.</p>
<p>If you return -1 here, you will skip training for the rest of the current epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_end">
<span class="sig-name descname"><span class="pre">on_train_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of training before logger experiment is closed.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very end of the epoch.</p>
<p>To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> and access them in this hook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyLightningModule</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># do something with all training_step outputs, for example:</span>
        <span class="n">epoch_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;training_epoch_mean&quot;</span><span class="p">,</span> <span class="n">epoch_mean</span><span class="p">)</span>
        <span class="c1"># free up the memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_epoch_start">
<span class="sig-name descname"><span class="pre">on_train_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_start">
<span class="sig-name descname"><span class="pre">on_train_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of training after sanity check.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_batch_end">
<span class="sig-name descname"><span class="pre">on_validation_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of validation_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_batch_start">
<span class="sig-name descname"><span class="pre">on_validation_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_end">
<span class="sig-name descname"><span class="pre">on_validation_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_epoch_end">
<span class="sig-name descname"><span class="pre">on_validation_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_epoch_start">
<span class="sig-name descname"><span class="pre">on_validation_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_eval">
<span class="sig-name descname"><span class="pre">on_validation_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_train">
<span class="sig-name descname"><span class="pre">on_validation_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_zero_grad">
<span class="sig-name descname"><span class="pre">on_validation_model_zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_model_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by the training loop to release gradients before entering the validation loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_start">
<span class="sig-name descname"><span class="pre">on_validation_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizer_step">
<span class="sig-name descname"><span class="pre">optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
the optimizer.</p>
<p>By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code> as shown in the example.
This method (and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code>) won’t be called during the accumulation phase when
<code class="docutils literal notranslate"><span class="pre">Trainer(accumulate_grad_batches</span> <span class="pre">!=</span> <span class="pre">1)</span></code>. Overriding this hook has no benefit with manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – A PyTorch optimizer</p></li>
<li><p><strong>optimizer_closure</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[], <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]]) – The optimizer closure. This closure must be executed as it includes the
calls to <code class="docutils literal notranslate"><span class="pre">training_step()</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>, and <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

<span class="c1"># Learning rate warm-up</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="c1"># update params</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

    <span class="c1"># manually warm up lr without a scheduler</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">&lt;</span> <span class="mi">500</span><span class="p">:</span>
        <span class="n">lr_scale</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">500.0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">pg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_scale</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizer_zero_grad">
<span class="sig-name descname"><span class="pre">optimizer_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizer_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – A PyTorch optimizer</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="c1"># Set gradients to `None` instead of zero to improve performance (not required on `torch&gt;=2.0.0`).</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for the explanation of the above example.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizers">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the optimizer(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_pl_optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will wrap the optimizer(s) in a
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code> for automatic handling of precision,
profiling, and counting of step calls for proper logging and checkpointing. It specifically wraps the
<code class="docutils literal notranslate"><span class="pre">step</span></code> method and custom optimizers that don’t have this method are not supported.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A single optimizer, or a list of optimizers in case multiple ones are present.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.output_chunk_length">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_chunk_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.output_chunk_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of time steps predicted at once by the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>Parameter</em> – module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.predict_dataloader">
<span class="sig-name descname"><span class="pre">predict_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.predict_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying prediction samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code> or a sequence of them specifying prediction samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.predict_step">
<span class="sig-name descname"><span class="pre">predict_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.predict_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.predict_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the prediction step</p>
<dl class="simple">
<dt>batch</dt><dd><p>output of Darts’ <code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceDataset</span></code> - tuple of <code class="docutils literal notranslate"><span class="pre">(past_target,</span> <span class="pre">past_covariates,</span>
<span class="pre">historic_future_covariates,</span> <span class="pre">future_covariates,</span> <span class="pre">future_past_covariates,</span> <span class="pre">input_timeseries)</span></code></p>
</dd>
<dt>batch_idx</dt><dd><p>the batch index of the current batch</p>
</dd>
<dt>dataloader_idx</dt><dd><p>the dataloader index</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data">
<span class="sig-name descname"><span class="pre">prepare_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Use this to download and prepare data. Downloading and saving data with multiple processes (distributed
settings) will result in corrupted data. Lightning ensures this method is called only within a single process,
so you can safely add your downloading logic within.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>DO NOT set state to the model (use <code class="docutils literal notranslate"><span class="pre">setup</span></code> instead)
since this is NOT called on every device</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># good</span>
    <span class="n">download_data</span><span class="p">()</span>
    <span class="n">tokenize</span><span class="p">()</span>
    <span class="n">etc</span><span class="p">()</span>

    <span class="c1"># bad</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">data_split</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">some_state</span> <span class="o">=</span> <span class="n">some_other_state</span><span class="p">()</span>
</pre></div>
</div>
<p>In a distributed environment, <code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> can be called in two ways
(using <span class="xref std std-ref">prepare_data_per_node</span>)</p>
<ol class="arabic simple">
<li><p>Once per node. This is the default and is only called on LOCAL_RANK=0.</p></li>
<li><p>Once in total. Only called on GLOBAL_RANK=0.</p></li>
</ol>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="c1"># called once per node on LOCAL_RANK=0 of that node</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># call on GLOBAL_RANK=0 (great for shared file systems)</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>This is called before requesting the dataloaders:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">initialize_distributed</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_dataloader</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.print">
<span class="sig-name descname"><span class="pre">print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.print" title="Permalink to this definition">¶</a></dt>
<dd><p>Prints only from process 0. Use this in any distributed mode to log only once.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – The thing to print. The same as for Python’s built-in print function.</p></li>
<li><p><strong>**kwargs</strong> – The same as for Python’s built-in print function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;in forward&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>This function is deprecated in favor of <code class="xref py py-meth docutils literal notranslate"><span class="pre">register_full_backward_hook()</span></code> and
the behavior of this function will change in future versions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the module’s state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">persistent</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the buffer. The buffer can be accessed
from this module using the given name</p></li>
<li><p><strong>tensor</strong> (<em>Tensor</em><em> or </em><em>None</em>) – buffer to be registered. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations
that run on buffers, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>, are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
the buffer is <strong>not</strong> included in the module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>) – whether the buffer is part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">always_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_forward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
output. It can modify the input inplace but it will not have effect on
forward since this is called after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called. The hook
should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the forward hook will be passed the
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> given to the forward function and be expected to return the
output possibly modified. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired
before all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_hook()</span></code> will fire before all hooks
registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the
kwargs given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>always_call</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be run regardless of
whether an exception is raised while calling the Module.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_forward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is false or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
input. User can either return a tuple or a single modified value in the
hook. We will wrap the value into a tuple if a single value is returned
(unless that value is already a tuple). The hook should have the
following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is true, the forward pre-hook will be passed the
kwargs given to the forward function. And if the hook modifies the
input, both the args and kwargs should be returned. The hook should have
the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">a</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">modified</span> <span class="nb">input</span> <span class="ow">and</span> <span class="n">kwargs</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_pre_hook()</span></code> will fire before all
hooks registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If true, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the kwargs
given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_full_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to a module
are computed, i.e. the hook will execute if and only if the gradients with
respect to module outputs are computed. The hook should have the following
signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in
subsequent computations. <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for all non-Tensor
arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_full_backward_pre_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_full_backward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward pre-hook on the module.</p>
<p>The hook will be called every time the gradients for the module are computed.
The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> is a tuple. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the output that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> in
subsequent computations. Entries in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for
all non-Tensor arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_pre_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_load_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_load_state_dict_post_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a post hook to be run after module’s <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code>
is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, incompatible_keys) -&gt; None</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">module</span></code> argument is the current module that this hook is registered
on, and the <code class="docutils literal notranslate"><span class="pre">incompatible_keys</span></code> argument is a <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> consisting
of attributes <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>. <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code>
is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the missing keys and
<code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the unexpected keys.</p>
<p>The given incompatible_keys can be modified inplace if needed.</p>
<p>Note that the checks performed when calling <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">strict=True</span></code> are affected by modifications the hook makes to
<code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> or <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>, as expected. Additions to either
set of keys will result in an error being thrown when <code class="docutils literal notranslate"><span class="pre">strict=True</span></code>, and
clearing out both missing and unexpected keys will avoid an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_module">
<span class="sig-name descname"><span class="pre">register_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_parameter">
<span class="sig-name descname"><span class="pre">register_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the parameter. The parameter can be accessed
from this module using the given name</p></li>
<li><p><strong>param</strong> (<em>Parameter</em><em> or </em><em>None</em>) – parameter to be added to the module. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations that run on parameters, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>,
are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the parameter is <strong>not</strong> included in the
module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.register_state_dict_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>,
and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>. The registered
hooks can be used to perform pre-processing before the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>
call is made.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.requires_grad_" title="Permalink to this definition">¶</a></dt>
<dd><p>Change if autograd should record operations on parameters in this
module.</p>
<p>This method sets the parameters’ <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.requires_grad_()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<em>bool</em>) – whether autograd should record operations on
parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters">
<span class="sig-name descname"><span class="pre">save_hyperparameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.save_hyperparameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – single object of <cite>dict</cite>, <cite>NameSpace</cite> or <cite>OmegaConf</cite>
or string names or arguments from class <code class="docutils literal notranslate"><span class="pre">__init__</span></code></p></li>
<li><p><strong>ignore</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – an argument name or a list of argument names from
class <code class="docutils literal notranslate"><span class="pre">__init__</span></code> to be ignored</p></li>
<li><p><strong>frame</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">frame</span></code>]) – a frame object. Default is None</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to send the hyperparameters to the logger. Default: True</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Example::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign arguments</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="s1">&#39;arg1&#39;</span><span class="p">,</span> <span class="s1">&#39;arg3&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AutomaticArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># equivalent automatic</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutomaticArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg2&quot;: abc</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">SingleArgModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign single argument</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleArgModel</span><span class="p">(</span><span class="n">Namespace</span><span class="p">(</span><span class="n">p1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p2</span><span class="o">=</span><span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="n">p3</span><span class="o">=</span><span class="mf">3.14</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;p1&quot;: 1</span>
<span class="go">&quot;p2&quot;: abc</span>
<span class="go">&quot;p3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># pass argument(s) to ignore as a string or in a list</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="s1">&#39;arg2&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state
found within the <cite>state_dict</cite>. Implement this function and a corresponding
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.get_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_extra_state()</span></code></a> for your module if you need to store extra state within its
<cite>state_dict</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>dict</em>) – Extra state from the <cite>state_dict</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_mc_dropout">
<span class="sig-name descname"><span class="pre">set_mc_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">active</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.set_mc_dropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_mc_dropout" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_predict_parameters">
<span class="sig-name descname"><span class="pre">set_predict_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roll_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.set_predict_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_predict_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you
need to build models dynamically or adjust something about them. This hook is called on every process when
using DDP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">download_data</span><span class="p">()</span>
        <span class="n">tokenize</span><span class="p">()</span>

        <span class="c1"># don&#39;t do this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">something</span> <span class="o">=</span> <span class="k">else</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.share_memory">
<span class="sig-name descname"><span class="pre">share_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.share_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>~T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary containing references to the whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to <code class="docutils literal notranslate"><span class="pre">None</span></code> are not included.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned object is a shallow copy. It contains references
to the module’s parameters and buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> also accepts positional arguments for
<code class="docutils literal notranslate"><span class="pre">destination</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> in order. However,
this is being deprecated and keyword arguments will be enforced in
future releases.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please avoid the use of argument <code class="docutils literal notranslate"><span class="pre">destination</span></code> as it is not
designed for end-users.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>destination</strong> (<em>dict</em><em>, </em><em>optional</em>) – If provided, the state of module will
be updated into the dict and the same object is returned.
Otherwise, an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> will be created and returned.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em>) – a prefix added to parameter and buffer
names to compose the keys in state_dict. Default: <code class="docutils literal notranslate"><span class="pre">''</span></code>.</p></li>
<li><p><strong>keep_vars</strong> (<em>bool</em><em>, </em><em>optional</em>) – by default the <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> s
returned in the state dict are detached from autograd. If it’s
set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, detaching will not be performed.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary containing a whole state of the module</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.teardown">
<span class="sig-name descname"><span class="pre">teardown</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.teardown" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of fit (train + validate), validate, test, or predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_dataloader">
<span class="sig-name descname"><span class="pre">test_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying test samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">test()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a test dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a>, you don’t need to implement
this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the test set. In this step you’d normally generate examples or
calculate anything of interest such as accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your data iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><strong>batch_idx</strong> – The index of this batch.</p></li>
<li><p><strong>dataloader_idx</strong> – The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Skip to the next batch.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one test dataloader:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="o">...</span>

<span class="c1"># if you have multiple test dataloaders:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single test dataset</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple test dataloaders, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple test dataloaders</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="o">...</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need to test you don’t need to implement this method.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> is called, the model has been put in eval mode and
PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
to training mode and gradients are enabled.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_dtype">
<span class="sig-name descname"><span class="pre">to_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.to_dtype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Cast module precision (float32 by default) to another precision.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_empty" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves the parameters and buffers to the specified device without copying storage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>) – The desired device of the parameters
and buffers in this module.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – Whether parameters and buffers of submodules should
be recursively moved to the specified device.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_onnx">
<span class="sig-name descname"><span class="pre">to_onnx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_onnx" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the model in ONNX format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>]) – The path of the file the onnx model should be saved to.</p></li>
<li><p><strong>input_sample</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input for tracing. Default: None (Use self.example_input_array)</p></li>
<li><p><strong>**kwargs</strong> – Will be passed to torch.onnx.export function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">input_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">(</span><span class="s2">&quot;export.onnx&quot;</span><span class="p">,</span> <span class="n">input_sample</span><span class="p">,</span> <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_torchscript">
<span class="sig-name descname"><span class="pre">to_torchscript</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'script'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_torchscript" title="Permalink to this definition">¶</a></dt>
<dd><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>. If you want to use tracing,
please provided the argument <code class="docutils literal notranslate"><span class="pre">method='trace'</span></code> and make sure that either the <cite>example_inputs</cite> argument is
provided, or the model has <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a> set. If you would like to customize the modules that are
scripted you should override this method. In case you want to return multiple modules, we recommend using a
dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Path where to save the torchscript. Default: None (no file saved).</p></li>
<li><p><strong>method</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Whether to use TorchScript’s script or trace method. Default: ‘script’</p></li>
<li><p><strong>example_inputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input to be used to do tracing when method is set to ‘trace’.
Default: None (uses <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments that will be passed to the <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.script()</span></code> or
<code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.trace()</span></code> function.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Requires the implementation of the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> method.</p></li>
<li><p>The exported script will be set to evaluation mode.</p></li>
<li><p>It is recommended that you install the latest supported version of PyTorch
to use this feature without limitations. See also the <code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.jit</span></code>
documentation for supported features.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span>
    <span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model_trace.pt&quot;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;trace&#39;</span><span class="p">,</span> <span class="n">example_inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>]]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>This LightningModule as a torchscript, regardless of whether <cite>file_path</cite> is
defined or not.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.toggle_optimizer">
<span class="sig-name descname"><span class="pre">toggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.toggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Makes sure only the gradients of the current optimizer’s parameters are calculated in the training step to
prevent dangling gradients in multiple-optimizer setup.</p>
<p>It works with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.untoggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">untoggle_optimizer()</span></code></a> to make sure <code class="docutils literal notranslate"><span class="pre">param_requires_grad_state</span></code> is properly reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to toggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.train_dataloader">
<span class="sig-name descname"><span class="pre">train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.train_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying training samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id11"><span class="problematic" id="id12">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.trainer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">trainer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.trainer.trainer.Trainer</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.trainer" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.training_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the training step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.transfer_batch_to_device">
<span class="sig-name descname"><span class="pre">transfer_batch_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.transfer_batch_to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data
structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code> or anything that implements <cite>.to(…)</cite></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, …).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook should only transfer the data and not modify it, nor should it move the data to
any other device than the one passed in as argument (unless you know what you are doing).
To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be transferred to a new device.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>) – The target device as defined in PyTorch.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A reference to the data on the new device.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">CustomBatch</span><span class="p">):</span>
        <span class="c1"># move all tensors in your custom data structure to the device</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># skip device transfer for the first dataloader or anything you wish</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transfer_batch_to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">move_data_to_device()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_to_collection()</span></code></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.type">
<span class="sig-name descname"><span class="pre">type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.type" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.unfreeze">
<span class="sig-name descname"><span class="pre">unfreeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze all parameters for training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.untoggle_optimizer">
<span class="sig-name descname"><span class="pre">untoggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.untoggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to untoggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.val_dataloader">
<span class="sig-name descname"><span class="pre">val_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.val_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying validation samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id13"><span class="problematic" id="id14">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">validate()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a validation dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a>, you don’t need to
implement this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLForecastingModule.validation_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the validation step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.xpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the XPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLForecastingModule.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets gradients of all model parameters. See similar function
under <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code> for more context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>set_to_none</strong> (<em>bool</em>) – instead of setting to zero, set the grads to None.
See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for details.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">darts.models.forecasting.pl_forecasting_module.</span></span><span class="sig-name descname"><span class="pre">PLFutureCovariatesModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_sample_shape=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn=MSELoss()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_metrics=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_cls=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_cls=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_reversible_instance_norm=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLFutureCovariatesModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">darts.models.forecasting.pl_forecasting_module.PLForecastingModule</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>PyTorch Lightning-based Forecasting Module.</p>
<p>This class is meant to be inherited to create a new PyTorch Lightning-based forecasting module.
When subclassing this class, please make sure to add the following methods with the given signatures:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.__init__()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.forward()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._produce_train_output()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._get_batch_prediction()</span></code></p></li>
</ul>
</div></blockquote>
<p>In subclass <cite>MyModel</cite>’s <code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code> function call <code class="docutils literal notranslate"><span class="pre">super(MyModel,</span> <span class="pre">self).__init__(**kwargs)</span></code> where
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> are the parameters of <code class="xref py py-class docutils literal notranslate"><span class="pre">PLTorchForecastingModel</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps in the past to take as a model input (per chunk). Applies to the target
series, and past and/or future covariates (if the model supports it).</p></li>
<li><p><strong>output_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps predicted at once (per chunk) by the internal model. Also, the number of future values
from future covariates to use as a model input (if the model supports future covariates). It is not the same
as forecast horizon <cite>n</cite> used in <cite>predict()</cite>, which is the desired number of prediction points generated
using either a one-shot- or auto-regressive forecast. Setting <cite>n &lt;= output_chunk_length</cite> prevents
auto-regression. This is useful when the covariates don’t extend far enough into the future, or to prohibit
the model from using future values of past and / or future covariates for prediction (depending on the
model’s covariate support).</p></li>
<li><p><strong>train_sample_shape</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Shape of the model’s input, used to instantiate model without calling <code class="docutils literal notranslate"><span class="pre">fit_from_dataset</span></code> and
perform sanity check on new training/inference datasets used for re-training or prediction.</p></li>
<li><p><strong>loss_fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code>) – PyTorch loss function used for training.
This parameter will be ignored for probabilistic models if the <code class="docutils literal notranslate"><span class="pre">likelihood</span></code> parameter is specified.
Default: <code class="docutils literal notranslate"><span class="pre">torch.nn.MSELoss()</span></code>.</p></li>
<li><p><strong>torch_metrics</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – A torch metric or a <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code> used for evaluation. A full list of available metrics can be found
at <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/">https://torchmetrics.readthedocs.io/en/latest/</a>. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>likelihood</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code></a>]) – One of Darts’ <a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Likelihood</span></code></a> models to be used for
probabilistic forecasts. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>optimizer_cls</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The PyTorch optimizer class to be used. Default: <code class="docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code>.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch optimizer (e.g., <code class="docutils literal notranslate"><span class="pre">{'lr':</span> <span class="pre">1e-3}</span></code>
for specifying a learning rate). Otherwise the default values of the selected <code class="docutils literal notranslate"><span class="pre">optimizer_cls</span></code>
will be used. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_cls</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_LRScheduler</span></code>]) – Optionally, the PyTorch learning rate scheduler class to be used. Specifying <code class="docutils literal notranslate"><span class="pre">None</span></code> corresponds
to using a constant learning rate. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch learning rate scheduler. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>use_reversible_instance_norm</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to use reversible instance normalization <cite>RINorm</cite> against distribution shift as shown in <a class="reference internal" href="#r0fdf7d5ba27f-1" id="id15">[1]</a>.
It is only applied to the features of the target series and not the covariates.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r0fdf7d5ba27f-1"><span class="brackets"><a class="fn-backref" href="#id15">1</a></span></dt>
<dd><p>T. Kim et al. “Reversible Instance Normalization for Accurate Time-Series Forecasting against
Distribution Shift”, <a class="reference external" href="https://openreview.net/forum?id=cGDAkQo1C0p">https://openreview.net/forum?id=cGDAkQo1C0p</a></p>
</dd>
</dl>
<p class="rubric">Attributes</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.automatic_optimization" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.automatic_optimization"><code class="xref py py-obj docutils literal notranslate"><span class="pre">automatic_optimization</span></code></a></p></td>
<td><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.current_epoch" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.current_epoch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">current_epoch</span></code></a></p></td>
<td><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.example_input_array"><code class="xref py py-obj docutils literal notranslate"><span class="pre">example_input_array</span></code></a></p></td>
<td><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.global_rank" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.global_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_rank</span></code></a></p></td>
<td><p>The index of the current process across all nodes and devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.global_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.global_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_step</span></code></a></p></td>
<td><p>Total training batches seen across all epochs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams_initial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams_initial</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.local_rank" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.local_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">local_rank</span></code></a></p></td>
<td><p>The index of the current process within a single node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.logger" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.logger"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logger</span></code></a></p></td>
<td><p>Reference to the logger object in the Trainer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.loggers" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.loggers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">loggers</span></code></a></p></td>
<td><p>Reference to the list of loggers in the Trainer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_gpu" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_gpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_gpu</span></code></a></p></td>
<td><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.output_chunk_length" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.output_chunk_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_chunk_length</span></code></a></p></td>
<td><p>Number of time steps predicted at once by the model.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>device</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>dtype</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>epochs_trained</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>fabric</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>trainer</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.add_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_module</span></code></a>(name, module)</p></td>
<td><p>Adds a child module to the current module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.all_gather" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.all_gather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">all_gather</span></code></a>(data[, group, sync_grads])</p></td>
<td><p>Gather tensors or collections of tensors from multiple processes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.apply" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.backward" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.bfloat16" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.bfloat16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfloat16</span></code></a>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.buffers" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">buffers</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.children" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.clip_gradients" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.clip_gradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip_gradients</span></code></a>(optimizer[, ...])</p></td>
<td><p>Handles gradient clipping internally.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.compile" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(*args, **kwargs)</p></td>
<td><p>Compile this Module's forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_callbacks" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_callbacks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_callbacks</span></code></a>()</p></td>
<td><p>Configure model-specific callbacks.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_gradient_clipping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_gradient_clipping</span></code></a>(optimizer[, ...])</p></td>
<td><p>Perform gradient clipping for the optimizer parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_model" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_model</span></code></a>()</p></td>
<td><p>Hook to create modules in a strategy and precision aware context.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_optimizers" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_optimizers</span></code></a>()</p></td>
<td><p>configures optimizers and learning rate schedulers for model optimization.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_sharded_model" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_sharded_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_sharded_model</span></code></a>()</p></td>
<td><p>Deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_torch_metrics" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_torch_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_torch_metrics</span></code></a>(torch_metrics)</p></td>
<td><p>process the torch_metrics parameter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cpu" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cuda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.double" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.double"><code class="xref py py-obj docutils literal notranslate"><span class="pre">double</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.eval" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code></a>()</p></td>
<td><p>Sets the module in evaluation mode.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.extra_repr" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.extra_repr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extra_repr</span></code></a>()</p></td>
<td><p>Set the extra representation of the module</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(*args, **kwargs)</p></td>
<td><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.freeze" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.freeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">freeze</span></code></a>()</p></td>
<td><p>Freeze all params for inference.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_buffer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_buffer</span></code></a>(target)</p></td>
<td><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_extra_state</span></code></a>()</p></td>
<td><p>Returns any extra state to include in the module's state_dict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_parameter" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_parameter</span></code></a>(target)</p></td>
<td><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_submodule" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_submodule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_submodule</span></code></a>(target)</p></td>
<td><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.half" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.half"><code class="xref py py-obj docutils literal notranslate"><span class="pre">half</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.ipu" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.ipu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ipu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the IPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_from_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_from_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code></a>([map_location, ...])</p></td>
<td><p>Primary way of loading a model from a checkpoint.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>(state_dict[, strict, assign])</p></td>
<td><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.log" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log</span></code></a>(name, value[, prog_bar, logger, ...])</p></td>
<td><p>Log a key, value pair.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.log_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.log_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_dict</span></code></a>(dictionary[, prog_bar, logger, ...])</p></td>
<td><p>Log a dictionary of values at once.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.lr_scheduler_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.lr_scheduler_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_scheduler_step</span></code></a>(scheduler, metric)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls each scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.lr_schedulers" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.lr_schedulers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_schedulers</span></code></a>()</p></td>
<td><p>Returns the learning rate scheduler(s) that are being used during training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.manual_backward" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.manual_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">manual_backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.modules" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">modules</span></code></a>()</p></td>
<td><p>Returns an iterator over all modules in the network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_buffers" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_buffers</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_children" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_modules" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_modules</span></code></a>([memo, prefix, remove_duplicate])</p></td>
<td><p>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_parameters" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_after_backward" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_after_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_backward</span></code></a>()</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_after_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_backward" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_backward</span></code></a>(loss)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code></a>(optimizer)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_zero_grad</span></code></a>(optimizer)</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_fit_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_fit_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_end</span></code></a>()</p></td>
<td><p>Called at the very end of fit.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_fit_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_fit_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_start</span></code></a>()</p></td>
<td><p>Called at the very beginning of fit.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_load_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_load_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_load_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning to restore your model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the predict loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the predict loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the predict loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_save_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_save_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to save.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the test loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the test loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_end</span></code></a>()</p></td>
<td><p>Called at the end of testing.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_end</span></code></a>()</p></td>
<td><p>Called in the test loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_start</span></code></a>()</p></td>
<td><p>Called in the test loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the test loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_model_train" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the test loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_start</span></code></a>()</p></td>
<td><p>Called at the beginning of testing.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the training loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the training loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_end</span></code></a>()</p></td>
<td><p>Called at the end of training before logger experiment is closed.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_end</span></code></a>()</p></td>
<td><p>Called in the training loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_start</span></code></a>()</p></td>
<td><p>Called in the training loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_start</span></code></a>()</p></td>
<td><p>Called at the beginning of training after sanity check.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_end</span></code></a>(outputs, batch, ...)</p></td>
<td><p>Called in the validation loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the validation loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_end</span></code></a>()</p></td>
<td><p>Called at the end of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_end</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_start</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the val loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_train" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the val loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_zero_grad</span></code></a>()</p></td>
<td><p>Called by the training loop to release gradients before entering the validation loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_start" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_start</span></code></a>()</p></td>
<td><p>Called at the beginning of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_step</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls the optimizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizer_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizer_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_zero_grad</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizers" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizers</span></code></a>([use_pl_optimizer])</p></td>
<td><p>Returns the optimizer(s) that are being used during training.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.parameters" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.predict_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.predict_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying prediction samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.predict_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.predict_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_step</span></code></a>(batch, batch_idx[, dataloader_idx])</p></td>
<td><p>performs the prediction step</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare_data</span></code></a>()</p></td>
<td><p>Use this to download and prepare data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.print" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.print"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print</span></code></a>(*args, **kwargs)</p></td>
<td><p>Prints only from process 0.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_backward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_buffer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_buffer</span></code></a>(name, tensor[, persistent])</p></td>
<td><p>Adds a buffer to the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_forward_hook" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook, *[, prepend, ...])</p></td>
<td><p>Registers a forward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_forward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook, *[, ...])</p></td>
<td><p>Registers a forward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_full_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_full_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_full_backward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_full_backward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_pre_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_load_state_dict_post_hook" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_load_state_dict_post_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_load_state_dict_post_hook</span></code></a>(hook)</p></td>
<td><p>Registers a post hook to be run after module's <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> is called.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_module" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_module</span></code></a>(name, module)</p></td>
<td><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_parameter" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_parameter</span></code></a>(name, param)</p></td>
<td><p>Adds a parameter to the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_state_dict_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_state_dict_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_state_dict_pre_hook</span></code></a>(hook)</p></td>
<td><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>, and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.requires_grad_" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.requires_grad_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad_</span></code></a>([requires_grad])</p></td>
<td><p>Change if autograd should record operations on parameters in this module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_hyperparameters</span></code></a>(*args[, ignore, frame, ...])</p></td>
<td><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_extra_state</span></code></a>(state)</p></td>
<td><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state found within the <cite>state_dict</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_predict_parameters" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_predict_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_predict_parameters</span></code></a>(n, num_samples, ...)</p></td>
<td><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>(stage)</p></td>
<td><p>Called at the beginning of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.share_memory" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.share_memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_memory</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code></a>(*args[, destination, prefix, ...])</p></td>
<td><p>Returns a dictionary containing references to the whole state of the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.teardown" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.teardown"><code class="xref py py-obj docutils literal notranslate"><span class="pre">teardown</span></code></a>(stage)</p></td>
<td><p>Called at the end of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying test samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_step</span></code></a>(*args, **kwargs)</p></td>
<td><p>Operates on a single batch of data from the test set.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_dtype" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_dtype</span></code></a>(dtype)</p></td>
<td><p>Cast module precision (float32 by default) to another precision.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_empty" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_empty</span></code></a>(*, device[, recurse])</p></td>
<td><p>Moves the parameters and buffers to the specified device without copying storage.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_onnx" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_onnx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_onnx</span></code></a>(file_path[, input_sample])</p></td>
<td><p>Saves the model in ONNX format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_torchscript" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_torchscript"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_torchscript</span></code></a>([file_path, method, ...])</p></td>
<td><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.toggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">toggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Makes sure only the gradients of the current optimizer's parameters are calculated in the training step to prevent dangling gradients in multiple-optimizer setup.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.train" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>([mode])</p></td>
<td><p>Sets the module in training mode.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.train_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.train_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying training samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">training_step</span></code></a>(train_batch, batch_idx)</p></td>
<td><p>performs the training step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.transfer_batch_to_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transfer_batch_to_device</span></code></a>(batch, device, ...)</p></td>
<td><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data structure.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.type" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code></a>(dst_type)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.unfreeze" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.unfreeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unfreeze</span></code></a>()</p></td>
<td><p>Unfreeze all parameters for training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.untoggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">untoggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.val_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.val_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">val_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying validation samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.validation_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">validation_step</span></code></a>(val_batch, batch_idx)</p></td>
<td><p>performs the validation step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.xpu" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.xpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xpu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the XPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>([set_to_none])</p></td>
<td><p>Resets gradients of all model parameters.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>__call__</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_mc_dropout</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.CHECKPOINT_HYPER_PARAMS_KEY">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_KEY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hyper_parameters'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.CHECKPOINT_HYPER_PARAMS_KEY" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.CHECKPOINT_HYPER_PARAMS_NAME">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_name'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.CHECKPOINT_HYPER_PARAMS_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.CHECKPOINT_HYPER_PARAMS_TYPE">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_TYPE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_type'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.CHECKPOINT_HYPER_PARAMS_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.T_destination">
<span class="sig-name descname"><span class="pre">T_destination</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.T_destination" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of TypeVar(‘T_destination’, bound=<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>])</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.add_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the child module. The child module can be
accessed from this module using the given name</p></li>
<li><p><strong>module</strong> (<em>Module</em>) – child module to be added to the module.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.all_gather">
<span class="sig-name descname"><span class="pre">all_gather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.all_gather" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather tensors or collections of tensors from multiple processes.</p>
<p>This method needs to be called on all processes and the tensors need to have the same shape across all
processes, otherwise your program will stall forever.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – int, float, tensor of shape (batch, …), or a (possibly nested) collection thereof.</p></li>
<li><p><strong>group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the process group to gather results from. Defaults to all processes (world)</p></li>
<li><p><strong>sync_grads</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – flag that allows users to synchronize gradients for the all_gather operation</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor of shape (world_size, batch, …), or if the input was a collection
the output will also be a collection with tensors of this shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.allow_zero_length_dataloader_with_multiple_devices" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>)
as well as self. Typical use includes initializing the parameters of a model
(see also <span class="xref std std-ref">nn-init-doc</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> -&gt; None) – function to be applied to each submodule</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.automatic_optimization">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">automatic_optimization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.automatic_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. Override this hook with your own
implementation if you need to.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The loss tensor returned by <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. If gradient accumulation is used, the loss here
holds the normalized value (scaled by 1 / accumulation steps).</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.bfloat16">
<span class="sig-name descname"><span class="pre">bfloat16</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.bfloat16" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.buffers">
<span class="sig-name descname"><span class="pre">buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – module buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.call_super_init">
<span class="sig-name descname"><span class="pre">call_super_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.call_super_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a child module</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.clip_gradients">
<span class="sig-name descname"><span class="pre">clip_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.clip_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Handles gradient clipping internally.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Do not override this method. If you want to customize gradient clipping, consider using
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_gradient_clipping"><code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_gradient_clipping()</span></code></a> method.</p></li>
<li><p>For manual optimization (<code class="docutils literal notranslate"><span class="pre">self.automatic_optimization</span> <span class="pre">=</span> <span class="pre">False</span></code>), if you want to use
gradient clipping, consider calling
<code class="docutils literal notranslate"><span class="pre">self.clip_gradients(opt,</span> <span class="pre">gradient_clip_val=0.5,</span> <span class="pre">gradient_clip_algorithm=&quot;norm&quot;)</span></code>
manually in the training step.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. Pass <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;value&quot;</span></code>
to clip by value, and <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;norm&quot;</span></code> to clip by norm.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.compile" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile this Module’s forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>This Module’s <cite>__call__</cite> method is compiled and all arguments are passed as-is
to <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>See <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code> for details on the arguments for this function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_callbacks">
<span class="sig-name descname"><span class="pre">configure_callbacks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_callbacks" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure model-specific callbacks. When the model gets attached, e.g., when <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> or <code class="docutils literal notranslate"><span class="pre">.test()</span></code> gets
called, the list or a callback returned here will be merged with the list of callbacks passed to the Trainer’s
<code class="docutils literal notranslate"><span class="pre">callbacks</span></code> argument. If a callback returned here has the same type as one or several callbacks already
present in the Trainer’s callbacks list, it will take priority and replace them. In addition, Lightning will
make sure <code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> callbacks run last.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A callback or a list of callbacks which will extend the list of callbacks in the Trainer.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">early_stop</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_gradient_clipping">
<span class="sig-name descname"><span class="pre">configure_gradient_clipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_gradient_clipping" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform gradient clipping for the optimizer parameters. Called before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizer_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients. By default, value passed in Trainer
will be available here.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. By default, value
passed in Trainer will be available here.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_gradient_clipping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="p">,</span> <span class="n">gradient_clip_algorithm</span><span class="p">):</span>
    <span class="c1"># Implement your own custom logic to clip gradients</span>
    <span class="c1"># You can call `self.clip_gradients` with your settings:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="o">=</span><span class="n">gradient_clip_val</span><span class="p">,</span>
        <span class="n">gradient_clip_algorithm</span><span class="o">=</span><span class="n">gradient_clip_algorithm</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_model">
<span class="sig-name descname"><span class="pre">configure_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook to create modules in a strategy and precision aware context.</p>
<p>This is particularly useful for when using sharded strategies (FSDP and DeepSpeed), where we’d like to shard
the model instantly to save memory and initialization time.
For non-sharded strategies, you can choose to override this hook or to initialize your model under the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">init_module()</span></code> context manager.</p>
<p>This hook is called during each of fit/val/test/predict stages in the same process, so ensure that
implementation of this hook is idempotent.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>configures optimizers and learning rate schedulers for model optimization.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_sharded_model">
<span class="sig-name descname"><span class="pre">configure_sharded_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_sharded_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Deprecated.</p>
<p>Use <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_model()</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_torch_metrics">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">configure_torch_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">torch_metrics</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.configure_torch_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>process the torch_metrics parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cuda" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the GPU. This also makes associated parameters and buffers
different objects. So it should be called before constructing optimizer if the module will live on GPU while
being optimized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If specified, all parameters will be copied to that device. If <cite>None</cite>, the current CUDA device
index will be used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.current_epoch">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">current_epoch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.current_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.device</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.device" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.double" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.dtype</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.dtype" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dtype</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.dump_patches">
<span class="sig-name descname"><span class="pre">dump_patches</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.dump_patches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.epochs_trained">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">epochs_trained</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.epochs_trained" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code>.</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.eval()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.example_input_array">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">example_input_array</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.example_input_array" title="Permalink to this definition">¶</a></dt>
<dd><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method. The
return type is interpreted as follows:</p>
<ul class="simple">
<li><p>Single tensor: It is assumed the model takes a single argument, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(model.example_input_array)</span></code></p></li>
<li><p>Tuple: The input array should be interpreted as a sequence of positional arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(*model.example_input_array)</span></code></p></li>
<li><p>Dict: The input array represents named keyword arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(**model.example_input_array)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.fabric">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fabric</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.fabric.Fabric</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.fabric" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fabric</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Whatever you decide to pass into the forward method.</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments are also possible.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Your model’s output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.freeze">
<span class="sig-name descname"><span class="pre">freeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze all params for inference.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the buffer
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The buffer referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not a
buffer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns any extra state to include in the module’s state_dict.
Implement this and a corresponding <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_extra_state()</span></code></a> for your module
if you need to store extra state. This function is called when building the
module’s <cite>state_dict()</cite>.</p>
<p>Note that extra state should be picklable to ensure working serialization
of the state_dict. We only provide provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Any extra state to store in the module’s state_dict</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_parameter">
<span class="sig-name descname"><span class="pre">get_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the Parameter
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Parameter referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To check whether or not we have the <code class="docutils literal notranslate"><span class="pre">linear</span></code> submodule, we
would call <code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.linear&quot;)</span></code>. To check whether
we have the <code class="docutils literal notranslate"><span class="pre">conv</span></code> submodule, we would call
<code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.net_c.conv&quot;)</span></code>.</p>
<p>The runtime of <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> is bounded by the degree
of module nesting in <code class="docutils literal notranslate"><span class="pre">target</span></code>. A query against
<code class="docutils literal notranslate"><span class="pre">named_modules</span></code> achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists, <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> should always be
used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The submodule referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.global_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.global_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process across all nodes and devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.global_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.global_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Total training batches seen across all epochs.</p>
<p>If no Trainer is attached, this propery is 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.half" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">MutableMapping</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. It is mutable by the user. For
the frozen set of initial hyperparameters, use <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams_initial"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams_initial</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">AttributeDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MutableMapping</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mutable hyperparameters dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams_initial">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams_initial</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams_initial" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. These contents are read-only.
Manual updates to the saved hyperparameters can instead be performed through <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.hparams"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>immutable initial hyperparameters</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>AttributeDict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.ipu">
<span class="sig-name descname"><span class="pre">ipu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.ipu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the IPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on IPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_from_checkpoint">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_from_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments
passed to <code class="docutils literal notranslate"><span class="pre">__init__</span></code>  in the checkpoint under <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<p>Any arguments specified through **kwargs will override args stored in <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">IO</span></code>]) – Path to checkpoint. This can also be a URL, or file-like object</p></li>
<li><p><strong>map_location</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If your checkpoint saved a GPU model and you now load on CPUs
or a different number of GPUs, use this to map to the new setup.
The behaviour is the same as in <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code>.</p></li>
<li><p><strong>hparams_file</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optional path to a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> or <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file with hierarchical structure
as in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">drop_prob</span><span class="p">:</span> <span class="mf">0.2</span>
<span class="n">dataloader</span><span class="p">:</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="mi">32</span>
</pre></div>
</div>
<p>You most likely won’t need this since Lightning will always save the hyperparameters
to the checkpoint.
However, if your checkpoint weights don’t have the hyperparameters saved,
use this method to pass in a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file with the hparams you’d like to use.
These will be converted into a <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> and passed into your
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> for use.</p>
<p>If your model’s <code class="docutils literal notranslate"><span class="pre">hparams</span></code> argument is <code class="xref py py-class docutils literal notranslate"><span class="pre">Namespace</span></code>
and <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file has hierarchical structure, you need to refactor your model to treat
<code class="docutils literal notranslate"><span class="pre">hparams</span></code> as <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>.</p>
</p></li>
<li><p><strong>strict</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to strictly enforce that the keys in <code class="xref py py-attr docutils literal notranslate"><span class="pre">checkpoint_path</span></code> match the keys
returned by this module’s state dict.</p></li>
<li><p><strong>**kwargs</strong> – Any extra keyword args needed to init the model. Can also be used to override saved
hyperparameter values.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance with loaded weights and hyperparameters (if available).</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code> is a <strong>class</strong> method. You should use your <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code>
<strong>class</strong> to call it instead of the <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance, or a
<code class="docutils literal notranslate"><span class="pre">TypeError</span></code> will be raised.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load weights without mapping ...</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">)</span>

<span class="c1"># or load weights mapping all weights from GPU 1 to GPU 0 ...</span>
<span class="n">map_location</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span>
<span class="p">)</span>

<span class="c1"># or load weights and hyperparameters from separate files.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">hparams_file</span><span class="o">=</span><span class="s1">&#39;/path/to/hparams_file.yaml&#39;</span>
<span class="p">)</span>

<span class="c1"># override some of the params with new values</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="n">PATH</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">pretrained_ckpt_path</span><span class="o">=</span><span class="n">NEW_PATH</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># predict</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">pretrained_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into
this module and its descendants. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> the optimizer must be created after
the call to <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>dict</em>) – a dict containing parameters and
persistent buffers.</p></li>
<li><p><strong>strict</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to strictly enforce that the keys
in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this module’s
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>assign</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to assign items in the state
dictionary to their corresponding keys in the module instead
of copying them inplace into the module’s current parameters and buffers.
When <code class="docutils literal notranslate"><span class="pre">False</span></code>, the properties of the tensors in the current
module are preserved while when <code class="docutils literal notranslate"><span class="pre">True</span></code>, the properties of the
Tensors in the state dict are preserved.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>missing_keys</strong> is a list of str containing the missing keys</p></li>
<li><p><strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a parameter or buffer is registered as <code class="docutils literal notranslate"><span class="pre">None</span></code> and its corresponding key
exists in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> will raise a
<code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code>.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.local_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">local_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.local_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process within a single node.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_attribute</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a key, value pair.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>The default behavior per hook is documented here: <span class="xref std std-ref">extensions/logging:Automatic Logging</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – key to log.</p></li>
<li><p><strong>value</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]) – value to log. Can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, or a <code class="docutils literal notranslate"><span class="pre">Metric</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress bar.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto detach the graph.</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across devices. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the DDP group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple dataloaders). If False, user needs to give unique names for
each dataloader to not mix the values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch_size. This will be directly inferred from the loaded batch,
but for some data structures you might need to explicitly provide it.</p></li>
<li><p><strong>metric_attribute</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – To restore the metric state, Lightning requires the reference of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code> in your model. This is found automatically if it is a model attribute.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.log_dict">
<span class="sig-name descname"><span class="pre">log_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dictionary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.log_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a dictionary of values at once.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="s1">&#39;metric_n&#39;</span><span class="p">:</span> <span class="n">metric_n</span><span class="p">}</span>
<span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dictionary</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>]) – key value pairs.
The values can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">Metric</span></code>, or <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress base.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for training_step but not validation/test_step.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for val/test step but not <code class="docutils literal notranslate"><span class="pre">training_step</span></code>.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto-detach the graph</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across GPUs/TPUs. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the ddp group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple). If <code class="docutils literal notranslate"><span class="pre">False</span></code>, user needs to give unique names for
each dataloader to not mix values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch size. This will be directly inferred from the loaded batch,
but some data structures might need to explicitly provide it.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.logger">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.logger" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the logger object in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.loggers">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">loggers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.loggers" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the list of loggers in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.lr_scheduler_step">
<span class="sig-name descname"><span class="pre">lr_scheduler_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.lr_scheduler_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
each scheduler. By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and as shown in the example for each scheduler based on
its <code class="docutils literal notranslate"><span class="pre">interval</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scheduler</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]) – Learning rate scheduler.</p></li>
<li><p><strong>metric</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Value of the monitor used for schedulers like <code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>

<span class="c1"># Alternative way to update schedulers if it requires an epoch value</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.lr_schedulers">
<span class="sig-name descname"><span class="pre">lr_schedulers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.lr_schedulers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the learning rate scheduler(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A single scheduler, or a list of schedulers in case multiple ones are present, or <code class="docutils literal notranslate"><span class="pre">None</span></code> if no
schedulers were returned in <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_optimizers()</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.manual_backward">
<span class="sig-name descname"><span class="pre">manual_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.manual_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually. By using this,
Lightning can ensure that all the proper scaling gets applied when using mixed precision.</p>
<p>See <span class="xref std std-ref">manual optimization</span> for more examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># automatically applies scaling, etc...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The tensor on which to compute gradients. Must have a graph attached.</p></li>
<li><p><strong>*args</strong> – Additional positional arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a module in the network</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all buffer names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module. Defaults to True.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated buffers in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, torch.Tensor)</em> – Tuple containing the name and buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_children">
<span class="sig-name descname"><span class="pre">named_children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>(str, Module)</em> – Tuple containing a name and child module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_modules">
<span class="sig-name descname"><span class="pre">named_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>memo</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Set</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]) – a memo to store the set of modules already added to the result</p></li>
<li><p><strong>prefix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – a prefix that will be added to the name of the module</p></li>
<li><p><strong>remove_duplicate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – whether to remove the duplicated module instances in the result
or not</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Module)</em> – Tuple of name and module</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated
parameters in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Parameter)</em> – Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_after_backward">
<span class="sig-name descname"><span class="pre">on_after_backward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_after_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If using native AMP, the gradients will not be unscaled at this point.
Use the <code class="docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code> if you need the unscaled gradients.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_after_batch_transfer">
<span class="sig-name descname"><span class="pre">on_after_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_after_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gpu_transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_before_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_backward">
<span class="sig-name descname"><span class="pre">on_before_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Loss divided by number of batches for gradient accumulation and scaled if using AMP.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_batch_transfer">
<span class="sig-name descname"><span class="pre">on_before_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_after_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_after_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_optimizer_step">
<span class="sig-name descname"><span class="pre">on_before_optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p>
<p>If using gradient accumulation, the hook is called once the gradients have been accumulated.
See: <a href="#id16"><span class="problematic" id="id17">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.accumulate_grad_batches`</span></a>.</p>
<p>If using AMP, the loss will be unscaled before calling this hook.
See these <a class="reference external" href="https://pytorch.org/docs/stable/notes/amp_examples.html#working-with-unscaled-gradients">docs</a>
for more information on the scaling of gradients.</p>
<p>If clipping gradients, the gradients will not have been clipped yet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="c1"># example to inspect gradient information in tensorboard</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># don&#39;t make the tf file huge</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
                <span class="n">tag</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span>
            <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_zero_grad">
<span class="sig-name descname"><span class="pre">on_before_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_before_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<p>Called in the training loop after taking an optimizer step and before zeroing grads.
Good place to inspect weight information with weights updated.</p>
<p>This is where it is called:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">on_before_zero_grad</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span> <span class="c1"># &lt; ---- called here</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The optimizer for which grads should be zeroed.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_fit_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very end of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_fit_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very beginning of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_gpu">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">on_gpu</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_gpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p>
<p>Useful to set flags around the LightningModule for different CPU vs GPU behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_load_checkpoint">
<span class="sig-name descname"><span class="pre">on_load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_load_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning to restore your model. If you saved something with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_save_checkpoint"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_save_checkpoint()</span></code></a> this is
your chance to restore this.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Loaded checkpoint</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of the time you don&#39;t need to implement this method</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">something_cool_i_want_to_save</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning auto-restores global step, epoch, and train state including amp scaling.
There is no need for you to restore anything regarding training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_batch_end">
<span class="sig-name descname"><span class="pre">on_predict_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The outputs of predict_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the prediction DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_batch_start">
<span class="sig-name descname"><span class="pre">on_predict_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_end">
<span class="sig-name descname"><span class="pre">on_predict_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_epoch_end">
<span class="sig-name descname"><span class="pre">on_predict_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_epoch_start">
<span class="sig-name descname"><span class="pre">on_predict_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_model_eval">
<span class="sig-name descname"><span class="pre">on_predict_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the predict loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_start">
<span class="sig-name descname"><span class="pre">on_predict_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_predict_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_save_checkpoint">
<span class="sig-name descname"><span class="pre">on_save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to
save.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The full checkpoint dictionary before it gets dumped to a file.
Implementations of this hook can insert additional data into this dictionary.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of use cases you don&#39;t need to implement this method</span>
    <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_cool_pickable_object</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning saves all aspects of training (epoch, global step, etc…)
including amp scaling.
There is no need for you to store anything about training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_batch_end">
<span class="sig-name descname"><span class="pre">on_test_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of test_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_batch_start">
<span class="sig-name descname"><span class="pre">on_test_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_end">
<span class="sig-name descname"><span class="pre">on_test_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_epoch_end">
<span class="sig-name descname"><span class="pre">on_test_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_epoch_start">
<span class="sig-name descname"><span class="pre">on_test_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_model_eval">
<span class="sig-name descname"><span class="pre">on_test_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_model_train">
<span class="sig-name descname"><span class="pre">on_test_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_start">
<span class="sig-name descname"><span class="pre">on_test_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_test_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_batch_end">
<span class="sig-name descname"><span class="pre">on_train_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of training_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_batch_start">
<span class="sig-name descname"><span class="pre">on_train_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop before anything happens for that batch.</p>
<p>If you return -1 here, you will skip training for the rest of the current epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_end">
<span class="sig-name descname"><span class="pre">on_train_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of training before logger experiment is closed.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very end of the epoch.</p>
<p>To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> and access them in this hook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyLightningModule</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># do something with all training_step outputs, for example:</span>
        <span class="n">epoch_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;training_epoch_mean&quot;</span><span class="p">,</span> <span class="n">epoch_mean</span><span class="p">)</span>
        <span class="c1"># free up the memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_epoch_start">
<span class="sig-name descname"><span class="pre">on_train_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_start">
<span class="sig-name descname"><span class="pre">on_train_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_train_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of training after sanity check.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_batch_end">
<span class="sig-name descname"><span class="pre">on_validation_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of validation_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_batch_start">
<span class="sig-name descname"><span class="pre">on_validation_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_end">
<span class="sig-name descname"><span class="pre">on_validation_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_epoch_end">
<span class="sig-name descname"><span class="pre">on_validation_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_epoch_start">
<span class="sig-name descname"><span class="pre">on_validation_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_eval">
<span class="sig-name descname"><span class="pre">on_validation_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_train">
<span class="sig-name descname"><span class="pre">on_validation_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_zero_grad">
<span class="sig-name descname"><span class="pre">on_validation_model_zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_model_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by the training loop to release gradients before entering the validation loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_start">
<span class="sig-name descname"><span class="pre">on_validation_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.on_validation_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizer_step">
<span class="sig-name descname"><span class="pre">optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
the optimizer.</p>
<p>By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code> as shown in the example.
This method (and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code>) won’t be called during the accumulation phase when
<code class="docutils literal notranslate"><span class="pre">Trainer(accumulate_grad_batches</span> <span class="pre">!=</span> <span class="pre">1)</span></code>. Overriding this hook has no benefit with manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – A PyTorch optimizer</p></li>
<li><p><strong>optimizer_closure</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[], <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]]) – The optimizer closure. This closure must be executed as it includes the
calls to <code class="docutils literal notranslate"><span class="pre">training_step()</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>, and <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

<span class="c1"># Learning rate warm-up</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="c1"># update params</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

    <span class="c1"># manually warm up lr without a scheduler</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">&lt;</span> <span class="mi">500</span><span class="p">:</span>
        <span class="n">lr_scale</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">500.0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">pg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_scale</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizer_zero_grad">
<span class="sig-name descname"><span class="pre">optimizer_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizer_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – A PyTorch optimizer</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="c1"># Set gradients to `None` instead of zero to improve performance (not required on `torch&gt;=2.0.0`).</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for the explanation of the above example.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizers">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the optimizer(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_pl_optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will wrap the optimizer(s) in a
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code> for automatic handling of precision,
profiling, and counting of step calls for proper logging and checkpointing. It specifically wraps the
<code class="docutils literal notranslate"><span class="pre">step</span></code> method and custom optimizers that don’t have this method are not supported.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A single optimizer, or a list of optimizers in case multiple ones are present.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.output_chunk_length">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_chunk_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.output_chunk_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of time steps predicted at once by the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>Parameter</em> – module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.pred_batch_size">
<span class="sig-name descname"><span class="pre">pred_batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.pred_batch_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.pred_n">
<span class="sig-name descname"><span class="pre">pred_n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.pred_n" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.pred_n_jobs">
<span class="sig-name descname"><span class="pre">pred_n_jobs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.pred_n_jobs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.pred_num_samples">
<span class="sig-name descname"><span class="pre">pred_num_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.pred_num_samples" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.pred_roll_size">
<span class="sig-name descname"><span class="pre">pred_roll_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.pred_roll_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.predict_dataloader">
<span class="sig-name descname"><span class="pre">predict_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.predict_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying prediction samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code> or a sequence of them specifying prediction samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.predict_likelihood_parameters">
<span class="sig-name descname"><span class="pre">predict_likelihood_parameters</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.predict_likelihood_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.predict_step">
<span class="sig-name descname"><span class="pre">predict_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.predict_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the prediction step</p>
<dl class="simple">
<dt>batch</dt><dd><p>output of Darts’ <code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceDataset</span></code> - tuple of <code class="docutils literal notranslate"><span class="pre">(past_target,</span> <span class="pre">past_covariates,</span>
<span class="pre">historic_future_covariates,</span> <span class="pre">future_covariates,</span> <span class="pre">future_past_covariates,</span> <span class="pre">input_timeseries)</span></code></p>
</dd>
<dt>batch_idx</dt><dd><p>the batch index of the current batch</p>
</dd>
<dt>dataloader_idx</dt><dd><p>the dataloader index</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data">
<span class="sig-name descname"><span class="pre">prepare_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Use this to download and prepare data. Downloading and saving data with multiple processes (distributed
settings) will result in corrupted data. Lightning ensures this method is called only within a single process,
so you can safely add your downloading logic within.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>DO NOT set state to the model (use <code class="docutils literal notranslate"><span class="pre">setup</span></code> instead)
since this is NOT called on every device</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># good</span>
    <span class="n">download_data</span><span class="p">()</span>
    <span class="n">tokenize</span><span class="p">()</span>
    <span class="n">etc</span><span class="p">()</span>

    <span class="c1"># bad</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">data_split</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">some_state</span> <span class="o">=</span> <span class="n">some_other_state</span><span class="p">()</span>
</pre></div>
</div>
<p>In a distributed environment, <code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> can be called in two ways
(using <span class="xref std std-ref">prepare_data_per_node</span>)</p>
<ol class="arabic simple">
<li><p>Once per node. This is the default and is only called on LOCAL_RANK=0.</p></li>
<li><p>Once in total. Only called on GLOBAL_RANK=0.</p></li>
</ol>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="c1"># called once per node on LOCAL_RANK=0 of that node</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># call on GLOBAL_RANK=0 (great for shared file systems)</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>This is called before requesting the dataloaders:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">initialize_distributed</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_dataloader</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data_per_node" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.print">
<span class="sig-name descname"><span class="pre">print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.print" title="Permalink to this definition">¶</a></dt>
<dd><p>Prints only from process 0. Use this in any distributed mode to log only once.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – The thing to print. The same as for Python’s built-in print function.</p></li>
<li><p><strong>**kwargs</strong> – The same as for Python’s built-in print function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;in forward&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>This function is deprecated in favor of <code class="xref py py-meth docutils literal notranslate"><span class="pre">register_full_backward_hook()</span></code> and
the behavior of this function will change in future versions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the module’s state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">persistent</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the buffer. The buffer can be accessed
from this module using the given name</p></li>
<li><p><strong>tensor</strong> (<em>Tensor</em><em> or </em><em>None</em>) – buffer to be registered. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations
that run on buffers, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>, are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
the buffer is <strong>not</strong> included in the module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>) – whether the buffer is part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">always_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_forward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
output. It can modify the input inplace but it will not have effect on
forward since this is called after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called. The hook
should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the forward hook will be passed the
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> given to the forward function and be expected to return the
output possibly modified. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired
before all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_hook()</span></code> will fire before all hooks
registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the
kwargs given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>always_call</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be run regardless of
whether an exception is raised while calling the Module.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_forward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is false or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
input. User can either return a tuple or a single modified value in the
hook. We will wrap the value into a tuple if a single value is returned
(unless that value is already a tuple). The hook should have the
following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is true, the forward pre-hook will be passed the
kwargs given to the forward function. And if the hook modifies the
input, both the args and kwargs should be returned. The hook should have
the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">a</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">modified</span> <span class="nb">input</span> <span class="ow">and</span> <span class="n">kwargs</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_pre_hook()</span></code> will fire before all
hooks registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If true, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the kwargs
given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_full_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to a module
are computed, i.e. the hook will execute if and only if the gradients with
respect to module outputs are computed. The hook should have the following
signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in
subsequent computations. <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for all non-Tensor
arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_full_backward_pre_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_full_backward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward pre-hook on the module.</p>
<p>The hook will be called every time the gradients for the module are computed.
The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> is a tuple. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the output that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> in
subsequent computations. Entries in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for
all non-Tensor arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_pre_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_load_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_load_state_dict_post_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a post hook to be run after module’s <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code>
is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, incompatible_keys) -&gt; None</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">module</span></code> argument is the current module that this hook is registered
on, and the <code class="docutils literal notranslate"><span class="pre">incompatible_keys</span></code> argument is a <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> consisting
of attributes <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>. <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code>
is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the missing keys and
<code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the unexpected keys.</p>
<p>The given incompatible_keys can be modified inplace if needed.</p>
<p>Note that the checks performed when calling <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">strict=True</span></code> are affected by modifications the hook makes to
<code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> or <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>, as expected. Additions to either
set of keys will result in an error being thrown when <code class="docutils literal notranslate"><span class="pre">strict=True</span></code>, and
clearing out both missing and unexpected keys will avoid an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_module">
<span class="sig-name descname"><span class="pre">register_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_parameter">
<span class="sig-name descname"><span class="pre">register_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the parameter. The parameter can be accessed
from this module using the given name</p></li>
<li><p><strong>param</strong> (<em>Parameter</em><em> or </em><em>None</em>) – parameter to be added to the module. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations that run on parameters, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>,
are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the parameter is <strong>not</strong> included in the
module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.register_state_dict_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>,
and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>. The registered
hooks can be used to perform pre-processing before the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>
call is made.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.requires_grad_" title="Permalink to this definition">¶</a></dt>
<dd><p>Change if autograd should record operations on parameters in this
module.</p>
<p>This method sets the parameters’ <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.requires_grad_()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<em>bool</em>) – whether autograd should record operations on
parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters">
<span class="sig-name descname"><span class="pre">save_hyperparameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.save_hyperparameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – single object of <cite>dict</cite>, <cite>NameSpace</cite> or <cite>OmegaConf</cite>
or string names or arguments from class <code class="docutils literal notranslate"><span class="pre">__init__</span></code></p></li>
<li><p><strong>ignore</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – an argument name or a list of argument names from
class <code class="docutils literal notranslate"><span class="pre">__init__</span></code> to be ignored</p></li>
<li><p><strong>frame</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">frame</span></code>]) – a frame object. Default is None</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to send the hyperparameters to the logger. Default: True</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Example::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign arguments</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="s1">&#39;arg1&#39;</span><span class="p">,</span> <span class="s1">&#39;arg3&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AutomaticArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># equivalent automatic</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutomaticArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg2&quot;: abc</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">SingleArgModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign single argument</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleArgModel</span><span class="p">(</span><span class="n">Namespace</span><span class="p">(</span><span class="n">p1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p2</span><span class="o">=</span><span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="n">p3</span><span class="o">=</span><span class="mf">3.14</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;p1&quot;: 1</span>
<span class="go">&quot;p2&quot;: abc</span>
<span class="go">&quot;p3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># pass argument(s) to ignore as a string or in a list</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="s1">&#39;arg2&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state
found within the <cite>state_dict</cite>. Implement this function and a corresponding
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.get_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_extra_state()</span></code></a> for your module if you need to store extra state within its
<cite>state_dict</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>dict</em>) – Extra state from the <cite>state_dict</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_mc_dropout">
<span class="sig-name descname"><span class="pre">set_mc_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">active</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_mc_dropout" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_predict_parameters">
<span class="sig-name descname"><span class="pre">set_predict_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roll_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.set_predict_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you
need to build models dynamically or adjust something about them. This hook is called on every process when
using DDP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">download_data</span><span class="p">()</span>
        <span class="n">tokenize</span><span class="p">()</span>

        <span class="c1"># don&#39;t do this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">something</span> <span class="o">=</span> <span class="k">else</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.share_memory">
<span class="sig-name descname"><span class="pre">share_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.share_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>~T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary containing references to the whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to <code class="docutils literal notranslate"><span class="pre">None</span></code> are not included.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned object is a shallow copy. It contains references
to the module’s parameters and buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> also accepts positional arguments for
<code class="docutils literal notranslate"><span class="pre">destination</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> in order. However,
this is being deprecated and keyword arguments will be enforced in
future releases.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please avoid the use of argument <code class="docutils literal notranslate"><span class="pre">destination</span></code> as it is not
designed for end-users.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>destination</strong> (<em>dict</em><em>, </em><em>optional</em>) – If provided, the state of module will
be updated into the dict and the same object is returned.
Otherwise, an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> will be created and returned.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em>) – a prefix added to parameter and buffer
names to compose the keys in state_dict. Default: <code class="docutils literal notranslate"><span class="pre">''</span></code>.</p></li>
<li><p><strong>keep_vars</strong> (<em>bool</em><em>, </em><em>optional</em>) – by default the <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> s
returned in the state dict are detached from autograd. If it’s
set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, detaching will not be performed.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary containing a whole state of the module</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.teardown">
<span class="sig-name descname"><span class="pre">teardown</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.teardown" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of fit (train + validate), validate, test, or predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_dataloader">
<span class="sig-name descname"><span class="pre">test_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying test samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">test()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a test dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a>, you don’t need to implement
this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the test set. In this step you’d normally generate examples or
calculate anything of interest such as accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your data iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><strong>batch_idx</strong> – The index of this batch.</p></li>
<li><p><strong>dataloader_idx</strong> – The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Skip to the next batch.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one test dataloader:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="o">...</span>

<span class="c1"># if you have multiple test dataloaders:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single test dataset</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple test dataloaders, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple test dataloaders</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="o">...</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need to test you don’t need to implement this method.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> is called, the model has been put in eval mode and
PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
to training mode and gradients are enabled.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_dtype">
<span class="sig-name descname"><span class="pre">to_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Cast module precision (float32 by default) to another precision.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_empty" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves the parameters and buffers to the specified device without copying storage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>) – The desired device of the parameters
and buffers in this module.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – Whether parameters and buffers of submodules should
be recursively moved to the specified device.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_onnx">
<span class="sig-name descname"><span class="pre">to_onnx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_onnx" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the model in ONNX format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>]) – The path of the file the onnx model should be saved to.</p></li>
<li><p><strong>input_sample</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input for tracing. Default: None (Use self.example_input_array)</p></li>
<li><p><strong>**kwargs</strong> – Will be passed to torch.onnx.export function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">input_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">(</span><span class="s2">&quot;export.onnx&quot;</span><span class="p">,</span> <span class="n">input_sample</span><span class="p">,</span> <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_torchscript">
<span class="sig-name descname"><span class="pre">to_torchscript</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'script'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.to_torchscript" title="Permalink to this definition">¶</a></dt>
<dd><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>. If you want to use tracing,
please provided the argument <code class="docutils literal notranslate"><span class="pre">method='trace'</span></code> and make sure that either the <cite>example_inputs</cite> argument is
provided, or the model has <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a> set. If you would like to customize the modules that are
scripted you should override this method. In case you want to return multiple modules, we recommend using a
dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Path where to save the torchscript. Default: None (no file saved).</p></li>
<li><p><strong>method</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Whether to use TorchScript’s script or trace method. Default: ‘script’</p></li>
<li><p><strong>example_inputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input to be used to do tracing when method is set to ‘trace’.
Default: None (uses <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments that will be passed to the <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.script()</span></code> or
<code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.trace()</span></code> function.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Requires the implementation of the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> method.</p></li>
<li><p>The exported script will be set to evaluation mode.</p></li>
<li><p>It is recommended that you install the latest supported version of PyTorch
to use this feature without limitations. See also the <code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.jit</span></code>
documentation for supported features.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span>
    <span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model_trace.pt&quot;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;trace&#39;</span><span class="p">,</span> <span class="n">example_inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>]]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>This LightningModule as a torchscript, regardless of whether <cite>file_path</cite> is
defined or not.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.toggle_optimizer">
<span class="sig-name descname"><span class="pre">toggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.toggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Makes sure only the gradients of the current optimizer’s parameters are calculated in the training step to
prevent dangling gradients in multiple-optimizer setup.</p>
<p>It works with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.untoggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">untoggle_optimizer()</span></code></a> to make sure <code class="docutils literal notranslate"><span class="pre">param_requires_grad_state</span></code> is properly reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to toggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.train_dataloader">
<span class="sig-name descname"><span class="pre">train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.train_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying training samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id18"><span class="problematic" id="id19">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.trainer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">trainer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.trainer.trainer.Trainer</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.trainer" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the training step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.transfer_batch_to_device">
<span class="sig-name descname"><span class="pre">transfer_batch_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.transfer_batch_to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data
structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code> or anything that implements <cite>.to(…)</cite></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, …).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook should only transfer the data and not modify it, nor should it move the data to
any other device than the one passed in as argument (unless you know what you are doing).
To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be transferred to a new device.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>) – The target device as defined in PyTorch.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A reference to the data on the new device.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">CustomBatch</span><span class="p">):</span>
        <span class="c1"># move all tensors in your custom data structure to the device</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># skip device transfer for the first dataloader or anything you wish</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transfer_batch_to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">move_data_to_device()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_to_collection()</span></code></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.type">
<span class="sig-name descname"><span class="pre">type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.type" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.unfreeze">
<span class="sig-name descname"><span class="pre">unfreeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze all parameters for training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.untoggle_optimizer">
<span class="sig-name descname"><span class="pre">untoggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.untoggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to untoggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.val_dataloader">
<span class="sig-name descname"><span class="pre">val_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.val_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying validation samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id20"><span class="problematic" id="id21">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">validate()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a validation dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a>, you don’t need to
implement this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the validation step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.xpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the XPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLFutureCovariatesModule.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets gradients of all model parameters. See similar function
under <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code> for more context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>set_to_none</strong> (<em>bool</em>) – instead of setting to zero, set the grads to None.
See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for details.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">darts.models.forecasting.pl_forecasting_module.</span></span><span class="sig-name descname"><span class="pre">PLMixedCovariatesModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_sample_shape=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn=MSELoss()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_metrics=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_cls=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_cls=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_reversible_instance_norm=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLMixedCovariatesModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">darts.models.forecasting.pl_forecasting_module.PLForecastingModule</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>PyTorch Lightning-based Forecasting Module.</p>
<p>This class is meant to be inherited to create a new PyTorch Lightning-based forecasting module.
When subclassing this class, please make sure to add the following methods with the given signatures:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.__init__()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.forward()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._produce_train_output()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._get_batch_prediction()</span></code></p></li>
</ul>
</div></blockquote>
<p>In subclass <cite>MyModel</cite>’s <code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code> function call <code class="docutils literal notranslate"><span class="pre">super(MyModel,</span> <span class="pre">self).__init__(**kwargs)</span></code> where
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> are the parameters of <code class="xref py py-class docutils literal notranslate"><span class="pre">PLTorchForecastingModel</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps in the past to take as a model input (per chunk). Applies to the target
series, and past and/or future covariates (if the model supports it).</p></li>
<li><p><strong>output_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps predicted at once (per chunk) by the internal model. Also, the number of future values
from future covariates to use as a model input (if the model supports future covariates). It is not the same
as forecast horizon <cite>n</cite> used in <cite>predict()</cite>, which is the desired number of prediction points generated
using either a one-shot- or auto-regressive forecast. Setting <cite>n &lt;= output_chunk_length</cite> prevents
auto-regression. This is useful when the covariates don’t extend far enough into the future, or to prohibit
the model from using future values of past and / or future covariates for prediction (depending on the
model’s covariate support).</p></li>
<li><p><strong>train_sample_shape</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Shape of the model’s input, used to instantiate model without calling <code class="docutils literal notranslate"><span class="pre">fit_from_dataset</span></code> and
perform sanity check on new training/inference datasets used for re-training or prediction.</p></li>
<li><p><strong>loss_fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code>) – PyTorch loss function used for training.
This parameter will be ignored for probabilistic models if the <code class="docutils literal notranslate"><span class="pre">likelihood</span></code> parameter is specified.
Default: <code class="docutils literal notranslate"><span class="pre">torch.nn.MSELoss()</span></code>.</p></li>
<li><p><strong>torch_metrics</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – A torch metric or a <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code> used for evaluation. A full list of available metrics can be found
at <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/">https://torchmetrics.readthedocs.io/en/latest/</a>. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>likelihood</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code></a>]) – One of Darts’ <a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Likelihood</span></code></a> models to be used for
probabilistic forecasts. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>optimizer_cls</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The PyTorch optimizer class to be used. Default: <code class="docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code>.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch optimizer (e.g., <code class="docutils literal notranslate"><span class="pre">{'lr':</span> <span class="pre">1e-3}</span></code>
for specifying a learning rate). Otherwise the default values of the selected <code class="docutils literal notranslate"><span class="pre">optimizer_cls</span></code>
will be used. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_cls</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_LRScheduler</span></code>]) – Optionally, the PyTorch learning rate scheduler class to be used. Specifying <code class="docutils literal notranslate"><span class="pre">None</span></code> corresponds
to using a constant learning rate. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch learning rate scheduler. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>use_reversible_instance_norm</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to use reversible instance normalization <cite>RINorm</cite> against distribution shift as shown in <a class="reference internal" href="#rbce702062bef-1" id="id22">[1]</a>.
It is only applied to the features of the target series and not the covariates.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="rbce702062bef-1"><span class="brackets"><a class="fn-backref" href="#id22">1</a></span></dt>
<dd><p>T. Kim et al. “Reversible Instance Normalization for Accurate Time-Series Forecasting against
Distribution Shift”, <a class="reference external" href="https://openreview.net/forum?id=cGDAkQo1C0p">https://openreview.net/forum?id=cGDAkQo1C0p</a></p>
</dd>
</dl>
<p class="rubric">Attributes</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.automatic_optimization" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.automatic_optimization"><code class="xref py py-obj docutils literal notranslate"><span class="pre">automatic_optimization</span></code></a></p></td>
<td><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.current_epoch" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.current_epoch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">current_epoch</span></code></a></p></td>
<td><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.example_input_array"><code class="xref py py-obj docutils literal notranslate"><span class="pre">example_input_array</span></code></a></p></td>
<td><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.global_rank" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.global_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_rank</span></code></a></p></td>
<td><p>The index of the current process across all nodes and devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.global_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.global_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_step</span></code></a></p></td>
<td><p>Total training batches seen across all epochs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams_initial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams_initial</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.local_rank" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.local_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">local_rank</span></code></a></p></td>
<td><p>The index of the current process within a single node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.logger" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.logger"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logger</span></code></a></p></td>
<td><p>Reference to the logger object in the Trainer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.loggers" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.loggers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">loggers</span></code></a></p></td>
<td><p>Reference to the list of loggers in the Trainer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_gpu" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_gpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_gpu</span></code></a></p></td>
<td><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.output_chunk_length" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.output_chunk_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_chunk_length</span></code></a></p></td>
<td><p>Number of time steps predicted at once by the model.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>device</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>dtype</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>epochs_trained</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>fabric</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>trainer</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.add_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_module</span></code></a>(name, module)</p></td>
<td><p>Adds a child module to the current module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.all_gather" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.all_gather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">all_gather</span></code></a>(data[, group, sync_grads])</p></td>
<td><p>Gather tensors or collections of tensors from multiple processes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.apply" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.backward" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.bfloat16" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.bfloat16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfloat16</span></code></a>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.buffers" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">buffers</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.children" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.clip_gradients" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.clip_gradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip_gradients</span></code></a>(optimizer[, ...])</p></td>
<td><p>Handles gradient clipping internally.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.compile" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(*args, **kwargs)</p></td>
<td><p>Compile this Module's forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_callbacks" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_callbacks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_callbacks</span></code></a>()</p></td>
<td><p>Configure model-specific callbacks.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_gradient_clipping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_gradient_clipping</span></code></a>(optimizer[, ...])</p></td>
<td><p>Perform gradient clipping for the optimizer parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_model" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_model</span></code></a>()</p></td>
<td><p>Hook to create modules in a strategy and precision aware context.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_optimizers" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_optimizers</span></code></a>()</p></td>
<td><p>configures optimizers and learning rate schedulers for model optimization.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_sharded_model" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_sharded_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_sharded_model</span></code></a>()</p></td>
<td><p>Deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_torch_metrics" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_torch_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_torch_metrics</span></code></a>(torch_metrics)</p></td>
<td><p>process the torch_metrics parameter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cpu" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cuda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.double" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.double"><code class="xref py py-obj docutils literal notranslate"><span class="pre">double</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.eval" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code></a>()</p></td>
<td><p>Sets the module in evaluation mode.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.extra_repr" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.extra_repr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extra_repr</span></code></a>()</p></td>
<td><p>Set the extra representation of the module</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(*args, **kwargs)</p></td>
<td><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.freeze" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.freeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">freeze</span></code></a>()</p></td>
<td><p>Freeze all params for inference.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_buffer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_buffer</span></code></a>(target)</p></td>
<td><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_extra_state</span></code></a>()</p></td>
<td><p>Returns any extra state to include in the module's state_dict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_parameter" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_parameter</span></code></a>(target)</p></td>
<td><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_submodule" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_submodule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_submodule</span></code></a>(target)</p></td>
<td><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.half" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.half"><code class="xref py py-obj docutils literal notranslate"><span class="pre">half</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.ipu" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.ipu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ipu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the IPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_from_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_from_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code></a>([map_location, ...])</p></td>
<td><p>Primary way of loading a model from a checkpoint.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>(state_dict[, strict, assign])</p></td>
<td><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.log" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log</span></code></a>(name, value[, prog_bar, logger, ...])</p></td>
<td><p>Log a key, value pair.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.log_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.log_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_dict</span></code></a>(dictionary[, prog_bar, logger, ...])</p></td>
<td><p>Log a dictionary of values at once.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.lr_scheduler_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.lr_scheduler_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_scheduler_step</span></code></a>(scheduler, metric)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls each scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.lr_schedulers" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.lr_schedulers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_schedulers</span></code></a>()</p></td>
<td><p>Returns the learning rate scheduler(s) that are being used during training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.manual_backward" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.manual_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">manual_backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.modules" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">modules</span></code></a>()</p></td>
<td><p>Returns an iterator over all modules in the network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_buffers" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_buffers</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_children" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_modules" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_modules</span></code></a>([memo, prefix, remove_duplicate])</p></td>
<td><p>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_parameters" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_after_backward" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_after_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_backward</span></code></a>()</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_after_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_backward" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_backward</span></code></a>(loss)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code></a>(optimizer)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_zero_grad</span></code></a>(optimizer)</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_fit_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_fit_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_end</span></code></a>()</p></td>
<td><p>Called at the very end of fit.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_fit_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_fit_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_start</span></code></a>()</p></td>
<td><p>Called at the very beginning of fit.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_load_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_load_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_load_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning to restore your model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the predict loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the predict loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the predict loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_save_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_save_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to save.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the test loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the test loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_end</span></code></a>()</p></td>
<td><p>Called at the end of testing.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_end</span></code></a>()</p></td>
<td><p>Called in the test loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_start</span></code></a>()</p></td>
<td><p>Called in the test loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the test loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_model_train" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the test loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_start</span></code></a>()</p></td>
<td><p>Called at the beginning of testing.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the training loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the training loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_end</span></code></a>()</p></td>
<td><p>Called at the end of training before logger experiment is closed.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_end</span></code></a>()</p></td>
<td><p>Called in the training loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_start</span></code></a>()</p></td>
<td><p>Called in the training loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_start</span></code></a>()</p></td>
<td><p>Called at the beginning of training after sanity check.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_end</span></code></a>(outputs, batch, ...)</p></td>
<td><p>Called in the validation loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the validation loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_end</span></code></a>()</p></td>
<td><p>Called at the end of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_end</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_start</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the val loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_train" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the val loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_zero_grad</span></code></a>()</p></td>
<td><p>Called by the training loop to release gradients before entering the validation loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_start" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_start</span></code></a>()</p></td>
<td><p>Called at the beginning of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_step</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls the optimizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizer_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizer_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_zero_grad</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizers" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizers</span></code></a>([use_pl_optimizer])</p></td>
<td><p>Returns the optimizer(s) that are being used during training.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.parameters" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.predict_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.predict_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying prediction samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.predict_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.predict_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_step</span></code></a>(batch, batch_idx[, dataloader_idx])</p></td>
<td><p>performs the prediction step</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare_data</span></code></a>()</p></td>
<td><p>Use this to download and prepare data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.print" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.print"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print</span></code></a>(*args, **kwargs)</p></td>
<td><p>Prints only from process 0.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_backward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_buffer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_buffer</span></code></a>(name, tensor[, persistent])</p></td>
<td><p>Adds a buffer to the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_forward_hook" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook, *[, prepend, ...])</p></td>
<td><p>Registers a forward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_forward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook, *[, ...])</p></td>
<td><p>Registers a forward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_full_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_full_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_full_backward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_full_backward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_pre_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_load_state_dict_post_hook" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_load_state_dict_post_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_load_state_dict_post_hook</span></code></a>(hook)</p></td>
<td><p>Registers a post hook to be run after module's <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> is called.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_module" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_module</span></code></a>(name, module)</p></td>
<td><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_parameter" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_parameter</span></code></a>(name, param)</p></td>
<td><p>Adds a parameter to the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_state_dict_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_state_dict_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_state_dict_pre_hook</span></code></a>(hook)</p></td>
<td><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>, and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.requires_grad_" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.requires_grad_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad_</span></code></a>([requires_grad])</p></td>
<td><p>Change if autograd should record operations on parameters in this module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_hyperparameters</span></code></a>(*args[, ignore, frame, ...])</p></td>
<td><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_extra_state</span></code></a>(state)</p></td>
<td><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state found within the <cite>state_dict</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_predict_parameters" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_predict_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_predict_parameters</span></code></a>(n, num_samples, ...)</p></td>
<td><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>(stage)</p></td>
<td><p>Called at the beginning of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.share_memory" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.share_memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_memory</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code></a>(*args[, destination, prefix, ...])</p></td>
<td><p>Returns a dictionary containing references to the whole state of the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.teardown" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.teardown"><code class="xref py py-obj docutils literal notranslate"><span class="pre">teardown</span></code></a>(stage)</p></td>
<td><p>Called at the end of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying test samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_step</span></code></a>(*args, **kwargs)</p></td>
<td><p>Operates on a single batch of data from the test set.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_dtype" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_dtype</span></code></a>(dtype)</p></td>
<td><p>Cast module precision (float32 by default) to another precision.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_empty" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_empty</span></code></a>(*, device[, recurse])</p></td>
<td><p>Moves the parameters and buffers to the specified device without copying storage.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_onnx" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_onnx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_onnx</span></code></a>(file_path[, input_sample])</p></td>
<td><p>Saves the model in ONNX format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_torchscript" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_torchscript"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_torchscript</span></code></a>([file_path, method, ...])</p></td>
<td><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.toggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">toggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Makes sure only the gradients of the current optimizer's parameters are calculated in the training step to prevent dangling gradients in multiple-optimizer setup.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.train" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>([mode])</p></td>
<td><p>Sets the module in training mode.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.train_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.train_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying training samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">training_step</span></code></a>(train_batch, batch_idx)</p></td>
<td><p>performs the training step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.transfer_batch_to_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transfer_batch_to_device</span></code></a>(batch, device, ...)</p></td>
<td><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data structure.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.type" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code></a>(dst_type)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.unfreeze" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.unfreeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unfreeze</span></code></a>()</p></td>
<td><p>Unfreeze all parameters for training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.untoggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">untoggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.val_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.val_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">val_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying validation samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.validation_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">validation_step</span></code></a>(val_batch, batch_idx)</p></td>
<td><p>performs the validation step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.xpu" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.xpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xpu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the XPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>([set_to_none])</p></td>
<td><p>Resets gradients of all model parameters.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>__call__</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_mc_dropout</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.CHECKPOINT_HYPER_PARAMS_KEY">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_KEY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hyper_parameters'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.CHECKPOINT_HYPER_PARAMS_KEY" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.CHECKPOINT_HYPER_PARAMS_NAME">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_name'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.CHECKPOINT_HYPER_PARAMS_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.CHECKPOINT_HYPER_PARAMS_TYPE">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_TYPE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_type'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.CHECKPOINT_HYPER_PARAMS_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.T_destination">
<span class="sig-name descname"><span class="pre">T_destination</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.T_destination" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of TypeVar(‘T_destination’, bound=<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>])</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.add_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the child module. The child module can be
accessed from this module using the given name</p></li>
<li><p><strong>module</strong> (<em>Module</em>) – child module to be added to the module.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.all_gather">
<span class="sig-name descname"><span class="pre">all_gather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.all_gather" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather tensors or collections of tensors from multiple processes.</p>
<p>This method needs to be called on all processes and the tensors need to have the same shape across all
processes, otherwise your program will stall forever.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – int, float, tensor of shape (batch, …), or a (possibly nested) collection thereof.</p></li>
<li><p><strong>group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the process group to gather results from. Defaults to all processes (world)</p></li>
<li><p><strong>sync_grads</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – flag that allows users to synchronize gradients for the all_gather operation</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor of shape (world_size, batch, …), or if the input was a collection
the output will also be a collection with tensors of this shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.allow_zero_length_dataloader_with_multiple_devices" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>)
as well as self. Typical use includes initializing the parameters of a model
(see also <span class="xref std std-ref">nn-init-doc</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> -&gt; None) – function to be applied to each submodule</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.automatic_optimization">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">automatic_optimization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.automatic_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. Override this hook with your own
implementation if you need to.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The loss tensor returned by <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. If gradient accumulation is used, the loss here
holds the normalized value (scaled by 1 / accumulation steps).</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.bfloat16">
<span class="sig-name descname"><span class="pre">bfloat16</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.bfloat16" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.buffers">
<span class="sig-name descname"><span class="pre">buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – module buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.call_super_init">
<span class="sig-name descname"><span class="pre">call_super_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.call_super_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a child module</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.clip_gradients">
<span class="sig-name descname"><span class="pre">clip_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.clip_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Handles gradient clipping internally.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Do not override this method. If you want to customize gradient clipping, consider using
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_gradient_clipping"><code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_gradient_clipping()</span></code></a> method.</p></li>
<li><p>For manual optimization (<code class="docutils literal notranslate"><span class="pre">self.automatic_optimization</span> <span class="pre">=</span> <span class="pre">False</span></code>), if you want to use
gradient clipping, consider calling
<code class="docutils literal notranslate"><span class="pre">self.clip_gradients(opt,</span> <span class="pre">gradient_clip_val=0.5,</span> <span class="pre">gradient_clip_algorithm=&quot;norm&quot;)</span></code>
manually in the training step.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. Pass <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;value&quot;</span></code>
to clip by value, and <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;norm&quot;</span></code> to clip by norm.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.compile" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile this Module’s forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>This Module’s <cite>__call__</cite> method is compiled and all arguments are passed as-is
to <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>See <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code> for details on the arguments for this function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_callbacks">
<span class="sig-name descname"><span class="pre">configure_callbacks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_callbacks" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure model-specific callbacks. When the model gets attached, e.g., when <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> or <code class="docutils literal notranslate"><span class="pre">.test()</span></code> gets
called, the list or a callback returned here will be merged with the list of callbacks passed to the Trainer’s
<code class="docutils literal notranslate"><span class="pre">callbacks</span></code> argument. If a callback returned here has the same type as one or several callbacks already
present in the Trainer’s callbacks list, it will take priority and replace them. In addition, Lightning will
make sure <code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> callbacks run last.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A callback or a list of callbacks which will extend the list of callbacks in the Trainer.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">early_stop</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_gradient_clipping">
<span class="sig-name descname"><span class="pre">configure_gradient_clipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_gradient_clipping" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform gradient clipping for the optimizer parameters. Called before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizer_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients. By default, value passed in Trainer
will be available here.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. By default, value
passed in Trainer will be available here.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_gradient_clipping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="p">,</span> <span class="n">gradient_clip_algorithm</span><span class="p">):</span>
    <span class="c1"># Implement your own custom logic to clip gradients</span>
    <span class="c1"># You can call `self.clip_gradients` with your settings:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="o">=</span><span class="n">gradient_clip_val</span><span class="p">,</span>
        <span class="n">gradient_clip_algorithm</span><span class="o">=</span><span class="n">gradient_clip_algorithm</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_model">
<span class="sig-name descname"><span class="pre">configure_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook to create modules in a strategy and precision aware context.</p>
<p>This is particularly useful for when using sharded strategies (FSDP and DeepSpeed), where we’d like to shard
the model instantly to save memory and initialization time.
For non-sharded strategies, you can choose to override this hook or to initialize your model under the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">init_module()</span></code> context manager.</p>
<p>This hook is called during each of fit/val/test/predict stages in the same process, so ensure that
implementation of this hook is idempotent.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>configures optimizers and learning rate schedulers for model optimization.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_sharded_model">
<span class="sig-name descname"><span class="pre">configure_sharded_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_sharded_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Deprecated.</p>
<p>Use <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_model()</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_torch_metrics">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">configure_torch_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">torch_metrics</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.configure_torch_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>process the torch_metrics parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cuda" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the GPU. This also makes associated parameters and buffers
different objects. So it should be called before constructing optimizer if the module will live on GPU while
being optimized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If specified, all parameters will be copied to that device. If <cite>None</cite>, the current CUDA device
index will be used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.current_epoch">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">current_epoch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.current_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.device</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.device" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.double" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.dtype</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.dtype" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dtype</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.dump_patches">
<span class="sig-name descname"><span class="pre">dump_patches</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.dump_patches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.epochs_trained">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">epochs_trained</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.epochs_trained" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code>.</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.eval()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.example_input_array">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">example_input_array</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.example_input_array" title="Permalink to this definition">¶</a></dt>
<dd><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method. The
return type is interpreted as follows:</p>
<ul class="simple">
<li><p>Single tensor: It is assumed the model takes a single argument, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(model.example_input_array)</span></code></p></li>
<li><p>Tuple: The input array should be interpreted as a sequence of positional arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(*model.example_input_array)</span></code></p></li>
<li><p>Dict: The input array represents named keyword arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(**model.example_input_array)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.fabric">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fabric</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.fabric.Fabric</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.fabric" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fabric</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Whatever you decide to pass into the forward method.</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments are also possible.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Your model’s output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.freeze">
<span class="sig-name descname"><span class="pre">freeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze all params for inference.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the buffer
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The buffer referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not a
buffer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns any extra state to include in the module’s state_dict.
Implement this and a corresponding <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_extra_state()</span></code></a> for your module
if you need to store extra state. This function is called when building the
module’s <cite>state_dict()</cite>.</p>
<p>Note that extra state should be picklable to ensure working serialization
of the state_dict. We only provide provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Any extra state to store in the module’s state_dict</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_parameter">
<span class="sig-name descname"><span class="pre">get_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the Parameter
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Parameter referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To check whether or not we have the <code class="docutils literal notranslate"><span class="pre">linear</span></code> submodule, we
would call <code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.linear&quot;)</span></code>. To check whether
we have the <code class="docutils literal notranslate"><span class="pre">conv</span></code> submodule, we would call
<code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.net_c.conv&quot;)</span></code>.</p>
<p>The runtime of <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> is bounded by the degree
of module nesting in <code class="docutils literal notranslate"><span class="pre">target</span></code>. A query against
<code class="docutils literal notranslate"><span class="pre">named_modules</span></code> achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists, <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> should always be
used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The submodule referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.global_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.global_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process across all nodes and devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.global_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.global_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Total training batches seen across all epochs.</p>
<p>If no Trainer is attached, this propery is 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.half" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">MutableMapping</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. It is mutable by the user. For
the frozen set of initial hyperparameters, use <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams_initial"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams_initial</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">AttributeDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MutableMapping</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mutable hyperparameters dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams_initial">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams_initial</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams_initial" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. These contents are read-only.
Manual updates to the saved hyperparameters can instead be performed through <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.hparams"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>immutable initial hyperparameters</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>AttributeDict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.ipu">
<span class="sig-name descname"><span class="pre">ipu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.ipu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the IPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on IPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_from_checkpoint">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_from_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments
passed to <code class="docutils literal notranslate"><span class="pre">__init__</span></code>  in the checkpoint under <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<p>Any arguments specified through **kwargs will override args stored in <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">IO</span></code>]) – Path to checkpoint. This can also be a URL, or file-like object</p></li>
<li><p><strong>map_location</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If your checkpoint saved a GPU model and you now load on CPUs
or a different number of GPUs, use this to map to the new setup.
The behaviour is the same as in <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code>.</p></li>
<li><p><strong>hparams_file</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optional path to a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> or <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file with hierarchical structure
as in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">drop_prob</span><span class="p">:</span> <span class="mf">0.2</span>
<span class="n">dataloader</span><span class="p">:</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="mi">32</span>
</pre></div>
</div>
<p>You most likely won’t need this since Lightning will always save the hyperparameters
to the checkpoint.
However, if your checkpoint weights don’t have the hyperparameters saved,
use this method to pass in a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file with the hparams you’d like to use.
These will be converted into a <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> and passed into your
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> for use.</p>
<p>If your model’s <code class="docutils literal notranslate"><span class="pre">hparams</span></code> argument is <code class="xref py py-class docutils literal notranslate"><span class="pre">Namespace</span></code>
and <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file has hierarchical structure, you need to refactor your model to treat
<code class="docutils literal notranslate"><span class="pre">hparams</span></code> as <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>.</p>
</p></li>
<li><p><strong>strict</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to strictly enforce that the keys in <code class="xref py py-attr docutils literal notranslate"><span class="pre">checkpoint_path</span></code> match the keys
returned by this module’s state dict.</p></li>
<li><p><strong>**kwargs</strong> – Any extra keyword args needed to init the model. Can also be used to override saved
hyperparameter values.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance with loaded weights and hyperparameters (if available).</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code> is a <strong>class</strong> method. You should use your <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code>
<strong>class</strong> to call it instead of the <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance, or a
<code class="docutils literal notranslate"><span class="pre">TypeError</span></code> will be raised.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load weights without mapping ...</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">)</span>

<span class="c1"># or load weights mapping all weights from GPU 1 to GPU 0 ...</span>
<span class="n">map_location</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span>
<span class="p">)</span>

<span class="c1"># or load weights and hyperparameters from separate files.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">hparams_file</span><span class="o">=</span><span class="s1">&#39;/path/to/hparams_file.yaml&#39;</span>
<span class="p">)</span>

<span class="c1"># override some of the params with new values</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="n">PATH</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">pretrained_ckpt_path</span><span class="o">=</span><span class="n">NEW_PATH</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># predict</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">pretrained_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into
this module and its descendants. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> the optimizer must be created after
the call to <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>dict</em>) – a dict containing parameters and
persistent buffers.</p></li>
<li><p><strong>strict</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to strictly enforce that the keys
in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this module’s
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>assign</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to assign items in the state
dictionary to their corresponding keys in the module instead
of copying them inplace into the module’s current parameters and buffers.
When <code class="docutils literal notranslate"><span class="pre">False</span></code>, the properties of the tensors in the current
module are preserved while when <code class="docutils literal notranslate"><span class="pre">True</span></code>, the properties of the
Tensors in the state dict are preserved.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>missing_keys</strong> is a list of str containing the missing keys</p></li>
<li><p><strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a parameter or buffer is registered as <code class="docutils literal notranslate"><span class="pre">None</span></code> and its corresponding key
exists in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> will raise a
<code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code>.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.local_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">local_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.local_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process within a single node.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_attribute</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a key, value pair.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>The default behavior per hook is documented here: <span class="xref std std-ref">extensions/logging:Automatic Logging</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – key to log.</p></li>
<li><p><strong>value</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]) – value to log. Can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, or a <code class="docutils literal notranslate"><span class="pre">Metric</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress bar.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto detach the graph.</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across devices. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the DDP group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple dataloaders). If False, user needs to give unique names for
each dataloader to not mix the values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch_size. This will be directly inferred from the loaded batch,
but for some data structures you might need to explicitly provide it.</p></li>
<li><p><strong>metric_attribute</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – To restore the metric state, Lightning requires the reference of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code> in your model. This is found automatically if it is a model attribute.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.log_dict">
<span class="sig-name descname"><span class="pre">log_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dictionary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.log_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a dictionary of values at once.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="s1">&#39;metric_n&#39;</span><span class="p">:</span> <span class="n">metric_n</span><span class="p">}</span>
<span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dictionary</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>]) – key value pairs.
The values can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">Metric</span></code>, or <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress base.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for training_step but not validation/test_step.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for val/test step but not <code class="docutils literal notranslate"><span class="pre">training_step</span></code>.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto-detach the graph</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across GPUs/TPUs. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the ddp group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple). If <code class="docutils literal notranslate"><span class="pre">False</span></code>, user needs to give unique names for
each dataloader to not mix values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch size. This will be directly inferred from the loaded batch,
but some data structures might need to explicitly provide it.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.logger">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.logger" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the logger object in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.loggers">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">loggers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.loggers" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the list of loggers in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.lr_scheduler_step">
<span class="sig-name descname"><span class="pre">lr_scheduler_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.lr_scheduler_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
each scheduler. By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and as shown in the example for each scheduler based on
its <code class="docutils literal notranslate"><span class="pre">interval</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scheduler</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]) – Learning rate scheduler.</p></li>
<li><p><strong>metric</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Value of the monitor used for schedulers like <code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>

<span class="c1"># Alternative way to update schedulers if it requires an epoch value</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.lr_schedulers">
<span class="sig-name descname"><span class="pre">lr_schedulers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.lr_schedulers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the learning rate scheduler(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A single scheduler, or a list of schedulers in case multiple ones are present, or <code class="docutils literal notranslate"><span class="pre">None</span></code> if no
schedulers were returned in <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_optimizers()</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.manual_backward">
<span class="sig-name descname"><span class="pre">manual_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.manual_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually. By using this,
Lightning can ensure that all the proper scaling gets applied when using mixed precision.</p>
<p>See <span class="xref std std-ref">manual optimization</span> for more examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># automatically applies scaling, etc...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The tensor on which to compute gradients. Must have a graph attached.</p></li>
<li><p><strong>*args</strong> – Additional positional arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a module in the network</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all buffer names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module. Defaults to True.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated buffers in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, torch.Tensor)</em> – Tuple containing the name and buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_children">
<span class="sig-name descname"><span class="pre">named_children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>(str, Module)</em> – Tuple containing a name and child module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_modules">
<span class="sig-name descname"><span class="pre">named_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>memo</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Set</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]) – a memo to store the set of modules already added to the result</p></li>
<li><p><strong>prefix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – a prefix that will be added to the name of the module</p></li>
<li><p><strong>remove_duplicate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – whether to remove the duplicated module instances in the result
or not</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Module)</em> – Tuple of name and module</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated
parameters in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Parameter)</em> – Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_after_backward">
<span class="sig-name descname"><span class="pre">on_after_backward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_after_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If using native AMP, the gradients will not be unscaled at this point.
Use the <code class="docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code> if you need the unscaled gradients.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_after_batch_transfer">
<span class="sig-name descname"><span class="pre">on_after_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_after_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gpu_transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_before_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_backward">
<span class="sig-name descname"><span class="pre">on_before_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Loss divided by number of batches for gradient accumulation and scaled if using AMP.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_batch_transfer">
<span class="sig-name descname"><span class="pre">on_before_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_after_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_after_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_optimizer_step">
<span class="sig-name descname"><span class="pre">on_before_optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p>
<p>If using gradient accumulation, the hook is called once the gradients have been accumulated.
See: <a href="#id23"><span class="problematic" id="id24">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.accumulate_grad_batches`</span></a>.</p>
<p>If using AMP, the loss will be unscaled before calling this hook.
See these <a class="reference external" href="https://pytorch.org/docs/stable/notes/amp_examples.html#working-with-unscaled-gradients">docs</a>
for more information on the scaling of gradients.</p>
<p>If clipping gradients, the gradients will not have been clipped yet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="c1"># example to inspect gradient information in tensorboard</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># don&#39;t make the tf file huge</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
                <span class="n">tag</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span>
            <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_zero_grad">
<span class="sig-name descname"><span class="pre">on_before_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_before_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<p>Called in the training loop after taking an optimizer step and before zeroing grads.
Good place to inspect weight information with weights updated.</p>
<p>This is where it is called:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">on_before_zero_grad</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span> <span class="c1"># &lt; ---- called here</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The optimizer for which grads should be zeroed.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_fit_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very end of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_fit_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very beginning of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_gpu">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">on_gpu</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_gpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p>
<p>Useful to set flags around the LightningModule for different CPU vs GPU behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_load_checkpoint">
<span class="sig-name descname"><span class="pre">on_load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_load_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning to restore your model. If you saved something with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_save_checkpoint"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_save_checkpoint()</span></code></a> this is
your chance to restore this.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Loaded checkpoint</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of the time you don&#39;t need to implement this method</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">something_cool_i_want_to_save</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning auto-restores global step, epoch, and train state including amp scaling.
There is no need for you to restore anything regarding training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_batch_end">
<span class="sig-name descname"><span class="pre">on_predict_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The outputs of predict_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the prediction DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_batch_start">
<span class="sig-name descname"><span class="pre">on_predict_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_end">
<span class="sig-name descname"><span class="pre">on_predict_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_epoch_end">
<span class="sig-name descname"><span class="pre">on_predict_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_epoch_start">
<span class="sig-name descname"><span class="pre">on_predict_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_model_eval">
<span class="sig-name descname"><span class="pre">on_predict_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the predict loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_start">
<span class="sig-name descname"><span class="pre">on_predict_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_predict_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_save_checkpoint">
<span class="sig-name descname"><span class="pre">on_save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to
save.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The full checkpoint dictionary before it gets dumped to a file.
Implementations of this hook can insert additional data into this dictionary.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of use cases you don&#39;t need to implement this method</span>
    <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_cool_pickable_object</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning saves all aspects of training (epoch, global step, etc…)
including amp scaling.
There is no need for you to store anything about training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_batch_end">
<span class="sig-name descname"><span class="pre">on_test_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of test_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_batch_start">
<span class="sig-name descname"><span class="pre">on_test_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_end">
<span class="sig-name descname"><span class="pre">on_test_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_epoch_end">
<span class="sig-name descname"><span class="pre">on_test_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_epoch_start">
<span class="sig-name descname"><span class="pre">on_test_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_model_eval">
<span class="sig-name descname"><span class="pre">on_test_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_model_train">
<span class="sig-name descname"><span class="pre">on_test_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_start">
<span class="sig-name descname"><span class="pre">on_test_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_test_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_batch_end">
<span class="sig-name descname"><span class="pre">on_train_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of training_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_batch_start">
<span class="sig-name descname"><span class="pre">on_train_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop before anything happens for that batch.</p>
<p>If you return -1 here, you will skip training for the rest of the current epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_end">
<span class="sig-name descname"><span class="pre">on_train_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of training before logger experiment is closed.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very end of the epoch.</p>
<p>To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> and access them in this hook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyLightningModule</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># do something with all training_step outputs, for example:</span>
        <span class="n">epoch_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;training_epoch_mean&quot;</span><span class="p">,</span> <span class="n">epoch_mean</span><span class="p">)</span>
        <span class="c1"># free up the memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_epoch_start">
<span class="sig-name descname"><span class="pre">on_train_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_start">
<span class="sig-name descname"><span class="pre">on_train_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_train_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of training after sanity check.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_batch_end">
<span class="sig-name descname"><span class="pre">on_validation_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of validation_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_batch_start">
<span class="sig-name descname"><span class="pre">on_validation_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_end">
<span class="sig-name descname"><span class="pre">on_validation_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_epoch_end">
<span class="sig-name descname"><span class="pre">on_validation_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_epoch_start">
<span class="sig-name descname"><span class="pre">on_validation_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_eval">
<span class="sig-name descname"><span class="pre">on_validation_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_train">
<span class="sig-name descname"><span class="pre">on_validation_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_zero_grad">
<span class="sig-name descname"><span class="pre">on_validation_model_zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_model_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by the training loop to release gradients before entering the validation loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_start">
<span class="sig-name descname"><span class="pre">on_validation_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.on_validation_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizer_step">
<span class="sig-name descname"><span class="pre">optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
the optimizer.</p>
<p>By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code> as shown in the example.
This method (and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code>) won’t be called during the accumulation phase when
<code class="docutils literal notranslate"><span class="pre">Trainer(accumulate_grad_batches</span> <span class="pre">!=</span> <span class="pre">1)</span></code>. Overriding this hook has no benefit with manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – A PyTorch optimizer</p></li>
<li><p><strong>optimizer_closure</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[], <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]]) – The optimizer closure. This closure must be executed as it includes the
calls to <code class="docutils literal notranslate"><span class="pre">training_step()</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>, and <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

<span class="c1"># Learning rate warm-up</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="c1"># update params</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

    <span class="c1"># manually warm up lr without a scheduler</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">&lt;</span> <span class="mi">500</span><span class="p">:</span>
        <span class="n">lr_scale</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">500.0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">pg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_scale</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizer_zero_grad">
<span class="sig-name descname"><span class="pre">optimizer_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizer_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – A PyTorch optimizer</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="c1"># Set gradients to `None` instead of zero to improve performance (not required on `torch&gt;=2.0.0`).</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for the explanation of the above example.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizers">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the optimizer(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_pl_optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will wrap the optimizer(s) in a
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code> for automatic handling of precision,
profiling, and counting of step calls for proper logging and checkpointing. It specifically wraps the
<code class="docutils literal notranslate"><span class="pre">step</span></code> method and custom optimizers that don’t have this method are not supported.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A single optimizer, or a list of optimizers in case multiple ones are present.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.output_chunk_length">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_chunk_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.output_chunk_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of time steps predicted at once by the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>Parameter</em> – module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.pred_batch_size">
<span class="sig-name descname"><span class="pre">pred_batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.pred_batch_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.pred_n">
<span class="sig-name descname"><span class="pre">pred_n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.pred_n" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.pred_n_jobs">
<span class="sig-name descname"><span class="pre">pred_n_jobs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.pred_n_jobs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.pred_num_samples">
<span class="sig-name descname"><span class="pre">pred_num_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.pred_num_samples" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.pred_roll_size">
<span class="sig-name descname"><span class="pre">pred_roll_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.pred_roll_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.predict_dataloader">
<span class="sig-name descname"><span class="pre">predict_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.predict_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying prediction samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code> or a sequence of them specifying prediction samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.predict_likelihood_parameters">
<span class="sig-name descname"><span class="pre">predict_likelihood_parameters</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.predict_likelihood_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.predict_step">
<span class="sig-name descname"><span class="pre">predict_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.predict_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the prediction step</p>
<dl class="simple">
<dt>batch</dt><dd><p>output of Darts’ <code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceDataset</span></code> - tuple of <code class="docutils literal notranslate"><span class="pre">(past_target,</span> <span class="pre">past_covariates,</span>
<span class="pre">historic_future_covariates,</span> <span class="pre">future_covariates,</span> <span class="pre">future_past_covariates,</span> <span class="pre">input_timeseries)</span></code></p>
</dd>
<dt>batch_idx</dt><dd><p>the batch index of the current batch</p>
</dd>
<dt>dataloader_idx</dt><dd><p>the dataloader index</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data">
<span class="sig-name descname"><span class="pre">prepare_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Use this to download and prepare data. Downloading and saving data with multiple processes (distributed
settings) will result in corrupted data. Lightning ensures this method is called only within a single process,
so you can safely add your downloading logic within.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>DO NOT set state to the model (use <code class="docutils literal notranslate"><span class="pre">setup</span></code> instead)
since this is NOT called on every device</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># good</span>
    <span class="n">download_data</span><span class="p">()</span>
    <span class="n">tokenize</span><span class="p">()</span>
    <span class="n">etc</span><span class="p">()</span>

    <span class="c1"># bad</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">data_split</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">some_state</span> <span class="o">=</span> <span class="n">some_other_state</span><span class="p">()</span>
</pre></div>
</div>
<p>In a distributed environment, <code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> can be called in two ways
(using <span class="xref std std-ref">prepare_data_per_node</span>)</p>
<ol class="arabic simple">
<li><p>Once per node. This is the default and is only called on LOCAL_RANK=0.</p></li>
<li><p>Once in total. Only called on GLOBAL_RANK=0.</p></li>
</ol>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="c1"># called once per node on LOCAL_RANK=0 of that node</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># call on GLOBAL_RANK=0 (great for shared file systems)</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>This is called before requesting the dataloaders:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">initialize_distributed</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_dataloader</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data_per_node" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.print">
<span class="sig-name descname"><span class="pre">print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.print" title="Permalink to this definition">¶</a></dt>
<dd><p>Prints only from process 0. Use this in any distributed mode to log only once.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – The thing to print. The same as for Python’s built-in print function.</p></li>
<li><p><strong>**kwargs</strong> – The same as for Python’s built-in print function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;in forward&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>This function is deprecated in favor of <code class="xref py py-meth docutils literal notranslate"><span class="pre">register_full_backward_hook()</span></code> and
the behavior of this function will change in future versions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the module’s state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">persistent</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the buffer. The buffer can be accessed
from this module using the given name</p></li>
<li><p><strong>tensor</strong> (<em>Tensor</em><em> or </em><em>None</em>) – buffer to be registered. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations
that run on buffers, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>, are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
the buffer is <strong>not</strong> included in the module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>) – whether the buffer is part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">always_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_forward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
output. It can modify the input inplace but it will not have effect on
forward since this is called after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called. The hook
should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the forward hook will be passed the
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> given to the forward function and be expected to return the
output possibly modified. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired
before all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_hook()</span></code> will fire before all hooks
registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the
kwargs given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>always_call</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be run regardless of
whether an exception is raised while calling the Module.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_forward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is false or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
input. User can either return a tuple or a single modified value in the
hook. We will wrap the value into a tuple if a single value is returned
(unless that value is already a tuple). The hook should have the
following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is true, the forward pre-hook will be passed the
kwargs given to the forward function. And if the hook modifies the
input, both the args and kwargs should be returned. The hook should have
the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">a</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">modified</span> <span class="nb">input</span> <span class="ow">and</span> <span class="n">kwargs</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_pre_hook()</span></code> will fire before all
hooks registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If true, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the kwargs
given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_full_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to a module
are computed, i.e. the hook will execute if and only if the gradients with
respect to module outputs are computed. The hook should have the following
signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in
subsequent computations. <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for all non-Tensor
arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_full_backward_pre_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_full_backward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward pre-hook on the module.</p>
<p>The hook will be called every time the gradients for the module are computed.
The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> is a tuple. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the output that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> in
subsequent computations. Entries in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for
all non-Tensor arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_pre_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_load_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_load_state_dict_post_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a post hook to be run after module’s <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code>
is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, incompatible_keys) -&gt; None</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">module</span></code> argument is the current module that this hook is registered
on, and the <code class="docutils literal notranslate"><span class="pre">incompatible_keys</span></code> argument is a <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> consisting
of attributes <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>. <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code>
is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the missing keys and
<code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the unexpected keys.</p>
<p>The given incompatible_keys can be modified inplace if needed.</p>
<p>Note that the checks performed when calling <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">strict=True</span></code> are affected by modifications the hook makes to
<code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> or <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>, as expected. Additions to either
set of keys will result in an error being thrown when <code class="docutils literal notranslate"><span class="pre">strict=True</span></code>, and
clearing out both missing and unexpected keys will avoid an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_module">
<span class="sig-name descname"><span class="pre">register_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_parameter">
<span class="sig-name descname"><span class="pre">register_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the parameter. The parameter can be accessed
from this module using the given name</p></li>
<li><p><strong>param</strong> (<em>Parameter</em><em> or </em><em>None</em>) – parameter to be added to the module. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations that run on parameters, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>,
are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the parameter is <strong>not</strong> included in the
module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.register_state_dict_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>,
and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>. The registered
hooks can be used to perform pre-processing before the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>
call is made.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.requires_grad_" title="Permalink to this definition">¶</a></dt>
<dd><p>Change if autograd should record operations on parameters in this
module.</p>
<p>This method sets the parameters’ <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.requires_grad_()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<em>bool</em>) – whether autograd should record operations on
parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters">
<span class="sig-name descname"><span class="pre">save_hyperparameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.save_hyperparameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – single object of <cite>dict</cite>, <cite>NameSpace</cite> or <cite>OmegaConf</cite>
or string names or arguments from class <code class="docutils literal notranslate"><span class="pre">__init__</span></code></p></li>
<li><p><strong>ignore</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – an argument name or a list of argument names from
class <code class="docutils literal notranslate"><span class="pre">__init__</span></code> to be ignored</p></li>
<li><p><strong>frame</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">frame</span></code>]) – a frame object. Default is None</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to send the hyperparameters to the logger. Default: True</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Example::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign arguments</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="s1">&#39;arg1&#39;</span><span class="p">,</span> <span class="s1">&#39;arg3&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AutomaticArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># equivalent automatic</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutomaticArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg2&quot;: abc</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">SingleArgModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign single argument</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleArgModel</span><span class="p">(</span><span class="n">Namespace</span><span class="p">(</span><span class="n">p1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p2</span><span class="o">=</span><span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="n">p3</span><span class="o">=</span><span class="mf">3.14</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;p1&quot;: 1</span>
<span class="go">&quot;p2&quot;: abc</span>
<span class="go">&quot;p3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># pass argument(s) to ignore as a string or in a list</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="s1">&#39;arg2&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state
found within the <cite>state_dict</cite>. Implement this function and a corresponding
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.get_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_extra_state()</span></code></a> for your module if you need to store extra state within its
<cite>state_dict</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>dict</em>) – Extra state from the <cite>state_dict</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_mc_dropout">
<span class="sig-name descname"><span class="pre">set_mc_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">active</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_mc_dropout" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_predict_parameters">
<span class="sig-name descname"><span class="pre">set_predict_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roll_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.set_predict_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you
need to build models dynamically or adjust something about them. This hook is called on every process when
using DDP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">download_data</span><span class="p">()</span>
        <span class="n">tokenize</span><span class="p">()</span>

        <span class="c1"># don&#39;t do this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">something</span> <span class="o">=</span> <span class="k">else</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.share_memory">
<span class="sig-name descname"><span class="pre">share_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.share_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>~T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary containing references to the whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to <code class="docutils literal notranslate"><span class="pre">None</span></code> are not included.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned object is a shallow copy. It contains references
to the module’s parameters and buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> also accepts positional arguments for
<code class="docutils literal notranslate"><span class="pre">destination</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> in order. However,
this is being deprecated and keyword arguments will be enforced in
future releases.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please avoid the use of argument <code class="docutils literal notranslate"><span class="pre">destination</span></code> as it is not
designed for end-users.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>destination</strong> (<em>dict</em><em>, </em><em>optional</em>) – If provided, the state of module will
be updated into the dict and the same object is returned.
Otherwise, an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> will be created and returned.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em>) – a prefix added to parameter and buffer
names to compose the keys in state_dict. Default: <code class="docutils literal notranslate"><span class="pre">''</span></code>.</p></li>
<li><p><strong>keep_vars</strong> (<em>bool</em><em>, </em><em>optional</em>) – by default the <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> s
returned in the state dict are detached from autograd. If it’s
set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, detaching will not be performed.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary containing a whole state of the module</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.teardown">
<span class="sig-name descname"><span class="pre">teardown</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.teardown" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of fit (train + validate), validate, test, or predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_dataloader">
<span class="sig-name descname"><span class="pre">test_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying test samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">test()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a test dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a>, you don’t need to implement
this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the test set. In this step you’d normally generate examples or
calculate anything of interest such as accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your data iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><strong>batch_idx</strong> – The index of this batch.</p></li>
<li><p><strong>dataloader_idx</strong> – The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Skip to the next batch.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one test dataloader:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="o">...</span>

<span class="c1"># if you have multiple test dataloaders:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single test dataset</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple test dataloaders, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple test dataloaders</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="o">...</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need to test you don’t need to implement this method.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> is called, the model has been put in eval mode and
PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
to training mode and gradients are enabled.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_dtype">
<span class="sig-name descname"><span class="pre">to_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Cast module precision (float32 by default) to another precision.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_empty" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves the parameters and buffers to the specified device without copying storage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>) – The desired device of the parameters
and buffers in this module.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – Whether parameters and buffers of submodules should
be recursively moved to the specified device.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_onnx">
<span class="sig-name descname"><span class="pre">to_onnx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_onnx" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the model in ONNX format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>]) – The path of the file the onnx model should be saved to.</p></li>
<li><p><strong>input_sample</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input for tracing. Default: None (Use self.example_input_array)</p></li>
<li><p><strong>**kwargs</strong> – Will be passed to torch.onnx.export function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">input_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">(</span><span class="s2">&quot;export.onnx&quot;</span><span class="p">,</span> <span class="n">input_sample</span><span class="p">,</span> <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_torchscript">
<span class="sig-name descname"><span class="pre">to_torchscript</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'script'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.to_torchscript" title="Permalink to this definition">¶</a></dt>
<dd><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>. If you want to use tracing,
please provided the argument <code class="docutils literal notranslate"><span class="pre">method='trace'</span></code> and make sure that either the <cite>example_inputs</cite> argument is
provided, or the model has <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a> set. If you would like to customize the modules that are
scripted you should override this method. In case you want to return multiple modules, we recommend using a
dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Path where to save the torchscript. Default: None (no file saved).</p></li>
<li><p><strong>method</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Whether to use TorchScript’s script or trace method. Default: ‘script’</p></li>
<li><p><strong>example_inputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input to be used to do tracing when method is set to ‘trace’.
Default: None (uses <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments that will be passed to the <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.script()</span></code> or
<code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.trace()</span></code> function.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Requires the implementation of the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> method.</p></li>
<li><p>The exported script will be set to evaluation mode.</p></li>
<li><p>It is recommended that you install the latest supported version of PyTorch
to use this feature without limitations. See also the <code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.jit</span></code>
documentation for supported features.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span>
    <span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model_trace.pt&quot;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;trace&#39;</span><span class="p">,</span> <span class="n">example_inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>]]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>This LightningModule as a torchscript, regardless of whether <cite>file_path</cite> is
defined or not.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.toggle_optimizer">
<span class="sig-name descname"><span class="pre">toggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.toggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Makes sure only the gradients of the current optimizer’s parameters are calculated in the training step to
prevent dangling gradients in multiple-optimizer setup.</p>
<p>It works with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.untoggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">untoggle_optimizer()</span></code></a> to make sure <code class="docutils literal notranslate"><span class="pre">param_requires_grad_state</span></code> is properly reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to toggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.train_dataloader">
<span class="sig-name descname"><span class="pre">train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.train_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying training samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id25"><span class="problematic" id="id26">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.trainer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">trainer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.trainer.trainer.Trainer</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.trainer" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the training step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.transfer_batch_to_device">
<span class="sig-name descname"><span class="pre">transfer_batch_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.transfer_batch_to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data
structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code> or anything that implements <cite>.to(…)</cite></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, …).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook should only transfer the data and not modify it, nor should it move the data to
any other device than the one passed in as argument (unless you know what you are doing).
To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be transferred to a new device.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>) – The target device as defined in PyTorch.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A reference to the data on the new device.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">CustomBatch</span><span class="p">):</span>
        <span class="c1"># move all tensors in your custom data structure to the device</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># skip device transfer for the first dataloader or anything you wish</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transfer_batch_to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">move_data_to_device()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_to_collection()</span></code></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.type">
<span class="sig-name descname"><span class="pre">type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.type" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.unfreeze">
<span class="sig-name descname"><span class="pre">unfreeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze all parameters for training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.untoggle_optimizer">
<span class="sig-name descname"><span class="pre">untoggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.untoggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to untoggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.val_dataloader">
<span class="sig-name descname"><span class="pre">val_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.val_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying validation samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id27"><span class="problematic" id="id28">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">validate()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a validation dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a>, you don’t need to
implement this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the validation step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.xpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the XPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLMixedCovariatesModule.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets gradients of all model parameters. See similar function
under <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code> for more context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>set_to_none</strong> (<em>bool</em>) – instead of setting to zero, set the grads to None.
See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for details.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">darts.models.forecasting.pl_forecasting_module.</span></span><span class="sig-name descname"><span class="pre">PLPastCovariatesModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_sample_shape=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn=MSELoss()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_metrics=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_cls=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_cls=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_reversible_instance_norm=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLPastCovariatesModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">darts.models.forecasting.pl_forecasting_module.PLForecastingModule</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>PyTorch Lightning-based Forecasting Module.</p>
<p>This class is meant to be inherited to create a new PyTorch Lightning-based forecasting module.
When subclassing this class, please make sure to add the following methods with the given signatures:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.__init__()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.forward()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._produce_train_output()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._get_batch_prediction()</span></code></p></li>
</ul>
</div></blockquote>
<p>In subclass <cite>MyModel</cite>’s <code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code> function call <code class="docutils literal notranslate"><span class="pre">super(MyModel,</span> <span class="pre">self).__init__(**kwargs)</span></code> where
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> are the parameters of <code class="xref py py-class docutils literal notranslate"><span class="pre">PLTorchForecastingModel</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps in the past to take as a model input (per chunk). Applies to the target
series, and past and/or future covariates (if the model supports it).</p></li>
<li><p><strong>output_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps predicted at once (per chunk) by the internal model. Also, the number of future values
from future covariates to use as a model input (if the model supports future covariates). It is not the same
as forecast horizon <cite>n</cite> used in <cite>predict()</cite>, which is the desired number of prediction points generated
using either a one-shot- or auto-regressive forecast. Setting <cite>n &lt;= output_chunk_length</cite> prevents
auto-regression. This is useful when the covariates don’t extend far enough into the future, or to prohibit
the model from using future values of past and / or future covariates for prediction (depending on the
model’s covariate support).</p></li>
<li><p><strong>train_sample_shape</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Shape of the model’s input, used to instantiate model without calling <code class="docutils literal notranslate"><span class="pre">fit_from_dataset</span></code> and
perform sanity check on new training/inference datasets used for re-training or prediction.</p></li>
<li><p><strong>loss_fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code>) – PyTorch loss function used for training.
This parameter will be ignored for probabilistic models if the <code class="docutils literal notranslate"><span class="pre">likelihood</span></code> parameter is specified.
Default: <code class="docutils literal notranslate"><span class="pre">torch.nn.MSELoss()</span></code>.</p></li>
<li><p><strong>torch_metrics</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – A torch metric or a <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code> used for evaluation. A full list of available metrics can be found
at <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/">https://torchmetrics.readthedocs.io/en/latest/</a>. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>likelihood</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code></a>]) – One of Darts’ <a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Likelihood</span></code></a> models to be used for
probabilistic forecasts. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>optimizer_cls</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The PyTorch optimizer class to be used. Default: <code class="docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code>.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch optimizer (e.g., <code class="docutils literal notranslate"><span class="pre">{'lr':</span> <span class="pre">1e-3}</span></code>
for specifying a learning rate). Otherwise the default values of the selected <code class="docutils literal notranslate"><span class="pre">optimizer_cls</span></code>
will be used. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_cls</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_LRScheduler</span></code>]) – Optionally, the PyTorch learning rate scheduler class to be used. Specifying <code class="docutils literal notranslate"><span class="pre">None</span></code> corresponds
to using a constant learning rate. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch learning rate scheduler. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>use_reversible_instance_norm</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to use reversible instance normalization <cite>RINorm</cite> against distribution shift as shown in <a class="reference internal" href="#r9944a583435e-1" id="id29">[1]</a>.
It is only applied to the features of the target series and not the covariates.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r9944a583435e-1"><span class="brackets"><a class="fn-backref" href="#id29">1</a></span></dt>
<dd><p>T. Kim et al. “Reversible Instance Normalization for Accurate Time-Series Forecasting against
Distribution Shift”, <a class="reference external" href="https://openreview.net/forum?id=cGDAkQo1C0p">https://openreview.net/forum?id=cGDAkQo1C0p</a></p>
</dd>
</dl>
<p class="rubric">Attributes</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.automatic_optimization" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.automatic_optimization"><code class="xref py py-obj docutils literal notranslate"><span class="pre">automatic_optimization</span></code></a></p></td>
<td><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.current_epoch" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.current_epoch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">current_epoch</span></code></a></p></td>
<td><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.example_input_array"><code class="xref py py-obj docutils literal notranslate"><span class="pre">example_input_array</span></code></a></p></td>
<td><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.global_rank" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.global_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_rank</span></code></a></p></td>
<td><p>The index of the current process across all nodes and devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.global_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.global_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_step</span></code></a></p></td>
<td><p>Total training batches seen across all epochs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams_initial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams_initial</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.local_rank" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.local_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">local_rank</span></code></a></p></td>
<td><p>The index of the current process within a single node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.logger" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.logger"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logger</span></code></a></p></td>
<td><p>Reference to the logger object in the Trainer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.loggers" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.loggers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">loggers</span></code></a></p></td>
<td><p>Reference to the list of loggers in the Trainer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_gpu" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_gpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_gpu</span></code></a></p></td>
<td><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.output_chunk_length" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.output_chunk_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_chunk_length</span></code></a></p></td>
<td><p>Number of time steps predicted at once by the model.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>device</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>dtype</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>epochs_trained</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>fabric</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>trainer</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.add_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_module</span></code></a>(name, module)</p></td>
<td><p>Adds a child module to the current module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.all_gather" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.all_gather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">all_gather</span></code></a>(data[, group, sync_grads])</p></td>
<td><p>Gather tensors or collections of tensors from multiple processes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.apply" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.backward" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.bfloat16" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.bfloat16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfloat16</span></code></a>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.buffers" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">buffers</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.children" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.clip_gradients" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.clip_gradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip_gradients</span></code></a>(optimizer[, ...])</p></td>
<td><p>Handles gradient clipping internally.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.compile" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(*args, **kwargs)</p></td>
<td><p>Compile this Module's forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_callbacks" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_callbacks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_callbacks</span></code></a>()</p></td>
<td><p>Configure model-specific callbacks.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_gradient_clipping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_gradient_clipping</span></code></a>(optimizer[, ...])</p></td>
<td><p>Perform gradient clipping for the optimizer parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_model" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_model</span></code></a>()</p></td>
<td><p>Hook to create modules in a strategy and precision aware context.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_optimizers" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_optimizers</span></code></a>()</p></td>
<td><p>configures optimizers and learning rate schedulers for model optimization.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_sharded_model" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_sharded_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_sharded_model</span></code></a>()</p></td>
<td><p>Deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_torch_metrics" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_torch_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_torch_metrics</span></code></a>(torch_metrics)</p></td>
<td><p>process the torch_metrics parameter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cpu" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cuda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.double" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.double"><code class="xref py py-obj docutils literal notranslate"><span class="pre">double</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.eval" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code></a>()</p></td>
<td><p>Sets the module in evaluation mode.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.extra_repr" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.extra_repr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extra_repr</span></code></a>()</p></td>
<td><p>Set the extra representation of the module</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(*args, **kwargs)</p></td>
<td><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.freeze" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.freeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">freeze</span></code></a>()</p></td>
<td><p>Freeze all params for inference.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_buffer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_buffer</span></code></a>(target)</p></td>
<td><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_extra_state</span></code></a>()</p></td>
<td><p>Returns any extra state to include in the module's state_dict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_parameter" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_parameter</span></code></a>(target)</p></td>
<td><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_submodule" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_submodule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_submodule</span></code></a>(target)</p></td>
<td><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.half" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.half"><code class="xref py py-obj docutils literal notranslate"><span class="pre">half</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.ipu" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.ipu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ipu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the IPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_from_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_from_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code></a>([map_location, ...])</p></td>
<td><p>Primary way of loading a model from a checkpoint.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>(state_dict[, strict, assign])</p></td>
<td><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.log" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log</span></code></a>(name, value[, prog_bar, logger, ...])</p></td>
<td><p>Log a key, value pair.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.log_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.log_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_dict</span></code></a>(dictionary[, prog_bar, logger, ...])</p></td>
<td><p>Log a dictionary of values at once.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.lr_scheduler_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.lr_scheduler_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_scheduler_step</span></code></a>(scheduler, metric)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls each scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.lr_schedulers" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.lr_schedulers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_schedulers</span></code></a>()</p></td>
<td><p>Returns the learning rate scheduler(s) that are being used during training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.manual_backward" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.manual_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">manual_backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.modules" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">modules</span></code></a>()</p></td>
<td><p>Returns an iterator over all modules in the network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_buffers" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_buffers</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_children" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_modules" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_modules</span></code></a>([memo, prefix, remove_duplicate])</p></td>
<td><p>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_parameters" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_after_backward" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_after_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_backward</span></code></a>()</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_after_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_backward" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_backward</span></code></a>(loss)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code></a>(optimizer)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_zero_grad</span></code></a>(optimizer)</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_fit_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_fit_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_end</span></code></a>()</p></td>
<td><p>Called at the very end of fit.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_fit_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_fit_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_start</span></code></a>()</p></td>
<td><p>Called at the very beginning of fit.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_load_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_load_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_load_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning to restore your model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the predict loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the predict loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the predict loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_save_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_save_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to save.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the test loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the test loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_end</span></code></a>()</p></td>
<td><p>Called at the end of testing.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_end</span></code></a>()</p></td>
<td><p>Called in the test loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_start</span></code></a>()</p></td>
<td><p>Called in the test loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the test loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_model_train" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the test loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_start</span></code></a>()</p></td>
<td><p>Called at the beginning of testing.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the training loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the training loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_end</span></code></a>()</p></td>
<td><p>Called at the end of training before logger experiment is closed.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_end</span></code></a>()</p></td>
<td><p>Called in the training loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_start</span></code></a>()</p></td>
<td><p>Called in the training loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_start</span></code></a>()</p></td>
<td><p>Called at the beginning of training after sanity check.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_end</span></code></a>(outputs, batch, ...)</p></td>
<td><p>Called in the validation loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the validation loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_end</span></code></a>()</p></td>
<td><p>Called at the end of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_end</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_start</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the val loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_train" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the val loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_zero_grad</span></code></a>()</p></td>
<td><p>Called by the training loop to release gradients before entering the validation loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_start" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_start</span></code></a>()</p></td>
<td><p>Called at the beginning of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_step</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls the optimizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizer_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizer_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_zero_grad</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizers" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizers</span></code></a>([use_pl_optimizer])</p></td>
<td><p>Returns the optimizer(s) that are being used during training.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.parameters" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.predict_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.predict_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying prediction samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.predict_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.predict_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_step</span></code></a>(batch, batch_idx[, dataloader_idx])</p></td>
<td><p>performs the prediction step</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare_data</span></code></a>()</p></td>
<td><p>Use this to download and prepare data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.print" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.print"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print</span></code></a>(*args, **kwargs)</p></td>
<td><p>Prints only from process 0.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_backward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_buffer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_buffer</span></code></a>(name, tensor[, persistent])</p></td>
<td><p>Adds a buffer to the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_forward_hook" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook, *[, prepend, ...])</p></td>
<td><p>Registers a forward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_forward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook, *[, ...])</p></td>
<td><p>Registers a forward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_full_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_full_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_full_backward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_full_backward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_pre_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_load_state_dict_post_hook" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_load_state_dict_post_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_load_state_dict_post_hook</span></code></a>(hook)</p></td>
<td><p>Registers a post hook to be run after module's <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> is called.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_module" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_module</span></code></a>(name, module)</p></td>
<td><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_parameter" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_parameter</span></code></a>(name, param)</p></td>
<td><p>Adds a parameter to the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_state_dict_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_state_dict_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_state_dict_pre_hook</span></code></a>(hook)</p></td>
<td><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>, and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.requires_grad_" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.requires_grad_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad_</span></code></a>([requires_grad])</p></td>
<td><p>Change if autograd should record operations on parameters in this module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_hyperparameters</span></code></a>(*args[, ignore, frame, ...])</p></td>
<td><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_extra_state</span></code></a>(state)</p></td>
<td><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state found within the <cite>state_dict</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_predict_parameters" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_predict_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_predict_parameters</span></code></a>(n, num_samples, ...)</p></td>
<td><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>(stage)</p></td>
<td><p>Called at the beginning of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.share_memory" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.share_memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_memory</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code></a>(*args[, destination, prefix, ...])</p></td>
<td><p>Returns a dictionary containing references to the whole state of the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.teardown" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.teardown"><code class="xref py py-obj docutils literal notranslate"><span class="pre">teardown</span></code></a>(stage)</p></td>
<td><p>Called at the end of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying test samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_step</span></code></a>(*args, **kwargs)</p></td>
<td><p>Operates on a single batch of data from the test set.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_dtype" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_dtype</span></code></a>(dtype)</p></td>
<td><p>Cast module precision (float32 by default) to another precision.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_empty" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_empty</span></code></a>(*, device[, recurse])</p></td>
<td><p>Moves the parameters and buffers to the specified device without copying storage.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_onnx" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_onnx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_onnx</span></code></a>(file_path[, input_sample])</p></td>
<td><p>Saves the model in ONNX format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_torchscript" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_torchscript"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_torchscript</span></code></a>([file_path, method, ...])</p></td>
<td><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.toggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">toggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Makes sure only the gradients of the current optimizer's parameters are calculated in the training step to prevent dangling gradients in multiple-optimizer setup.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.train" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>([mode])</p></td>
<td><p>Sets the module in training mode.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.train_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.train_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying training samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">training_step</span></code></a>(train_batch, batch_idx)</p></td>
<td><p>performs the training step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.transfer_batch_to_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transfer_batch_to_device</span></code></a>(batch, device, ...)</p></td>
<td><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data structure.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.type" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code></a>(dst_type)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.unfreeze" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.unfreeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unfreeze</span></code></a>()</p></td>
<td><p>Unfreeze all parameters for training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.untoggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">untoggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.val_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.val_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">val_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying validation samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.validation_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">validation_step</span></code></a>(val_batch, batch_idx)</p></td>
<td><p>performs the validation step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.xpu" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.xpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xpu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the XPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>([set_to_none])</p></td>
<td><p>Resets gradients of all model parameters.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>__call__</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_mc_dropout</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.CHECKPOINT_HYPER_PARAMS_KEY">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_KEY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hyper_parameters'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.CHECKPOINT_HYPER_PARAMS_KEY" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.CHECKPOINT_HYPER_PARAMS_NAME">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_name'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.CHECKPOINT_HYPER_PARAMS_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.CHECKPOINT_HYPER_PARAMS_TYPE">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_TYPE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_type'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.CHECKPOINT_HYPER_PARAMS_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.T_destination">
<span class="sig-name descname"><span class="pre">T_destination</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.T_destination" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of TypeVar(‘T_destination’, bound=<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>])</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.add_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the child module. The child module can be
accessed from this module using the given name</p></li>
<li><p><strong>module</strong> (<em>Module</em>) – child module to be added to the module.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.all_gather">
<span class="sig-name descname"><span class="pre">all_gather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.all_gather" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather tensors or collections of tensors from multiple processes.</p>
<p>This method needs to be called on all processes and the tensors need to have the same shape across all
processes, otherwise your program will stall forever.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – int, float, tensor of shape (batch, …), or a (possibly nested) collection thereof.</p></li>
<li><p><strong>group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the process group to gather results from. Defaults to all processes (world)</p></li>
<li><p><strong>sync_grads</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – flag that allows users to synchronize gradients for the all_gather operation</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor of shape (world_size, batch, …), or if the input was a collection
the output will also be a collection with tensors of this shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.allow_zero_length_dataloader_with_multiple_devices" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>)
as well as self. Typical use includes initializing the parameters of a model
(see also <span class="xref std std-ref">nn-init-doc</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> -&gt; None) – function to be applied to each submodule</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.automatic_optimization">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">automatic_optimization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.automatic_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. Override this hook with your own
implementation if you need to.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The loss tensor returned by <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. If gradient accumulation is used, the loss here
holds the normalized value (scaled by 1 / accumulation steps).</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.bfloat16">
<span class="sig-name descname"><span class="pre">bfloat16</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.bfloat16" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.buffers">
<span class="sig-name descname"><span class="pre">buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – module buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.call_super_init">
<span class="sig-name descname"><span class="pre">call_super_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.call_super_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a child module</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.clip_gradients">
<span class="sig-name descname"><span class="pre">clip_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.clip_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Handles gradient clipping internally.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Do not override this method. If you want to customize gradient clipping, consider using
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_gradient_clipping"><code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_gradient_clipping()</span></code></a> method.</p></li>
<li><p>For manual optimization (<code class="docutils literal notranslate"><span class="pre">self.automatic_optimization</span> <span class="pre">=</span> <span class="pre">False</span></code>), if you want to use
gradient clipping, consider calling
<code class="docutils literal notranslate"><span class="pre">self.clip_gradients(opt,</span> <span class="pre">gradient_clip_val=0.5,</span> <span class="pre">gradient_clip_algorithm=&quot;norm&quot;)</span></code>
manually in the training step.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. Pass <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;value&quot;</span></code>
to clip by value, and <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;norm&quot;</span></code> to clip by norm.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.compile" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile this Module’s forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>This Module’s <cite>__call__</cite> method is compiled and all arguments are passed as-is
to <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>See <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code> for details on the arguments for this function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_callbacks">
<span class="sig-name descname"><span class="pre">configure_callbacks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_callbacks" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure model-specific callbacks. When the model gets attached, e.g., when <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> or <code class="docutils literal notranslate"><span class="pre">.test()</span></code> gets
called, the list or a callback returned here will be merged with the list of callbacks passed to the Trainer’s
<code class="docutils literal notranslate"><span class="pre">callbacks</span></code> argument. If a callback returned here has the same type as one or several callbacks already
present in the Trainer’s callbacks list, it will take priority and replace them. In addition, Lightning will
make sure <code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> callbacks run last.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A callback or a list of callbacks which will extend the list of callbacks in the Trainer.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">early_stop</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_gradient_clipping">
<span class="sig-name descname"><span class="pre">configure_gradient_clipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_gradient_clipping" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform gradient clipping for the optimizer parameters. Called before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizer_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients. By default, value passed in Trainer
will be available here.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. By default, value
passed in Trainer will be available here.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_gradient_clipping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="p">,</span> <span class="n">gradient_clip_algorithm</span><span class="p">):</span>
    <span class="c1"># Implement your own custom logic to clip gradients</span>
    <span class="c1"># You can call `self.clip_gradients` with your settings:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="o">=</span><span class="n">gradient_clip_val</span><span class="p">,</span>
        <span class="n">gradient_clip_algorithm</span><span class="o">=</span><span class="n">gradient_clip_algorithm</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_model">
<span class="sig-name descname"><span class="pre">configure_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook to create modules in a strategy and precision aware context.</p>
<p>This is particularly useful for when using sharded strategies (FSDP and DeepSpeed), where we’d like to shard
the model instantly to save memory and initialization time.
For non-sharded strategies, you can choose to override this hook or to initialize your model under the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">init_module()</span></code> context manager.</p>
<p>This hook is called during each of fit/val/test/predict stages in the same process, so ensure that
implementation of this hook is idempotent.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>configures optimizers and learning rate schedulers for model optimization.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_sharded_model">
<span class="sig-name descname"><span class="pre">configure_sharded_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_sharded_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Deprecated.</p>
<p>Use <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_model()</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_torch_metrics">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">configure_torch_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">torch_metrics</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.configure_torch_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>process the torch_metrics parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cuda" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the GPU. This also makes associated parameters and buffers
different objects. So it should be called before constructing optimizer if the module will live on GPU while
being optimized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If specified, all parameters will be copied to that device. If <cite>None</cite>, the current CUDA device
index will be used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.current_epoch">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">current_epoch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.current_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.device</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.device" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.double" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.dtype</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.dtype" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dtype</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.dump_patches">
<span class="sig-name descname"><span class="pre">dump_patches</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.dump_patches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.epochs_trained">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">epochs_trained</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.epochs_trained" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code>.</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.eval()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.example_input_array">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">example_input_array</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.example_input_array" title="Permalink to this definition">¶</a></dt>
<dd><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method. The
return type is interpreted as follows:</p>
<ul class="simple">
<li><p>Single tensor: It is assumed the model takes a single argument, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(model.example_input_array)</span></code></p></li>
<li><p>Tuple: The input array should be interpreted as a sequence of positional arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(*model.example_input_array)</span></code></p></li>
<li><p>Dict: The input array represents named keyword arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(**model.example_input_array)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.fabric">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fabric</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.fabric.Fabric</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.fabric" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fabric</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Whatever you decide to pass into the forward method.</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments are also possible.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Your model’s output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.freeze">
<span class="sig-name descname"><span class="pre">freeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze all params for inference.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the buffer
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The buffer referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not a
buffer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns any extra state to include in the module’s state_dict.
Implement this and a corresponding <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_extra_state()</span></code></a> for your module
if you need to store extra state. This function is called when building the
module’s <cite>state_dict()</cite>.</p>
<p>Note that extra state should be picklable to ensure working serialization
of the state_dict. We only provide provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Any extra state to store in the module’s state_dict</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_parameter">
<span class="sig-name descname"><span class="pre">get_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the Parameter
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Parameter referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To check whether or not we have the <code class="docutils literal notranslate"><span class="pre">linear</span></code> submodule, we
would call <code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.linear&quot;)</span></code>. To check whether
we have the <code class="docutils literal notranslate"><span class="pre">conv</span></code> submodule, we would call
<code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.net_c.conv&quot;)</span></code>.</p>
<p>The runtime of <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> is bounded by the degree
of module nesting in <code class="docutils literal notranslate"><span class="pre">target</span></code>. A query against
<code class="docutils literal notranslate"><span class="pre">named_modules</span></code> achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists, <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> should always be
used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The submodule referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.global_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.global_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process across all nodes and devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.global_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.global_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Total training batches seen across all epochs.</p>
<p>If no Trainer is attached, this propery is 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.half" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">MutableMapping</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. It is mutable by the user. For
the frozen set of initial hyperparameters, use <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams_initial"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams_initial</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">AttributeDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MutableMapping</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mutable hyperparameters dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams_initial">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams_initial</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams_initial" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. These contents are read-only.
Manual updates to the saved hyperparameters can instead be performed through <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.hparams"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>immutable initial hyperparameters</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>AttributeDict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.ipu">
<span class="sig-name descname"><span class="pre">ipu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.ipu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the IPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on IPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_from_checkpoint">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_from_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments
passed to <code class="docutils literal notranslate"><span class="pre">__init__</span></code>  in the checkpoint under <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<p>Any arguments specified through **kwargs will override args stored in <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">IO</span></code>]) – Path to checkpoint. This can also be a URL, or file-like object</p></li>
<li><p><strong>map_location</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If your checkpoint saved a GPU model and you now load on CPUs
or a different number of GPUs, use this to map to the new setup.
The behaviour is the same as in <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code>.</p></li>
<li><p><strong>hparams_file</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optional path to a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> or <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file with hierarchical structure
as in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">drop_prob</span><span class="p">:</span> <span class="mf">0.2</span>
<span class="n">dataloader</span><span class="p">:</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="mi">32</span>
</pre></div>
</div>
<p>You most likely won’t need this since Lightning will always save the hyperparameters
to the checkpoint.
However, if your checkpoint weights don’t have the hyperparameters saved,
use this method to pass in a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file with the hparams you’d like to use.
These will be converted into a <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> and passed into your
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> for use.</p>
<p>If your model’s <code class="docutils literal notranslate"><span class="pre">hparams</span></code> argument is <code class="xref py py-class docutils literal notranslate"><span class="pre">Namespace</span></code>
and <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file has hierarchical structure, you need to refactor your model to treat
<code class="docutils literal notranslate"><span class="pre">hparams</span></code> as <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>.</p>
</p></li>
<li><p><strong>strict</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to strictly enforce that the keys in <code class="xref py py-attr docutils literal notranslate"><span class="pre">checkpoint_path</span></code> match the keys
returned by this module’s state dict.</p></li>
<li><p><strong>**kwargs</strong> – Any extra keyword args needed to init the model. Can also be used to override saved
hyperparameter values.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance with loaded weights and hyperparameters (if available).</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code> is a <strong>class</strong> method. You should use your <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code>
<strong>class</strong> to call it instead of the <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance, or a
<code class="docutils literal notranslate"><span class="pre">TypeError</span></code> will be raised.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load weights without mapping ...</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">)</span>

<span class="c1"># or load weights mapping all weights from GPU 1 to GPU 0 ...</span>
<span class="n">map_location</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span>
<span class="p">)</span>

<span class="c1"># or load weights and hyperparameters from separate files.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">hparams_file</span><span class="o">=</span><span class="s1">&#39;/path/to/hparams_file.yaml&#39;</span>
<span class="p">)</span>

<span class="c1"># override some of the params with new values</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="n">PATH</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">pretrained_ckpt_path</span><span class="o">=</span><span class="n">NEW_PATH</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># predict</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">pretrained_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into
this module and its descendants. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> the optimizer must be created after
the call to <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>dict</em>) – a dict containing parameters and
persistent buffers.</p></li>
<li><p><strong>strict</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to strictly enforce that the keys
in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this module’s
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>assign</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to assign items in the state
dictionary to their corresponding keys in the module instead
of copying them inplace into the module’s current parameters and buffers.
When <code class="docutils literal notranslate"><span class="pre">False</span></code>, the properties of the tensors in the current
module are preserved while when <code class="docutils literal notranslate"><span class="pre">True</span></code>, the properties of the
Tensors in the state dict are preserved.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>missing_keys</strong> is a list of str containing the missing keys</p></li>
<li><p><strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a parameter or buffer is registered as <code class="docutils literal notranslate"><span class="pre">None</span></code> and its corresponding key
exists in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> will raise a
<code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code>.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.local_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">local_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.local_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process within a single node.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_attribute</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a key, value pair.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>The default behavior per hook is documented here: <span class="xref std std-ref">extensions/logging:Automatic Logging</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – key to log.</p></li>
<li><p><strong>value</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]) – value to log. Can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, or a <code class="docutils literal notranslate"><span class="pre">Metric</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress bar.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto detach the graph.</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across devices. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the DDP group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple dataloaders). If False, user needs to give unique names for
each dataloader to not mix the values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch_size. This will be directly inferred from the loaded batch,
but for some data structures you might need to explicitly provide it.</p></li>
<li><p><strong>metric_attribute</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – To restore the metric state, Lightning requires the reference of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code> in your model. This is found automatically if it is a model attribute.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.log_dict">
<span class="sig-name descname"><span class="pre">log_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dictionary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.log_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a dictionary of values at once.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="s1">&#39;metric_n&#39;</span><span class="p">:</span> <span class="n">metric_n</span><span class="p">}</span>
<span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dictionary</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>]) – key value pairs.
The values can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">Metric</span></code>, or <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress base.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for training_step but not validation/test_step.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for val/test step but not <code class="docutils literal notranslate"><span class="pre">training_step</span></code>.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto-detach the graph</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across GPUs/TPUs. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the ddp group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple). If <code class="docutils literal notranslate"><span class="pre">False</span></code>, user needs to give unique names for
each dataloader to not mix values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch size. This will be directly inferred from the loaded batch,
but some data structures might need to explicitly provide it.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.logger">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.logger" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the logger object in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.loggers">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">loggers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.loggers" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the list of loggers in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.lr_scheduler_step">
<span class="sig-name descname"><span class="pre">lr_scheduler_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.lr_scheduler_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
each scheduler. By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and as shown in the example for each scheduler based on
its <code class="docutils literal notranslate"><span class="pre">interval</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scheduler</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]) – Learning rate scheduler.</p></li>
<li><p><strong>metric</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Value of the monitor used for schedulers like <code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>

<span class="c1"># Alternative way to update schedulers if it requires an epoch value</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.lr_schedulers">
<span class="sig-name descname"><span class="pre">lr_schedulers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.lr_schedulers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the learning rate scheduler(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A single scheduler, or a list of schedulers in case multiple ones are present, or <code class="docutils literal notranslate"><span class="pre">None</span></code> if no
schedulers were returned in <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_optimizers()</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.manual_backward">
<span class="sig-name descname"><span class="pre">manual_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.manual_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually. By using this,
Lightning can ensure that all the proper scaling gets applied when using mixed precision.</p>
<p>See <span class="xref std std-ref">manual optimization</span> for more examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># automatically applies scaling, etc...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The tensor on which to compute gradients. Must have a graph attached.</p></li>
<li><p><strong>*args</strong> – Additional positional arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a module in the network</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all buffer names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module. Defaults to True.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated buffers in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, torch.Tensor)</em> – Tuple containing the name and buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_children">
<span class="sig-name descname"><span class="pre">named_children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>(str, Module)</em> – Tuple containing a name and child module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_modules">
<span class="sig-name descname"><span class="pre">named_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>memo</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Set</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]) – a memo to store the set of modules already added to the result</p></li>
<li><p><strong>prefix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – a prefix that will be added to the name of the module</p></li>
<li><p><strong>remove_duplicate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – whether to remove the duplicated module instances in the result
or not</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Module)</em> – Tuple of name and module</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated
parameters in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Parameter)</em> – Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_after_backward">
<span class="sig-name descname"><span class="pre">on_after_backward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_after_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If using native AMP, the gradients will not be unscaled at this point.
Use the <code class="docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code> if you need the unscaled gradients.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_after_batch_transfer">
<span class="sig-name descname"><span class="pre">on_after_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_after_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gpu_transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_before_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_backward">
<span class="sig-name descname"><span class="pre">on_before_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Loss divided by number of batches for gradient accumulation and scaled if using AMP.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_batch_transfer">
<span class="sig-name descname"><span class="pre">on_before_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_after_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_after_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_optimizer_step">
<span class="sig-name descname"><span class="pre">on_before_optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p>
<p>If using gradient accumulation, the hook is called once the gradients have been accumulated.
See: <a href="#id30"><span class="problematic" id="id31">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.accumulate_grad_batches`</span></a>.</p>
<p>If using AMP, the loss will be unscaled before calling this hook.
See these <a class="reference external" href="https://pytorch.org/docs/stable/notes/amp_examples.html#working-with-unscaled-gradients">docs</a>
for more information on the scaling of gradients.</p>
<p>If clipping gradients, the gradients will not have been clipped yet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="c1"># example to inspect gradient information in tensorboard</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># don&#39;t make the tf file huge</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
                <span class="n">tag</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span>
            <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_zero_grad">
<span class="sig-name descname"><span class="pre">on_before_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_before_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<p>Called in the training loop after taking an optimizer step and before zeroing grads.
Good place to inspect weight information with weights updated.</p>
<p>This is where it is called:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">on_before_zero_grad</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span> <span class="c1"># &lt; ---- called here</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The optimizer for which grads should be zeroed.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_fit_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very end of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_fit_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very beginning of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_gpu">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">on_gpu</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_gpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p>
<p>Useful to set flags around the LightningModule for different CPU vs GPU behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_load_checkpoint">
<span class="sig-name descname"><span class="pre">on_load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_load_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning to restore your model. If you saved something with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_save_checkpoint"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_save_checkpoint()</span></code></a> this is
your chance to restore this.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Loaded checkpoint</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of the time you don&#39;t need to implement this method</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">something_cool_i_want_to_save</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning auto-restores global step, epoch, and train state including amp scaling.
There is no need for you to restore anything regarding training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_batch_end">
<span class="sig-name descname"><span class="pre">on_predict_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The outputs of predict_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the prediction DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_batch_start">
<span class="sig-name descname"><span class="pre">on_predict_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_end">
<span class="sig-name descname"><span class="pre">on_predict_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_epoch_end">
<span class="sig-name descname"><span class="pre">on_predict_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_epoch_start">
<span class="sig-name descname"><span class="pre">on_predict_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_model_eval">
<span class="sig-name descname"><span class="pre">on_predict_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the predict loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_start">
<span class="sig-name descname"><span class="pre">on_predict_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_predict_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_save_checkpoint">
<span class="sig-name descname"><span class="pre">on_save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to
save.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The full checkpoint dictionary before it gets dumped to a file.
Implementations of this hook can insert additional data into this dictionary.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of use cases you don&#39;t need to implement this method</span>
    <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_cool_pickable_object</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning saves all aspects of training (epoch, global step, etc…)
including amp scaling.
There is no need for you to store anything about training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_batch_end">
<span class="sig-name descname"><span class="pre">on_test_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of test_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_batch_start">
<span class="sig-name descname"><span class="pre">on_test_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_end">
<span class="sig-name descname"><span class="pre">on_test_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_epoch_end">
<span class="sig-name descname"><span class="pre">on_test_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_epoch_start">
<span class="sig-name descname"><span class="pre">on_test_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_model_eval">
<span class="sig-name descname"><span class="pre">on_test_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_model_train">
<span class="sig-name descname"><span class="pre">on_test_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_start">
<span class="sig-name descname"><span class="pre">on_test_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_test_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_batch_end">
<span class="sig-name descname"><span class="pre">on_train_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of training_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_batch_start">
<span class="sig-name descname"><span class="pre">on_train_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop before anything happens for that batch.</p>
<p>If you return -1 here, you will skip training for the rest of the current epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_end">
<span class="sig-name descname"><span class="pre">on_train_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of training before logger experiment is closed.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very end of the epoch.</p>
<p>To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> and access them in this hook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyLightningModule</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># do something with all training_step outputs, for example:</span>
        <span class="n">epoch_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;training_epoch_mean&quot;</span><span class="p">,</span> <span class="n">epoch_mean</span><span class="p">)</span>
        <span class="c1"># free up the memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_epoch_start">
<span class="sig-name descname"><span class="pre">on_train_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_start">
<span class="sig-name descname"><span class="pre">on_train_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_train_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of training after sanity check.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_batch_end">
<span class="sig-name descname"><span class="pre">on_validation_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of validation_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_batch_start">
<span class="sig-name descname"><span class="pre">on_validation_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_end">
<span class="sig-name descname"><span class="pre">on_validation_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_epoch_end">
<span class="sig-name descname"><span class="pre">on_validation_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_epoch_start">
<span class="sig-name descname"><span class="pre">on_validation_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_eval">
<span class="sig-name descname"><span class="pre">on_validation_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_train">
<span class="sig-name descname"><span class="pre">on_validation_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_zero_grad">
<span class="sig-name descname"><span class="pre">on_validation_model_zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_model_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by the training loop to release gradients before entering the validation loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_start">
<span class="sig-name descname"><span class="pre">on_validation_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.on_validation_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizer_step">
<span class="sig-name descname"><span class="pre">optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
the optimizer.</p>
<p>By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code> as shown in the example.
This method (and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code>) won’t be called during the accumulation phase when
<code class="docutils literal notranslate"><span class="pre">Trainer(accumulate_grad_batches</span> <span class="pre">!=</span> <span class="pre">1)</span></code>. Overriding this hook has no benefit with manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – A PyTorch optimizer</p></li>
<li><p><strong>optimizer_closure</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[], <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]]) – The optimizer closure. This closure must be executed as it includes the
calls to <code class="docutils literal notranslate"><span class="pre">training_step()</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>, and <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

<span class="c1"># Learning rate warm-up</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="c1"># update params</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

    <span class="c1"># manually warm up lr without a scheduler</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">&lt;</span> <span class="mi">500</span><span class="p">:</span>
        <span class="n">lr_scale</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">500.0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">pg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_scale</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizer_zero_grad">
<span class="sig-name descname"><span class="pre">optimizer_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizer_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – A PyTorch optimizer</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="c1"># Set gradients to `None` instead of zero to improve performance (not required on `torch&gt;=2.0.0`).</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for the explanation of the above example.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizers">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the optimizer(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_pl_optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will wrap the optimizer(s) in a
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code> for automatic handling of precision,
profiling, and counting of step calls for proper logging and checkpointing. It specifically wraps the
<code class="docutils literal notranslate"><span class="pre">step</span></code> method and custom optimizers that don’t have this method are not supported.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A single optimizer, or a list of optimizers in case multiple ones are present.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.output_chunk_length">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_chunk_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.output_chunk_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of time steps predicted at once by the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>Parameter</em> – module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.pred_batch_size">
<span class="sig-name descname"><span class="pre">pred_batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.pred_batch_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.pred_n">
<span class="sig-name descname"><span class="pre">pred_n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.pred_n" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.pred_n_jobs">
<span class="sig-name descname"><span class="pre">pred_n_jobs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.pred_n_jobs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.pred_num_samples">
<span class="sig-name descname"><span class="pre">pred_num_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.pred_num_samples" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.pred_roll_size">
<span class="sig-name descname"><span class="pre">pred_roll_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.pred_roll_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.predict_dataloader">
<span class="sig-name descname"><span class="pre">predict_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.predict_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying prediction samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code> or a sequence of them specifying prediction samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.predict_likelihood_parameters">
<span class="sig-name descname"><span class="pre">predict_likelihood_parameters</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.predict_likelihood_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.predict_step">
<span class="sig-name descname"><span class="pre">predict_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.predict_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the prediction step</p>
<dl class="simple">
<dt>batch</dt><dd><p>output of Darts’ <code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceDataset</span></code> - tuple of <code class="docutils literal notranslate"><span class="pre">(past_target,</span> <span class="pre">past_covariates,</span>
<span class="pre">historic_future_covariates,</span> <span class="pre">future_covariates,</span> <span class="pre">future_past_covariates,</span> <span class="pre">input_timeseries)</span></code></p>
</dd>
<dt>batch_idx</dt><dd><p>the batch index of the current batch</p>
</dd>
<dt>dataloader_idx</dt><dd><p>the dataloader index</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data">
<span class="sig-name descname"><span class="pre">prepare_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Use this to download and prepare data. Downloading and saving data with multiple processes (distributed
settings) will result in corrupted data. Lightning ensures this method is called only within a single process,
so you can safely add your downloading logic within.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>DO NOT set state to the model (use <code class="docutils literal notranslate"><span class="pre">setup</span></code> instead)
since this is NOT called on every device</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># good</span>
    <span class="n">download_data</span><span class="p">()</span>
    <span class="n">tokenize</span><span class="p">()</span>
    <span class="n">etc</span><span class="p">()</span>

    <span class="c1"># bad</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">data_split</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">some_state</span> <span class="o">=</span> <span class="n">some_other_state</span><span class="p">()</span>
</pre></div>
</div>
<p>In a distributed environment, <code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> can be called in two ways
(using <span class="xref std std-ref">prepare_data_per_node</span>)</p>
<ol class="arabic simple">
<li><p>Once per node. This is the default and is only called on LOCAL_RANK=0.</p></li>
<li><p>Once in total. Only called on GLOBAL_RANK=0.</p></li>
</ol>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="c1"># called once per node on LOCAL_RANK=0 of that node</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># call on GLOBAL_RANK=0 (great for shared file systems)</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>This is called before requesting the dataloaders:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">initialize_distributed</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_dataloader</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data_per_node" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.print">
<span class="sig-name descname"><span class="pre">print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.print" title="Permalink to this definition">¶</a></dt>
<dd><p>Prints only from process 0. Use this in any distributed mode to log only once.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – The thing to print. The same as for Python’s built-in print function.</p></li>
<li><p><strong>**kwargs</strong> – The same as for Python’s built-in print function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;in forward&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>This function is deprecated in favor of <code class="xref py py-meth docutils literal notranslate"><span class="pre">register_full_backward_hook()</span></code> and
the behavior of this function will change in future versions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the module’s state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">persistent</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the buffer. The buffer can be accessed
from this module using the given name</p></li>
<li><p><strong>tensor</strong> (<em>Tensor</em><em> or </em><em>None</em>) – buffer to be registered. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations
that run on buffers, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>, are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
the buffer is <strong>not</strong> included in the module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>) – whether the buffer is part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">always_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_forward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
output. It can modify the input inplace but it will not have effect on
forward since this is called after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called. The hook
should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the forward hook will be passed the
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> given to the forward function and be expected to return the
output possibly modified. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired
before all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_hook()</span></code> will fire before all hooks
registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the
kwargs given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>always_call</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be run regardless of
whether an exception is raised while calling the Module.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_forward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is false or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
input. User can either return a tuple or a single modified value in the
hook. We will wrap the value into a tuple if a single value is returned
(unless that value is already a tuple). The hook should have the
following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is true, the forward pre-hook will be passed the
kwargs given to the forward function. And if the hook modifies the
input, both the args and kwargs should be returned. The hook should have
the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">a</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">modified</span> <span class="nb">input</span> <span class="ow">and</span> <span class="n">kwargs</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_pre_hook()</span></code> will fire before all
hooks registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If true, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the kwargs
given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_full_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to a module
are computed, i.e. the hook will execute if and only if the gradients with
respect to module outputs are computed. The hook should have the following
signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in
subsequent computations. <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for all non-Tensor
arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_full_backward_pre_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_full_backward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward pre-hook on the module.</p>
<p>The hook will be called every time the gradients for the module are computed.
The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> is a tuple. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the output that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> in
subsequent computations. Entries in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for
all non-Tensor arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_pre_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_load_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_load_state_dict_post_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a post hook to be run after module’s <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code>
is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, incompatible_keys) -&gt; None</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">module</span></code> argument is the current module that this hook is registered
on, and the <code class="docutils literal notranslate"><span class="pre">incompatible_keys</span></code> argument is a <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> consisting
of attributes <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>. <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code>
is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the missing keys and
<code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the unexpected keys.</p>
<p>The given incompatible_keys can be modified inplace if needed.</p>
<p>Note that the checks performed when calling <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">strict=True</span></code> are affected by modifications the hook makes to
<code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> or <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>, as expected. Additions to either
set of keys will result in an error being thrown when <code class="docutils literal notranslate"><span class="pre">strict=True</span></code>, and
clearing out both missing and unexpected keys will avoid an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_module">
<span class="sig-name descname"><span class="pre">register_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_parameter">
<span class="sig-name descname"><span class="pre">register_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the parameter. The parameter can be accessed
from this module using the given name</p></li>
<li><p><strong>param</strong> (<em>Parameter</em><em> or </em><em>None</em>) – parameter to be added to the module. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations that run on parameters, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>,
are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the parameter is <strong>not</strong> included in the
module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.register_state_dict_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>,
and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>. The registered
hooks can be used to perform pre-processing before the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>
call is made.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.requires_grad_" title="Permalink to this definition">¶</a></dt>
<dd><p>Change if autograd should record operations on parameters in this
module.</p>
<p>This method sets the parameters’ <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.requires_grad_()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<em>bool</em>) – whether autograd should record operations on
parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters">
<span class="sig-name descname"><span class="pre">save_hyperparameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.save_hyperparameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – single object of <cite>dict</cite>, <cite>NameSpace</cite> or <cite>OmegaConf</cite>
or string names or arguments from class <code class="docutils literal notranslate"><span class="pre">__init__</span></code></p></li>
<li><p><strong>ignore</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – an argument name or a list of argument names from
class <code class="docutils literal notranslate"><span class="pre">__init__</span></code> to be ignored</p></li>
<li><p><strong>frame</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">frame</span></code>]) – a frame object. Default is None</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to send the hyperparameters to the logger. Default: True</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Example::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign arguments</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="s1">&#39;arg1&#39;</span><span class="p">,</span> <span class="s1">&#39;arg3&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AutomaticArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># equivalent automatic</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutomaticArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg2&quot;: abc</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">SingleArgModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign single argument</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleArgModel</span><span class="p">(</span><span class="n">Namespace</span><span class="p">(</span><span class="n">p1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p2</span><span class="o">=</span><span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="n">p3</span><span class="o">=</span><span class="mf">3.14</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;p1&quot;: 1</span>
<span class="go">&quot;p2&quot;: abc</span>
<span class="go">&quot;p3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># pass argument(s) to ignore as a string or in a list</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="s1">&#39;arg2&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state
found within the <cite>state_dict</cite>. Implement this function and a corresponding
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.get_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_extra_state()</span></code></a> for your module if you need to store extra state within its
<cite>state_dict</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>dict</em>) – Extra state from the <cite>state_dict</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_mc_dropout">
<span class="sig-name descname"><span class="pre">set_mc_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">active</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_mc_dropout" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_predict_parameters">
<span class="sig-name descname"><span class="pre">set_predict_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roll_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.set_predict_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you
need to build models dynamically or adjust something about them. This hook is called on every process when
using DDP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">download_data</span><span class="p">()</span>
        <span class="n">tokenize</span><span class="p">()</span>

        <span class="c1"># don&#39;t do this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">something</span> <span class="o">=</span> <span class="k">else</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.share_memory">
<span class="sig-name descname"><span class="pre">share_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.share_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>~T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary containing references to the whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to <code class="docutils literal notranslate"><span class="pre">None</span></code> are not included.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned object is a shallow copy. It contains references
to the module’s parameters and buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> also accepts positional arguments for
<code class="docutils literal notranslate"><span class="pre">destination</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> in order. However,
this is being deprecated and keyword arguments will be enforced in
future releases.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please avoid the use of argument <code class="docutils literal notranslate"><span class="pre">destination</span></code> as it is not
designed for end-users.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>destination</strong> (<em>dict</em><em>, </em><em>optional</em>) – If provided, the state of module will
be updated into the dict and the same object is returned.
Otherwise, an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> will be created and returned.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em>) – a prefix added to parameter and buffer
names to compose the keys in state_dict. Default: <code class="docutils literal notranslate"><span class="pre">''</span></code>.</p></li>
<li><p><strong>keep_vars</strong> (<em>bool</em><em>, </em><em>optional</em>) – by default the <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> s
returned in the state dict are detached from autograd. If it’s
set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, detaching will not be performed.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary containing a whole state of the module</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.teardown">
<span class="sig-name descname"><span class="pre">teardown</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.teardown" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of fit (train + validate), validate, test, or predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_dataloader">
<span class="sig-name descname"><span class="pre">test_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying test samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">test()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a test dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a>, you don’t need to implement
this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the test set. In this step you’d normally generate examples or
calculate anything of interest such as accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your data iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><strong>batch_idx</strong> – The index of this batch.</p></li>
<li><p><strong>dataloader_idx</strong> – The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Skip to the next batch.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one test dataloader:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="o">...</span>

<span class="c1"># if you have multiple test dataloaders:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single test dataset</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple test dataloaders, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple test dataloaders</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="o">...</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need to test you don’t need to implement this method.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> is called, the model has been put in eval mode and
PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
to training mode and gradients are enabled.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_dtype">
<span class="sig-name descname"><span class="pre">to_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Cast module precision (float32 by default) to another precision.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_empty" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves the parameters and buffers to the specified device without copying storage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>) – The desired device of the parameters
and buffers in this module.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – Whether parameters and buffers of submodules should
be recursively moved to the specified device.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_onnx">
<span class="sig-name descname"><span class="pre">to_onnx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_onnx" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the model in ONNX format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>]) – The path of the file the onnx model should be saved to.</p></li>
<li><p><strong>input_sample</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input for tracing. Default: None (Use self.example_input_array)</p></li>
<li><p><strong>**kwargs</strong> – Will be passed to torch.onnx.export function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">input_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">(</span><span class="s2">&quot;export.onnx&quot;</span><span class="p">,</span> <span class="n">input_sample</span><span class="p">,</span> <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_torchscript">
<span class="sig-name descname"><span class="pre">to_torchscript</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'script'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.to_torchscript" title="Permalink to this definition">¶</a></dt>
<dd><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>. If you want to use tracing,
please provided the argument <code class="docutils literal notranslate"><span class="pre">method='trace'</span></code> and make sure that either the <cite>example_inputs</cite> argument is
provided, or the model has <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a> set. If you would like to customize the modules that are
scripted you should override this method. In case you want to return multiple modules, we recommend using a
dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Path where to save the torchscript. Default: None (no file saved).</p></li>
<li><p><strong>method</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Whether to use TorchScript’s script or trace method. Default: ‘script’</p></li>
<li><p><strong>example_inputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input to be used to do tracing when method is set to ‘trace’.
Default: None (uses <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments that will be passed to the <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.script()</span></code> or
<code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.trace()</span></code> function.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Requires the implementation of the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> method.</p></li>
<li><p>The exported script will be set to evaluation mode.</p></li>
<li><p>It is recommended that you install the latest supported version of PyTorch
to use this feature without limitations. See also the <code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.jit</span></code>
documentation for supported features.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span>
    <span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model_trace.pt&quot;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;trace&#39;</span><span class="p">,</span> <span class="n">example_inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>]]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>This LightningModule as a torchscript, regardless of whether <cite>file_path</cite> is
defined or not.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.toggle_optimizer">
<span class="sig-name descname"><span class="pre">toggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.toggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Makes sure only the gradients of the current optimizer’s parameters are calculated in the training step to
prevent dangling gradients in multiple-optimizer setup.</p>
<p>It works with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.untoggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">untoggle_optimizer()</span></code></a> to make sure <code class="docutils literal notranslate"><span class="pre">param_requires_grad_state</span></code> is properly reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to toggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.train_dataloader">
<span class="sig-name descname"><span class="pre">train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.train_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying training samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id32"><span class="problematic" id="id33">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.trainer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">trainer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.trainer.trainer.Trainer</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.trainer" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the training step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.transfer_batch_to_device">
<span class="sig-name descname"><span class="pre">transfer_batch_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.transfer_batch_to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data
structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code> or anything that implements <cite>.to(…)</cite></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, …).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook should only transfer the data and not modify it, nor should it move the data to
any other device than the one passed in as argument (unless you know what you are doing).
To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be transferred to a new device.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>) – The target device as defined in PyTorch.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A reference to the data on the new device.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">CustomBatch</span><span class="p">):</span>
        <span class="c1"># move all tensors in your custom data structure to the device</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># skip device transfer for the first dataloader or anything you wish</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transfer_batch_to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">move_data_to_device()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_to_collection()</span></code></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.type">
<span class="sig-name descname"><span class="pre">type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.type" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.unfreeze">
<span class="sig-name descname"><span class="pre">unfreeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze all parameters for training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.untoggle_optimizer">
<span class="sig-name descname"><span class="pre">untoggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.untoggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to untoggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.val_dataloader">
<span class="sig-name descname"><span class="pre">val_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.val_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying validation samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id34"><span class="problematic" id="id35">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">validate()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a validation dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a>, you don’t need to
implement this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the validation step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.xpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the XPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLPastCovariatesModule.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets gradients of all model parameters. See similar function
under <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code> for more context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>set_to_none</strong> (<em>bool</em>) – instead of setting to zero, set the grads to None.
See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for details.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">darts.models.forecasting.pl_forecasting_module.</span></span><span class="sig-name descname"><span class="pre">PLSplitCovariatesModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_sample_shape=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn=MSELoss()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_metrics=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_cls=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_cls=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_reversible_instance_norm=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#PLSplitCovariatesModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLForecastingModule" title="darts.models.forecasting.pl_forecasting_module.PLForecastingModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">darts.models.forecasting.pl_forecasting_module.PLForecastingModule</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>PyTorch Lightning-based Forecasting Module.</p>
<p>This class is meant to be inherited to create a new PyTorch Lightning-based forecasting module.
When subclassing this class, please make sure to add the following methods with the given signatures:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.__init__()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel.forward()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._produce_train_output()</span></code></p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">PLTorchForecastingModel._get_batch_prediction()</span></code></p></li>
</ul>
</div></blockquote>
<p>In subclass <cite>MyModel</cite>’s <code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code> function call <code class="docutils literal notranslate"><span class="pre">super(MyModel,</span> <span class="pre">self).__init__(**kwargs)</span></code> where
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> are the parameters of <code class="xref py py-class docutils literal notranslate"><span class="pre">PLTorchForecastingModel</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps in the past to take as a model input (per chunk). Applies to the target
series, and past and/or future covariates (if the model supports it).</p></li>
<li><p><strong>output_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps predicted at once (per chunk) by the internal model. Also, the number of future values
from future covariates to use as a model input (if the model supports future covariates). It is not the same
as forecast horizon <cite>n</cite> used in <cite>predict()</cite>, which is the desired number of prediction points generated
using either a one-shot- or auto-regressive forecast. Setting <cite>n &lt;= output_chunk_length</cite> prevents
auto-regression. This is useful when the covariates don’t extend far enough into the future, or to prohibit
the model from using future values of past and / or future covariates for prediction (depending on the
model’s covariate support).</p></li>
<li><p><strong>train_sample_shape</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Shape of the model’s input, used to instantiate model without calling <code class="docutils literal notranslate"><span class="pre">fit_from_dataset</span></code> and
perform sanity check on new training/inference datasets used for re-training or prediction.</p></li>
<li><p><strong>loss_fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code>) – PyTorch loss function used for training.
This parameter will be ignored for probabilistic models if the <code class="docutils literal notranslate"><span class="pre">likelihood</span></code> parameter is specified.
Default: <code class="docutils literal notranslate"><span class="pre">torch.nn.MSELoss()</span></code>.</p></li>
<li><p><strong>torch_metrics</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – A torch metric or a <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code> used for evaluation. A full list of available metrics can be found
at <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/">https://torchmetrics.readthedocs.io/en/latest/</a>. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>likelihood</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code></a>]) – One of Darts’ <a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Likelihood</span></code></a> models to be used for
probabilistic forecasts. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>optimizer_cls</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The PyTorch optimizer class to be used. Default: <code class="docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code>.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch optimizer (e.g., <code class="docutils literal notranslate"><span class="pre">{'lr':</span> <span class="pre">1e-3}</span></code>
for specifying a learning rate). Otherwise the default values of the selected <code class="docutils literal notranslate"><span class="pre">optimizer_cls</span></code>
will be used. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_cls</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_LRScheduler</span></code>]) – Optionally, the PyTorch learning rate scheduler class to be used. Specifying <code class="docutils literal notranslate"><span class="pre">None</span></code> corresponds
to using a constant learning rate. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]) – Optionally, some keyword arguments for the PyTorch learning rate scheduler. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>use_reversible_instance_norm</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to use reversible instance normalization <cite>RINorm</cite> against distribution shift as shown in <a class="reference internal" href="#r581ea62de027-1" id="id36">[1]</a>.
It is only applied to the features of the target series and not the covariates.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r581ea62de027-1"><span class="brackets"><a class="fn-backref" href="#id36">1</a></span></dt>
<dd><p>T. Kim et al. “Reversible Instance Normalization for Accurate Time-Series Forecasting against
Distribution Shift”, <a class="reference external" href="https://openreview.net/forum?id=cGDAkQo1C0p">https://openreview.net/forum?id=cGDAkQo1C0p</a></p>
</dd>
</dl>
<p class="rubric">Attributes</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.automatic_optimization" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.automatic_optimization"><code class="xref py py-obj docutils literal notranslate"><span class="pre">automatic_optimization</span></code></a></p></td>
<td><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.current_epoch" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.current_epoch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">current_epoch</span></code></a></p></td>
<td><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.example_input_array"><code class="xref py py-obj docutils literal notranslate"><span class="pre">example_input_array</span></code></a></p></td>
<td><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.global_rank" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.global_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_rank</span></code></a></p></td>
<td><p>The index of the current process across all nodes and devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.global_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.global_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_step</span></code></a></p></td>
<td><p>Total training batches seen across all epochs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams_initial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hparams_initial</span></code></a></p></td>
<td><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.local_rank" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.local_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">local_rank</span></code></a></p></td>
<td><p>The index of the current process within a single node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.logger" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.logger"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logger</span></code></a></p></td>
<td><p>Reference to the logger object in the Trainer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.loggers" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.loggers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">loggers</span></code></a></p></td>
<td><p>Reference to the list of loggers in the Trainer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_gpu" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_gpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_gpu</span></code></a></p></td>
<td><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.output_chunk_length" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.output_chunk_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_chunk_length</span></code></a></p></td>
<td><p>Number of time steps predicted at once by the model.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>device</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>dtype</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>epochs_trained</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>fabric</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>trainer</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.add_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_module</span></code></a>(name, module)</p></td>
<td><p>Adds a child module to the current module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.all_gather" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.all_gather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">all_gather</span></code></a>(data[, group, sync_grads])</p></td>
<td><p>Gather tensors or collections of tensors from multiple processes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.apply" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.backward" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.bfloat16" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.bfloat16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfloat16</span></code></a>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.buffers" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">buffers</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.children" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.clip_gradients" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.clip_gradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip_gradients</span></code></a>(optimizer[, ...])</p></td>
<td><p>Handles gradient clipping internally.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.compile" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(*args, **kwargs)</p></td>
<td><p>Compile this Module's forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_callbacks" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_callbacks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_callbacks</span></code></a>()</p></td>
<td><p>Configure model-specific callbacks.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_gradient_clipping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_gradient_clipping</span></code></a>(optimizer[, ...])</p></td>
<td><p>Perform gradient clipping for the optimizer parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_model" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_model</span></code></a>()</p></td>
<td><p>Hook to create modules in a strategy and precision aware context.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_optimizers" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_optimizers</span></code></a>()</p></td>
<td><p>configures optimizers and learning rate schedulers for model optimization.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_sharded_model" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_sharded_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_sharded_model</span></code></a>()</p></td>
<td><p>Deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_torch_metrics" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_torch_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">configure_torch_metrics</span></code></a>(torch_metrics)</p></td>
<td><p>process the torch_metrics parameter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cpu" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cuda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the GPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.double" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.double"><code class="xref py py-obj docutils literal notranslate"><span class="pre">double</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.eval" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code></a>()</p></td>
<td><p>Sets the module in evaluation mode.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.extra_repr" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.extra_repr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extra_repr</span></code></a>()</p></td>
<td><p>Set the extra representation of the module</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(*args, **kwargs)</p></td>
<td><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.freeze" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.freeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">freeze</span></code></a>()</p></td>
<td><p>Freeze all params for inference.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_buffer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_buffer</span></code></a>(target)</p></td>
<td><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_extra_state</span></code></a>()</p></td>
<td><p>Returns any extra state to include in the module's state_dict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_parameter" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_parameter</span></code></a>(target)</p></td>
<td><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_submodule" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_submodule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_submodule</span></code></a>(target)</p></td>
<td><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.half" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.half"><code class="xref py py-obj docutils literal notranslate"><span class="pre">half</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.ipu" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.ipu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ipu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the IPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_from_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_from_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code></a>([map_location, ...])</p></td>
<td><p>Primary way of loading a model from a checkpoint.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>(state_dict[, strict, assign])</p></td>
<td><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.log" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log</span></code></a>(name, value[, prog_bar, logger, ...])</p></td>
<td><p>Log a key, value pair.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.log_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.log_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_dict</span></code></a>(dictionary[, prog_bar, logger, ...])</p></td>
<td><p>Log a dictionary of values at once.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.lr_scheduler_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.lr_scheduler_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_scheduler_step</span></code></a>(scheduler, metric)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls each scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.lr_schedulers" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.lr_schedulers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_schedulers</span></code></a>()</p></td>
<td><p>Returns the learning rate scheduler(s) that are being used during training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.manual_backward" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.manual_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">manual_backward</span></code></a>(loss, *args, **kwargs)</p></td>
<td><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.modules" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">modules</span></code></a>()</p></td>
<td><p>Returns an iterator over all modules in the network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_buffers" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_buffers</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_children" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_children</span></code></a>()</p></td>
<td><p>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_modules" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_modules</span></code></a>([memo, prefix, remove_duplicate])</p></td>
<td><p>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_parameters" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_after_backward" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_after_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_backward</span></code></a>()</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_after_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_after_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_backward" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_backward</span></code></a>(loss)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_batch_transfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_batch_transfer</span></code></a>(batch, dataloader_idx)</p></td>
<td><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code></a>(optimizer)</p></td>
<td><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_before_zero_grad</span></code></a>(optimizer)</p></td>
<td><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_fit_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_fit_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_end</span></code></a>()</p></td>
<td><p>Called at the very end of fit.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_fit_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_fit_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_fit_start</span></code></a>()</p></td>
<td><p>Called at the very beginning of fit.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_load_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_load_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_load_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning to restore your model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the predict loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the predict loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_end</span></code></a>()</p></td>
<td><p>Called at the end of predicting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_epoch_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the predict loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_predict_start</span></code></a>()</p></td>
<td><p>Called at the beginning of predicting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_save_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_save_checkpoint</span></code></a>(checkpoint)</p></td>
<td><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to save.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the test loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_batch_start</span></code></a>(batch, batch_idx[, ...])</p></td>
<td><p>Called in the test loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_end</span></code></a>()</p></td>
<td><p>Called at the end of testing.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_end</span></code></a>()</p></td>
<td><p>Called in the test loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_epoch_start</span></code></a>()</p></td>
<td><p>Called in the test loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the test loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_model_train" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the test loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_test_start</span></code></a>()</p></td>
<td><p>Called at the beginning of testing.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_end</span></code></a>(outputs, batch, batch_idx)</p></td>
<td><p>Called in the training loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the training loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_end</span></code></a>()</p></td>
<td><p>Called at the end of training before logger experiment is closed.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_end</span></code></a>()</p></td>
<td><p>Called in the training loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_epoch_start</span></code></a>()</p></td>
<td><p>Called in the training loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_start</span></code></a>()</p></td>
<td><p>Called at the beginning of training after sanity check.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_batch_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_batch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_end</span></code></a>(outputs, batch, ...)</p></td>
<td><p>Called in the validation loop after the batch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_batch_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_batch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_batch_start</span></code></a>(batch, batch_idx)</p></td>
<td><p>Called in the validation loop before anything happens for that batch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_end</span></code></a>()</p></td>
<td><p>Called at the end of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_epoch_end" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_epoch_end"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_end</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very end of the epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_epoch_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_epoch_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_epoch_start</span></code></a>()</p></td>
<td><p>Called in the validation loop at the very beginning of the epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_eval" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_eval</span></code></a>()</p></td>
<td><p>Sets the model to eval during the val loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_train" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_train</span></code></a>()</p></td>
<td><p>Sets the model to train during the val loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_model_zero_grad</span></code></a>()</p></td>
<td><p>Called by the training loop to release gradients before entering the validation loop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_start" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_validation_start</span></code></a>()</p></td>
<td><p>Called at the beginning of validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizer_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_step</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls the optimizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizer_zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizer_zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer_zero_grad</span></code></a>(epoch, batch_idx, optimizer)</p></td>
<td><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizers" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizers</span></code></a>([use_pl_optimizer])</p></td>
<td><p>Returns the optimizer(s) that are being used during training.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.parameters" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a>([recurse])</p></td>
<td><p>Returns an iterator over module parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.predict_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.predict_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying prediction samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.predict_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.predict_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_step</span></code></a>(batch, batch_idx[, dataloader_idx])</p></td>
<td><p>performs the prediction step</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare_data</span></code></a>()</p></td>
<td><p>Use this to download and prepare data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.print" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.print"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print</span></code></a>(*args, **kwargs)</p></td>
<td><p>Prints only from process 0.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_backward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_buffer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_buffer</span></code></a>(name, tensor[, persistent])</p></td>
<td><p>Adds a buffer to the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_forward_hook" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook, *[, prepend, ...])</p></td>
<td><p>Registers a forward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_forward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook, *[, ...])</p></td>
<td><p>Registers a forward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_full_backward_hook" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_full_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_full_backward_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_full_backward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_pre_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Registers a backward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_load_state_dict_post_hook" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_load_state_dict_post_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_load_state_dict_post_hook</span></code></a>(hook)</p></td>
<td><p>Registers a post hook to be run after module's <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> is called.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_module" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_module</span></code></a>(name, module)</p></td>
<td><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_parameter" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_parameter</span></code></a>(name, param)</p></td>
<td><p>Adds a parameter to the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_state_dict_pre_hook" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_state_dict_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_state_dict_pre_hook</span></code></a>(hook)</p></td>
<td><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>, and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.requires_grad_" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.requires_grad_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad_</span></code></a>([requires_grad])</p></td>
<td><p>Change if autograd should record operations on parameters in this module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_hyperparameters</span></code></a>(*args[, ignore, frame, ...])</p></td>
<td><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_extra_state</span></code></a>(state)</p></td>
<td><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state found within the <cite>state_dict</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_predict_parameters" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_predict_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_predict_parameters</span></code></a>(n, num_samples, ...)</p></td>
<td><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>(stage)</p></td>
<td><p>Called at the beginning of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.share_memory" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.share_memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_memory</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code></a>(*args[, destination, prefix, ...])</p></td>
<td><p>Returns a dictionary containing references to the whole state of the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.teardown" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.teardown"><code class="xref py py-obj docutils literal notranslate"><span class="pre">teardown</span></code></a>(stage)</p></td>
<td><p>Called at the end of fit (train + validate), validate, test, or predict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying test samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_step</span></code></a>(*args, **kwargs)</p></td>
<td><p>Operates on a single batch of data from the test set.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_dtype" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_dtype</span></code></a>(dtype)</p></td>
<td><p>Cast module precision (float32 by default) to another precision.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_empty" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_empty</span></code></a>(*, device[, recurse])</p></td>
<td><p>Moves the parameters and buffers to the specified device without copying storage.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_onnx" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_onnx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_onnx</span></code></a>(file_path[, input_sample])</p></td>
<td><p>Saves the model in ONNX format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_torchscript" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_torchscript"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_torchscript</span></code></a>([file_path, method, ...])</p></td>
<td><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.toggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">toggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Makes sure only the gradients of the current optimizer's parameters are calculated in the training step to prevent dangling gradients in multiple-optimizer setup.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.train" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>([mode])</p></td>
<td><p>Sets the module in training mode.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.train_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.train_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying training samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">training_step</span></code></a>(train_batch, batch_idx)</p></td>
<td><p>performs the training step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.transfer_batch_to_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transfer_batch_to_device</span></code></a>(batch, device, ...)</p></td>
<td><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data structure.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.type" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code></a>(dst_type)</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.unfreeze" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.unfreeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unfreeze</span></code></a>()</p></td>
<td><p>Unfreeze all parameters for training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.untoggle_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">untoggle_optimizer</span></code></a>(optimizer)</p></td>
<td><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.val_dataloader" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.val_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">val_dataloader</span></code></a>()</p></td>
<td><p>An iterable or collection of iterables specifying validation samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.validation_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">validation_step</span></code></a>(val_batch, batch_idx)</p></td>
<td><p>performs the validation step</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.xpu" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.xpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xpu</span></code></a>([device])</p></td>
<td><p>Moves all model parameters and buffers to the XPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.zero_grad" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>([set_to_none])</p></td>
<td><p>Resets gradients of all model parameters.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>__call__</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_mc_dropout</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.CHECKPOINT_HYPER_PARAMS_KEY">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_KEY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hyper_parameters'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.CHECKPOINT_HYPER_PARAMS_KEY" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.CHECKPOINT_HYPER_PARAMS_NAME">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_name'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.CHECKPOINT_HYPER_PARAMS_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.CHECKPOINT_HYPER_PARAMS_TYPE">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_TYPE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_type'</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.CHECKPOINT_HYPER_PARAMS_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.T_destination">
<span class="sig-name descname"><span class="pre">T_destination</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.T_destination" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of TypeVar(‘T_destination’, bound=<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>])</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.add_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the child module. The child module can be
accessed from this module using the given name</p></li>
<li><p><strong>module</strong> (<em>Module</em>) – child module to be added to the module.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.all_gather">
<span class="sig-name descname"><span class="pre">all_gather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.all_gather" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather tensors or collections of tensors from multiple processes.</p>
<p>This method needs to be called on all processes and the tensors need to have the same shape across all
processes, otherwise your program will stall forever.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – int, float, tensor of shape (batch, …), or a (possibly nested) collection thereof.</p></li>
<li><p><strong>group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the process group to gather results from. Defaults to all processes (world)</p></li>
<li><p><strong>sync_grads</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – flag that allows users to synchronize gradients for the all_gather operation</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor of shape (world_size, batch, …), or if the input was a collection
the output will also be a collection with tensors of this shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.allow_zero_length_dataloader_with_multiple_devices" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>)
as well as self. Typical use includes initializing the parameters of a model
(see also <span class="xref std std-ref">nn-init-doc</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> -&gt; None) – function to be applied to each submodule</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.automatic_optimization">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">automatic_optimization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.automatic_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called to perform backward on the loss returned in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. Override this hook with your own
implementation if you need to.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The loss tensor returned by <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. If gradient accumulation is used, the loss here
holds the normalized value (scaled by 1 / accumulation steps).</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.bfloat16">
<span class="sig-name descname"><span class="pre">bfloat16</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.bfloat16" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.buffers">
<span class="sig-name descname"><span class="pre">buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – module buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.call_super_init">
<span class="sig-name descname"><span class="pre">call_super_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.call_super_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a child module</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.clip_gradients">
<span class="sig-name descname"><span class="pre">clip_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.clip_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Handles gradient clipping internally.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Do not override this method. If you want to customize gradient clipping, consider using
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_gradient_clipping" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_gradient_clipping"><code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_gradient_clipping()</span></code></a> method.</p></li>
<li><p>For manual optimization (<code class="docutils literal notranslate"><span class="pre">self.automatic_optimization</span> <span class="pre">=</span> <span class="pre">False</span></code>), if you want to use
gradient clipping, consider calling
<code class="docutils literal notranslate"><span class="pre">self.clip_gradients(opt,</span> <span class="pre">gradient_clip_val=0.5,</span> <span class="pre">gradient_clip_algorithm=&quot;norm&quot;)</span></code>
manually in the training step.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. Pass <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;value&quot;</span></code>
to clip by value, and <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;norm&quot;</span></code> to clip by norm.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.compile" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile this Module’s forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>This Module’s <cite>__call__</cite> method is compiled and all arguments are passed as-is
to <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>See <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code> for details on the arguments for this function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_callbacks">
<span class="sig-name descname"><span class="pre">configure_callbacks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_callbacks" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure model-specific callbacks. When the model gets attached, e.g., when <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> or <code class="docutils literal notranslate"><span class="pre">.test()</span></code> gets
called, the list or a callback returned here will be merged with the list of callbacks passed to the Trainer’s
<code class="docutils literal notranslate"><span class="pre">callbacks</span></code> argument. If a callback returned here has the same type as one or several callbacks already
present in the Trainer’s callbacks list, it will take priority and replace them. In addition, Lightning will
make sure <code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> callbacks run last.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A callback or a list of callbacks which will extend the list of callbacks in the Trainer.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">early_stop</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_gradient_clipping">
<span class="sig-name descname"><span class="pre">configure_gradient_clipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_gradient_clipping" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform gradient clipping for the optimizer parameters. Called before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizer_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizer_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The value at which to clip gradients. By default, value passed in Trainer
will be available here.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The gradient clipping algorithm to use. By default, value
passed in Trainer will be available here.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_gradient_clipping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="p">,</span> <span class="n">gradient_clip_algorithm</span><span class="p">):</span>
    <span class="c1"># Implement your own custom logic to clip gradients</span>
    <span class="c1"># You can call `self.clip_gradients` with your settings:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="o">=</span><span class="n">gradient_clip_val</span><span class="p">,</span>
        <span class="n">gradient_clip_algorithm</span><span class="o">=</span><span class="n">gradient_clip_algorithm</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_model">
<span class="sig-name descname"><span class="pre">configure_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook to create modules in a strategy and precision aware context.</p>
<p>This is particularly useful for when using sharded strategies (FSDP and DeepSpeed), where we’d like to shard
the model instantly to save memory and initialization time.
For non-sharded strategies, you can choose to override this hook or to initialize your model under the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">init_module()</span></code> context manager.</p>
<p>This hook is called during each of fit/val/test/predict stages in the same process, so ensure that
implementation of this hook is idempotent.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>configures optimizers and learning rate schedulers for model optimization.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_sharded_model">
<span class="sig-name descname"><span class="pre">configure_sharded_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_sharded_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Deprecated.</p>
<p>Use <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_model()</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_torch_metrics">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">configure_torch_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">torch_metrics</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.configure_torch_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>process the torch_metrics parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cuda" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the GPU. This also makes associated parameters and buffers
different objects. So it should be called before constructing optimizer if the module will live on GPU while
being optimized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If specified, all parameters will be copied to that device. If <cite>None</cite>, the current CUDA device
index will be used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.current_epoch">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">current_epoch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.current_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.device</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.device" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.double" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.dtype</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.dtype" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dtype</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.dump_patches">
<span class="sig-name descname"><span class="pre">dump_patches</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.dump_patches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.epochs_trained">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">epochs_trained</span></span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.epochs_trained" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code>.</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.eval()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.example_input_array">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">example_input_array</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.example_input_array" title="Permalink to this definition">¶</a></dt>
<dd><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method. The
return type is interpreted as follows:</p>
<ul class="simple">
<li><p>Single tensor: It is assumed the model takes a single argument, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(model.example_input_array)</span></code></p></li>
<li><p>Tuple: The input array should be interpreted as a sequence of positional arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(*model.example_input_array)</span></code></p></li>
<li><p>Dict: The input array represents named keyword arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(**model.example_input_array)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.fabric">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fabric</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.fabric.Fabric</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.fabric" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fabric</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Whatever you decide to pass into the forward method.</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments are also possible.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Your model’s output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.freeze">
<span class="sig-name descname"><span class="pre">freeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze all params for inference.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the buffer
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The buffer referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not a
buffer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns any extra state to include in the module’s state_dict.
Implement this and a corresponding <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_extra_state()</span></code></a> for your module
if you need to store extra state. This function is called when building the
module’s <cite>state_dict()</cite>.</p>
<p>Note that extra state should be picklable to ensure working serialization
of the state_dict. We only provide provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Any extra state to store in the module’s state_dict</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_parameter">
<span class="sig-name descname"><span class="pre">get_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the Parameter
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Parameter referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To check whether or not we have the <code class="docutils literal notranslate"><span class="pre">linear</span></code> submodule, we
would call <code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.linear&quot;)</span></code>. To check whether
we have the <code class="docutils literal notranslate"><span class="pre">conv</span></code> submodule, we would call
<code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.net_c.conv&quot;)</span></code>.</p>
<p>The runtime of <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> is bounded by the degree
of module nesting in <code class="docutils literal notranslate"><span class="pre">target</span></code>. A query against
<code class="docutils literal notranslate"><span class="pre">named_modules</span></code> achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists, <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> should always be
used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The submodule referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.global_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.global_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process across all nodes and devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.global_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.global_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Total training batches seen across all epochs.</p>
<p>If no Trainer is attached, this propery is 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.half" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">MutableMapping</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. It is mutable by the user. For
the frozen set of initial hyperparameters, use <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams_initial" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams_initial"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams_initial</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">AttributeDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MutableMapping</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mutable hyperparameters dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams_initial">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams_initial</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.utilities.parsing.AttributeDict</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams_initial" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. These contents are read-only.
Manual updates to the saved hyperparameters can instead be performed through <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.hparams"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>immutable initial hyperparameters</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>AttributeDict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.ipu">
<span class="sig-name descname"><span class="pre">ipu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.ipu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the IPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on IPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_from_checkpoint">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_from_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments
passed to <code class="docutils literal notranslate"><span class="pre">__init__</span></code>  in the checkpoint under <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<p>Any arguments specified through **kwargs will override args stored in <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">IO</span></code>]) – Path to checkpoint. This can also be a URL, or file-like object</p></li>
<li><p><strong>map_location</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – If your checkpoint saved a GPU model and you now load on CPUs
or a different number of GPUs, use this to map to the new setup.
The behaviour is the same as in <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code>.</p></li>
<li><p><strong>hparams_file</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optional path to a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> or <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file with hierarchical structure
as in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">drop_prob</span><span class="p">:</span> <span class="mf">0.2</span>
<span class="n">dataloader</span><span class="p">:</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="mi">32</span>
</pre></div>
</div>
<p>You most likely won’t need this since Lightning will always save the hyperparameters
to the checkpoint.
However, if your checkpoint weights don’t have the hyperparameters saved,
use this method to pass in a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file with the hparams you’d like to use.
These will be converted into a <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> and passed into your
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> for use.</p>
<p>If your model’s <code class="docutils literal notranslate"><span class="pre">hparams</span></code> argument is <code class="xref py py-class docutils literal notranslate"><span class="pre">Namespace</span></code>
and <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file has hierarchical structure, you need to refactor your model to treat
<code class="docutils literal notranslate"><span class="pre">hparams</span></code> as <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>.</p>
</p></li>
<li><p><strong>strict</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to strictly enforce that the keys in <code class="xref py py-attr docutils literal notranslate"><span class="pre">checkpoint_path</span></code> match the keys
returned by this module’s state dict.</p></li>
<li><p><strong>**kwargs</strong> – Any extra keyword args needed to init the model. Can also be used to override saved
hyperparameter values.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance with loaded weights and hyperparameters (if available).</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code> is a <strong>class</strong> method. You should use your <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code>
<strong>class</strong> to call it instead of the <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance, or a
<code class="docutils literal notranslate"><span class="pre">TypeError</span></code> will be raised.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load weights without mapping ...</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">)</span>

<span class="c1"># or load weights mapping all weights from GPU 1 to GPU 0 ...</span>
<span class="n">map_location</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span>
<span class="p">)</span>

<span class="c1"># or load weights and hyperparameters from separate files.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">hparams_file</span><span class="o">=</span><span class="s1">&#39;/path/to/hparams_file.yaml&#39;</span>
<span class="p">)</span>

<span class="c1"># override some of the params with new values</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="n">PATH</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">pretrained_ckpt_path</span><span class="o">=</span><span class="n">NEW_PATH</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># predict</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">pretrained_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into
this module and its descendants. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> the optimizer must be created after
the call to <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>dict</em>) – a dict containing parameters and
persistent buffers.</p></li>
<li><p><strong>strict</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to strictly enforce that the keys
in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this module’s
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>assign</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to assign items in the state
dictionary to their corresponding keys in the module instead
of copying them inplace into the module’s current parameters and buffers.
When <code class="docutils literal notranslate"><span class="pre">False</span></code>, the properties of the tensors in the current
module are preserved while when <code class="docutils literal notranslate"><span class="pre">True</span></code>, the properties of the
Tensors in the state dict are preserved.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>missing_keys</strong> is a list of str containing the missing keys</p></li>
<li><p><strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a parameter or buffer is registered as <code class="docutils literal notranslate"><span class="pre">None</span></code> and its corresponding key
exists in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> will raise a
<code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code>.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.local_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">local_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.local_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>The index of the current process within a single node.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_attribute</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a key, value pair.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>The default behavior per hook is documented here: <span class="xref std std-ref">extensions/logging:Automatic Logging</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – key to log.</p></li>
<li><p><strong>value</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]) – value to log. Can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, or a <code class="docutils literal notranslate"><span class="pre">Metric</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress bar.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto detach the graph.</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across devices. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the DDP group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple dataloaders). If False, user needs to give unique names for
each dataloader to not mix the values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch_size. This will be directly inferred from the loaded batch,
but for some data structures you might need to explicitly provide it.</p></li>
<li><p><strong>metric_attribute</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – To restore the metric state, Lightning requires the reference of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code> in your model. This is found automatically if it is a model attribute.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.log_dict">
<span class="sig-name descname"><span class="pre">log_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dictionary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.log_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Log a dictionary of values at once.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="s1">&#39;metric_n&#39;</span><span class="p">:</span> <span class="n">metric_n</span><span class="p">}</span>
<span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dictionary</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.float"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">MetricCollection</span></code>]) – key value pairs.
The values can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">Metric</span></code>, or <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress base.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for training_step but not validation/test_step.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for val/test step but not <code class="docutils literal notranslate"><span class="pre">training_step</span></code>.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto-detach the graph</p></li>
<li><p><strong>sync_dist</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across GPUs/TPUs. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the ddp group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple). If <code class="docutils literal notranslate"><span class="pre">False</span></code>, user needs to give unique names for
each dataloader to not mix values.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Current batch size. This will be directly inferred from the loaded batch,
but some data structures might need to explicitly provide it.</p></li>
<li><p><strong>rank_zero_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.logger">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.logger" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the logger object in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.loggers">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">loggers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.loggers" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the list of loggers in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.lr_scheduler_step">
<span class="sig-name descname"><span class="pre">lr_scheduler_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.lr_scheduler_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
each scheduler. By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and as shown in the example for each scheduler based on
its <code class="docutils literal notranslate"><span class="pre">interval</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scheduler</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]) – Learning rate scheduler.</p></li>
<li><p><strong>metric</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Value of the monitor used for schedulers like <code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>

<span class="c1"># Alternative way to update schedulers if it requires an epoch value</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.lr_schedulers">
<span class="sig-name descname"><span class="pre">lr_schedulers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.lr_schedulers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the learning rate scheduler(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A single scheduler, or a list of schedulers in case multiple ones are present, or <code class="docutils literal notranslate"><span class="pre">None</span></code> if no
schedulers were returned in <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_optimizers()</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.manual_backward">
<span class="sig-name descname"><span class="pre">manual_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.manual_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this directly from your <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually. By using this,
Lightning can ensure that all the proper scaling gets applied when using mixed precision.</p>
<p>See <span class="xref std std-ref">manual optimization</span> for more examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># automatically applies scaling, etc...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The tensor on which to compute gradients. Must have a graph attached.</p></li>
<li><p><strong>*args</strong> – Additional positional arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to be forwarded to <code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a module in the network</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all buffer names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module. Defaults to True.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated buffers in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, torch.Tensor)</em> – Tuple containing the name and buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_children">
<span class="sig-name descname"><span class="pre">named_children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>(str, Module)</em> – Tuple containing a name and child module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_modules">
<span class="sig-name descname"><span class="pre">named_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>memo</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Set</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]) – a memo to store the set of modules already added to the result</p></li>
<li><p><strong>prefix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – a prefix that will be added to the name of the module</p></li>
<li><p><strong>remove_duplicate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – whether to remove the duplicated module instances in the result
or not</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Module)</em> – Tuple of name and module</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated
parameters in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Parameter)</em> – Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_after_backward">
<span class="sig-name descname"><span class="pre">on_after_backward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_after_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If using native AMP, the gradients will not be unscaled at this point.
Use the <code class="docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code> if you need the unscaled gradients.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_after_batch_transfer">
<span class="sig-name descname"><span class="pre">on_after_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_after_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gpu_transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_before_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_backward">
<span class="sig-name descname"><span class="pre">on_before_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loss</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Loss divided by number of batches for gradient accumulation and scaled if using AMP.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_batch_transfer">
<span class="sig-name descname"><span class="pre">on_before_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_batch_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_after_batch_transfer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_after_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_after_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.transfer_batch_to_device" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_optimizer_step">
<span class="sig-name descname"><span class="pre">on_before_optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p>
<p>If using gradient accumulation, the hook is called once the gradients have been accumulated.
See: <a href="#id37"><span class="problematic" id="id38">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.accumulate_grad_batches`</span></a>.</p>
<p>If using AMP, the loss will be unscaled before calling this hook.
See these <a class="reference external" href="https://pytorch.org/docs/stable/notes/amp_examples.html#working-with-unscaled-gradients">docs</a>
for more information on the scaling of gradients.</p>
<p>If clipping gradients, the gradients will not have been clipped yet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Current optimizer being used.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="c1"># example to inspect gradient information in tensorboard</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># don&#39;t make the tf file huge</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
                <span class="n">tag</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span>
            <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_zero_grad">
<span class="sig-name descname"><span class="pre">on_before_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_before_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<p>Called in the training loop after taking an optimizer step and before zeroing grads.
Good place to inspect weight information with weights updated.</p>
<p>This is where it is called:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">on_before_zero_grad</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span> <span class="c1"># &lt; ---- called here</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – The optimizer for which grads should be zeroed.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_fit_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very end of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_fit_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the very beginning of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_gpu">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">on_gpu</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_gpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p>
<p>Useful to set flags around the LightningModule for different CPU vs GPU behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_load_checkpoint">
<span class="sig-name descname"><span class="pre">on_load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_load_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning to restore your model. If you saved something with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_save_checkpoint" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_save_checkpoint"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_save_checkpoint()</span></code></a> this is
your chance to restore this.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – Loaded checkpoint</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of the time you don&#39;t need to implement this method</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">something_cool_i_want_to_save</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning auto-restores global step, epoch, and train state including amp scaling.
There is no need for you to restore anything regarding training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_batch_end">
<span class="sig-name descname"><span class="pre">on_predict_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The outputs of predict_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the prediction DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_batch_start">
<span class="sig-name descname"><span class="pre">on_predict_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the predict loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_end">
<span class="sig-name descname"><span class="pre">on_predict_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_epoch_end">
<span class="sig-name descname"><span class="pre">on_predict_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_epoch_start">
<span class="sig-name descname"><span class="pre">on_predict_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_model_eval">
<span class="sig-name descname"><span class="pre">on_predict_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the predict loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_start">
<span class="sig-name descname"><span class="pre">on_predict_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_predict_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_save_checkpoint">
<span class="sig-name descname"><span class="pre">on_save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to
save.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – The full checkpoint dictionary before it gets dumped to a file.
Implementations of this hook can insert additional data into this dictionary.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of use cases you don&#39;t need to implement this method</span>
    <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_cool_pickable_object</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning saves all aspects of training (epoch, global step, etc…)
including amp scaling.
There is no need for you to store anything about training.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_batch_end">
<span class="sig-name descname"><span class="pre">on_test_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of test_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_batch_start">
<span class="sig-name descname"><span class="pre">on_test_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_end">
<span class="sig-name descname"><span class="pre">on_test_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_epoch_end">
<span class="sig-name descname"><span class="pre">on_test_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_epoch_start">
<span class="sig-name descname"><span class="pre">on_test_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the test loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_model_eval">
<span class="sig-name descname"><span class="pre">on_test_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_model_train">
<span class="sig-name descname"><span class="pre">on_test_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the test loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_start">
<span class="sig-name descname"><span class="pre">on_test_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_test_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_batch_end">
<span class="sig-name descname"><span class="pre">on_train_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of training_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_batch_start">
<span class="sig-name descname"><span class="pre">on_train_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop before anything happens for that batch.</p>
<p>If you return -1 here, you will skip training for the rest of the current epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_end">
<span class="sig-name descname"><span class="pre">on_train_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of training before logger experiment is closed.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very end of the epoch.</p>
<p>To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> and access them in this hook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyLightningModule</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># do something with all training_step outputs, for example:</span>
        <span class="n">epoch_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;training_epoch_mean&quot;</span><span class="p">,</span> <span class="n">epoch_mean</span><span class="p">)</span>
        <span class="c1"># free up the memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_epoch_start">
<span class="sig-name descname"><span class="pre">on_train_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_start">
<span class="sig-name descname"><span class="pre">on_train_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_train_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of training after sanity check.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_batch_end">
<span class="sig-name descname"><span class="pre">on_validation_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The outputs of validation_step(x)</p></li>
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_batch_start">
<span class="sig-name descname"><span class="pre">on_validation_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_end">
<span class="sig-name descname"><span class="pre">on_validation_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_epoch_end">
<span class="sig-name descname"><span class="pre">on_validation_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_epoch_start">
<span class="sig-name descname"><span class="pre">on_validation_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_eval">
<span class="sig-name descname"><span class="pre">on_validation_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to eval during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_train">
<span class="sig-name descname"><span class="pre">on_validation_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the model to train during the val loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_zero_grad">
<span class="sig-name descname"><span class="pre">on_validation_model_zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_model_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Called by the training loop to release gradients before entering the validation loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_start">
<span class="sig-name descname"><span class="pre">on_validation_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.on_validation_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizer_step">
<span class="sig-name descname"><span class="pre">optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizer_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
the optimizer.</p>
<p>By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code> as shown in the example.
This method (and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code>) won’t be called during the accumulation phase when
<code class="docutils literal notranslate"><span class="pre">Trainer(accumulate_grad_batches</span> <span class="pre">!=</span> <span class="pre">1)</span></code>. Overriding this hook has no benefit with manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – A PyTorch optimizer</p></li>
<li><p><strong>optimizer_closure</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[], <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]]) – The optimizer closure. This closure must be executed as it includes the
calls to <code class="docutils literal notranslate"><span class="pre">training_step()</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>, and <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

<span class="c1"># Learning rate warm-up</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="c1"># update params</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

    <span class="c1"># manually warm up lr without a scheduler</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">&lt;</span> <span class="mi">500</span><span class="p">:</span>
        <span class="n">lr_scale</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">500.0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">pg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_scale</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizer_zero_grad">
<span class="sig-name descname"><span class="pre">optimizer_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizer_zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – A PyTorch optimizer</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="c1"># Set gradients to `None` instead of zero to improve performance (not required on `torch&gt;=2.0.0`).</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for the explanation of the above example.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizers">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the optimizer(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_pl_optimizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will wrap the optimizer(s) in a
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code> for automatic handling of precision,
profiling, and counting of step calls for proper logging and checkpointing. It specifically wraps the
<code class="docutils literal notranslate"><span class="pre">step</span></code> method and custom optimizers that don’t have this method are not supported.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A single optimizer, or a list of optimizers in case multiple ones are present.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.output_chunk_length">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_chunk_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.output_chunk_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of time steps predicted at once by the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>Parameter</em> – module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.pred_batch_size">
<span class="sig-name descname"><span class="pre">pred_batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.pred_batch_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.pred_n">
<span class="sig-name descname"><span class="pre">pred_n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.pred_n" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.pred_n_jobs">
<span class="sig-name descname"><span class="pre">pred_n_jobs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.pred_n_jobs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.pred_num_samples">
<span class="sig-name descname"><span class="pre">pred_num_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.pred_num_samples" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.pred_roll_size">
<span class="sig-name descname"><span class="pre">pred_roll_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.pred_roll_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.predict_dataloader">
<span class="sig-name descname"><span class="pre">predict_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.predict_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying prediction samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code> or a sequence of them specifying prediction samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.predict_likelihood_parameters">
<span class="sig-name descname"><span class="pre">predict_likelihood_parameters</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.predict_likelihood_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.predict_step">
<span class="sig-name descname"><span class="pre">predict_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.predict_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the prediction step</p>
<dl class="simple">
<dt>batch</dt><dd><p>output of Darts’ <code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceDataset</span></code> - tuple of <code class="docutils literal notranslate"><span class="pre">(past_target,</span> <span class="pre">past_covariates,</span>
<span class="pre">historic_future_covariates,</span> <span class="pre">future_covariates,</span> <span class="pre">future_past_covariates,</span> <span class="pre">input_timeseries)</span></code></p>
</dd>
<dt>batch_idx</dt><dd><p>the batch index of the current batch</p>
</dd>
<dt>dataloader_idx</dt><dd><p>the dataloader index</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data">
<span class="sig-name descname"><span class="pre">prepare_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Use this to download and prepare data. Downloading and saving data with multiple processes (distributed
settings) will result in corrupted data. Lightning ensures this method is called only within a single process,
so you can safely add your downloading logic within.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>DO NOT set state to the model (use <code class="docutils literal notranslate"><span class="pre">setup</span></code> instead)
since this is NOT called on every device</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># good</span>
    <span class="n">download_data</span><span class="p">()</span>
    <span class="n">tokenize</span><span class="p">()</span>
    <span class="n">etc</span><span class="p">()</span>

    <span class="c1"># bad</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">data_split</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">some_state</span> <span class="o">=</span> <span class="n">some_other_state</span><span class="p">()</span>
</pre></div>
</div>
<p>In a distributed environment, <code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> can be called in two ways
(using <span class="xref std std-ref">prepare_data_per_node</span>)</p>
<ol class="arabic simple">
<li><p>Once per node. This is the default and is only called on LOCAL_RANK=0.</p></li>
<li><p>Once in total. Only called on GLOBAL_RANK=0.</p></li>
</ol>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="c1"># called once per node on LOCAL_RANK=0 of that node</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># call on GLOBAL_RANK=0 (great for shared file systems)</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>This is called before requesting the dataloaders:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">initialize_distributed</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_dataloader</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data_per_node" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.print">
<span class="sig-name descname"><span class="pre">print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.print" title="Permalink to this definition">¶</a></dt>
<dd><p>Prints only from process 0. Use this in any distributed mode to log only once.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – The thing to print. The same as for Python’s built-in print function.</p></li>
<li><p><strong>**kwargs</strong> – The same as for Python’s built-in print function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;in forward&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>This function is deprecated in favor of <code class="xref py py-meth docutils literal notranslate"><span class="pre">register_full_backward_hook()</span></code> and
the behavior of this function will change in future versions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the module’s state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">persistent</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the buffer. The buffer can be accessed
from this module using the given name</p></li>
<li><p><strong>tensor</strong> (<em>Tensor</em><em> or </em><em>None</em>) – buffer to be registered. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations
that run on buffers, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>, are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
the buffer is <strong>not</strong> included in the module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>) – whether the buffer is part of this module’s
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">always_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_forward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
output. It can modify the input inplace but it will not have effect on
forward since this is called after <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called. The hook
should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the forward hook will be passed the
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> given to the forward function and be expected to return the
output possibly modified. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired
before all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_hook()</span></code> will fire before all hooks
registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the
kwargs given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>always_call</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be run regardless of
whether an exception is raised while calling the Module.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_forward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is false or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
input. User can either return a tuple or a single modified value in the
hook. We will wrap the value into a tuple if a single value is returned
(unless that value is already a tuple). The hook should have the
following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is true, the forward pre-hook will be passed the
kwargs given to the forward function. And if the hook modifies the
input, both the args and kwargs should be returned. The hook should have
the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">a</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">modified</span> <span class="nb">input</span> <span class="ow">and</span> <span class="n">kwargs</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_pre_hook()</span></code> will fire before all
hooks registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If true, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the kwargs
given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_full_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to a module
are computed, i.e. the hook will execute if and only if the gradients with
respect to module outputs are computed. The hook should have the following
signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in
subsequent computations. <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for all non-Tensor
arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_full_backward_pre_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_full_backward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward pre-hook on the module.</p>
<p>The hook will be called every time the gradients for the module are computed.
The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> is a tuple. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the output that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> in
subsequent computations. Entries in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for
all non-Tensor arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_pre_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_load_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_load_state_dict_post_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a post hook to be run after module’s <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code>
is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, incompatible_keys) -&gt; None</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">module</span></code> argument is the current module that this hook is registered
on, and the <code class="docutils literal notranslate"><span class="pre">incompatible_keys</span></code> argument is a <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> consisting
of attributes <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>. <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code>
is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the missing keys and
<code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the unexpected keys.</p>
<p>The given incompatible_keys can be modified inplace if needed.</p>
<p>Note that the checks performed when calling <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">strict=True</span></code> are affected by modifications the hook makes to
<code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> or <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>, as expected. Additions to either
set of keys will result in an error being thrown when <code class="docutils literal notranslate"><span class="pre">strict=True</span></code>, and
clearing out both missing and unexpected keys will avoid an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_module">
<span class="sig-name descname"><span class="pre">register_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.add_module" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_parameter">
<span class="sig-name descname"><span class="pre">register_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the parameter. The parameter can be accessed
from this module using the given name</p></li>
<li><p><strong>param</strong> (<em>Parameter</em><em> or </em><em>None</em>) – parameter to be added to the module. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations that run on parameters, such as <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cuda" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>,
are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the parameter is <strong>not</strong> included in the
module’s <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.register_state_dict_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>,
and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>. The registered
hooks can be used to perform pre-processing before the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>
call is made.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.requires_grad_" title="Permalink to this definition">¶</a></dt>
<dd><p>Change if autograd should record operations on parameters in this
module.</p>
<p>This method sets the parameters’ <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.requires_grad_()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<em>bool</em>) – whether autograd should record operations on
parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters">
<span class="sig-name descname"><span class="pre">save_hyperparameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.save_hyperparameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – single object of <cite>dict</cite>, <cite>NameSpace</cite> or <cite>OmegaConf</cite>
or string names or arguments from class <code class="docutils literal notranslate"><span class="pre">__init__</span></code></p></li>
<li><p><strong>ignore</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – an argument name or a list of argument names from
class <code class="docutils literal notranslate"><span class="pre">__init__</span></code> to be ignored</p></li>
<li><p><strong>frame</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">frame</span></code>]) – a frame object. Default is None</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to send the hyperparameters to the logger. Default: True</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Example::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign arguments</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="s1">&#39;arg1&#39;</span><span class="p">,</span> <span class="s1">&#39;arg3&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AutomaticArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># equivalent automatic</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutomaticArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg2&quot;: abc</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">SingleArgModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign single argument</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleArgModel</span><span class="p">(</span><span class="n">Namespace</span><span class="p">(</span><span class="n">p1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p2</span><span class="o">=</span><span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="n">p3</span><span class="o">=</span><span class="mf">3.14</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;p1&quot;: 1</span>
<span class="go">&quot;p2&quot;: abc</span>
<span class="go">&quot;p3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.mixins</span> <span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># pass argument(s) to ignore as a string or in a list</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="s1">&#39;arg2&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is called from <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state
found within the <cite>state_dict</cite>. Implement this function and a corresponding
<a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_extra_state" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.get_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_extra_state()</span></code></a> for your module if you need to store extra state within its
<cite>state_dict</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>dict</em>) – Extra state from the <cite>state_dict</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_mc_dropout">
<span class="sig-name descname"><span class="pre">set_mc_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">active</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_mc_dropout" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_predict_parameters">
<span class="sig-name descname"><span class="pre">set_predict_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roll_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.set_predict_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you
need to build models dynamically or adjust something about them. This hook is called on every process when
using DDP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">download_data</span><span class="p">()</span>
        <span class="n">tokenize</span><span class="p">()</span>

        <span class="c1"># don&#39;t do this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">something</span> <span class="o">=</span> <span class="k">else</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.share_memory">
<span class="sig-name descname"><span class="pre">share_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.share_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>~T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary containing references to the whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to <code class="docutils literal notranslate"><span class="pre">None</span></code> are not included.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned object is a shallow copy. It contains references
to the module’s parameters and buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> also accepts positional arguments for
<code class="docutils literal notranslate"><span class="pre">destination</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> in order. However,
this is being deprecated and keyword arguments will be enforced in
future releases.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please avoid the use of argument <code class="docutils literal notranslate"><span class="pre">destination</span></code> as it is not
designed for end-users.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>destination</strong> (<em>dict</em><em>, </em><em>optional</em>) – If provided, the state of module will
be updated into the dict and the same object is returned.
Otherwise, an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> will be created and returned.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em>) – a prefix added to parameter and buffer
names to compose the keys in state_dict. Default: <code class="docutils literal notranslate"><span class="pre">''</span></code>.</p></li>
<li><p><strong>keep_vars</strong> (<em>bool</em><em>, </em><em>optional</em>) – by default the <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> s
returned in the state dict are detached from autograd. If it’s
set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, detaching will not be performed.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary containing a whole state of the module</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.teardown">
<span class="sig-name descname"><span class="pre">teardown</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.teardown" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of fit (train + validate), validate, test, or predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stage</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_dataloader">
<span class="sig-name descname"><span class="pre">test_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying test samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">test()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a test dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a>, you don’t need to implement
this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the test set. In this step you’d normally generate examples or
calculate anything of interest such as accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your data iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><strong>batch_idx</strong> – The index of this batch.</p></li>
<li><p><strong>dataloader_idx</strong> – The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Skip to the next batch.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one test dataloader:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="o">...</span>

<span class="c1"># if you have multiple test dataloaders:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single test dataset</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple test dataloaders, <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple test dataloaders</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="o">...</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need to test you don’t need to implement this method.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> is called, the model has been put in eval mode and
PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
to training mode and gradients are enabled.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_dtype">
<span class="sig-name descname"><span class="pre">to_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Cast module precision (float32 by default) to another precision.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_empty" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves the parameters and buffers to the specified device without copying storage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>) – The desired device of the parameters
and buffers in this module.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – Whether parameters and buffers of submodules should
be recursively moved to the specified device.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_onnx">
<span class="sig-name descname"><span class="pre">to_onnx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_onnx" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the model in ONNX format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>]) – The path of the file the onnx model should be saved to.</p></li>
<li><p><strong>input_sample</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input for tracing. Default: None (Use self.example_input_array)</p></li>
<li><p><strong>**kwargs</strong> – Will be passed to torch.onnx.export function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">input_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">(</span><span class="s2">&quot;export.onnx&quot;</span><span class="p">,</span> <span class="n">input_sample</span><span class="p">,</span> <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_torchscript">
<span class="sig-name descname"><span class="pre">to_torchscript</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'script'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.to_torchscript" title="Permalink to this definition">¶</a></dt>
<dd><p>By default compiles the whole model to a <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>. If you want to use tracing,
please provided the argument <code class="docutils literal notranslate"><span class="pre">method='trace'</span></code> and make sure that either the <cite>example_inputs</cite> argument is
provided, or the model has <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a> set. If you would like to customize the modules that are
scripted you should override this method. In case you want to return multiple modules, we recommend using a
dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Path where to save the torchscript. Default: None (no file saved).</p></li>
<li><p><strong>method</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Whether to use TorchScript’s script or trace method. Default: ‘script’</p></li>
<li><p><strong>example_inputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – An input to be used to do tracing when method is set to ‘trace’.
Default: None (uses <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.example_input_array" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments that will be passed to the <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.script()</span></code> or
<code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.trace()</span></code> function.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Requires the implementation of the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> method.</p></li>
<li><p>The exported script will be set to evaluation mode.</p></li>
<li><p>It is recommended that you install the latest supported version of PyTorch
to use this feature without limitations. See also the <code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.jit</span></code>
documentation for supported features.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span>
    <span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model_trace.pt&quot;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;trace&#39;</span><span class="p">,</span> <span class="n">example_inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>]]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>This LightningModule as a torchscript, regardless of whether <cite>file_path</cite> is
defined or not.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.toggle_optimizer">
<span class="sig-name descname"><span class="pre">toggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.toggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Makes sure only the gradients of the current optimizer’s parameters are calculated in the training step to
prevent dangling gradients in multiple-optimizer setup.</p>
<p>It works with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.untoggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.untoggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">untoggle_optimizer()</span></code></a> to make sure <code class="docutils literal notranslate"><span class="pre">param_requires_grad_state</span></code> is properly reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to toggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.train_dataloader">
<span class="sig-name descname"><span class="pre">train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.train_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying training samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id39"><span class="problematic" id="id40">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.trainer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">trainer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.trainer.trainer.Trainer</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.trainer" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the training step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.transfer_batch_to_device">
<span class="sig-name descname"><span class="pre">transfer_batch_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.transfer_batch_to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data
structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code> or anything that implements <cite>.to(…)</cite></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, …).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook should only transfer the data and not modify it, nor should it move the data to
any other device than the one passed in as argument (unless you know what you are doing).
To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be transferred to a new device.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>) – The target device as defined in PyTorch.</p></li>
<li><p><strong>dataloader_idx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A reference to the data on the new device.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">CustomBatch</span><span class="p">):</span>
        <span class="c1"># move all tensors in your custom data structure to the device</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># skip device transfer for the first dataloader or anything you wish</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transfer_batch_to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">move_data_to_device()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_to_collection()</span></code></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.type">
<span class="sig-name descname"><span class="pre">type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.type" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.unfreeze">
<span class="sig-name descname"><span class="pre">unfreeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze all parameters for training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.untoggle_optimizer">
<span class="sig-name descname"><span class="pre">untoggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.untoggle_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.toggle_optimizer" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code>]) – The optimizer to untoggle.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.val_dataloader">
<span class="sig-name descname"><span class="pre">val_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.val_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>An iterable or collection of iterables specifying validation samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id41"><span class="problematic" id="id42">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">validate()</span></code></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a validation dataset and a <a class="reference internal" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.validation_step" title="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a>, you don’t need to
implement this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>performs the validation step</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.xpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the XPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.PLSplitCovariatesModule.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets gradients of all model parameters. See similar function
under <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code> for more context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>set_to_none</strong> (<em>bool</em>) – instead of setting to zero, set the grads to None.
See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for details.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="darts.models.forecasting.pl_forecasting_module.io_processor">
<span class="sig-prename descclassname"><span class="pre">darts.models.forecasting.pl_forecasting_module.</span></span><span class="sig-name descname"><span class="pre">io_processor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/pl_forecasting_module.html#io_processor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.pl_forecasting_module.io_processor" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies some input / output processing to PLForecastingModule.forward.
Note that this wrapper must be added to each of PLForecastinModule’s subclasses forward methods.
Here is an example how to add the decorator:</p>
<dl>
<dt><a href="#id43"><span class="problematic" id="id44">``</span></a><a href="#id45"><span class="problematic" id="id46">`</span></a>python</dt><dd><p>&#64;io_processor
def forward(self, <a href="#id47"><span class="problematic" id="id48">*</span></a>args, <a href="#id49"><span class="problematic" id="id50">**</span></a>kwargs)</p>
<blockquote>
<div><p>pass</p>
</div></blockquote>
</dd>
</dl>
<p><a href="#id51"><span class="problematic" id="id52">``</span></a><a href="#id53"><span class="problematic" id="id54">`</span></a></p>
</dd></dl>



              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="darts.models.forecasting.nlinear.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">N-Linear</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="darts.models.forecasting.prophet_model.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Facebook Prophet</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2020 - 2023, Unit8 SA (Apache 2.0 License).<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.3.2.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>