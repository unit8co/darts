
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Time-Series Mixer (TSMixer) &#8212; darts  documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <link rel="shortcut icon" href="../_static/docs-favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="VARIMA" href="darts.models.forecasting.varima.html" />
    <link rel="prev" title="Transformer Model" href="darts.models.forecasting.transformer_model.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/darts-logo-trim.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../README.html">
  Home
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../quickstart/00-quickstart.html">
  Quickstart
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../userguide.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="darts.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../examples.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release_notes/RELEASE_NOTES.html">
  Release Notes
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/unit8co/darts" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/unit8co" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.ad.html">
   Anomaly Detection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.ad.aggregators.html">
     Anomaly Aggregators
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.aggregators.and_aggregator.html">
       AND Aggregator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.aggregators.ensemble_sklearn_aggregator.html">
       Ensemble scikit-learn aggregator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.aggregators.or_aggregator.html">
       OR Aggregator
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.ad.anomaly_model.html">
     Anomaly Models
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.anomaly_model.filtering_am.html">
       Filtering Anomaly Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.anomaly_model.forecasting_am.html">
       Forecasting Anomaly Model
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.ad.detectors.html">
     Anomaly Detectors
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.detectors.iqr_detector.html">
       Interquartile Range (IQR) Detector
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.detectors.quantile_detector.html">
       Quantile Detector
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.detectors.threshold_detector.html">
       Threshold Detector
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.ad.scorers.html">
     Anomaly Scorers
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.difference_scorer.html">
       Difference Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.kmeans_scorer.html">
       k-means Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_cauchy_scorer.html">
       NLL Cauchy Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_exponential_scorer.html">
       NLL Exponential Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_gamma_scorer.html">
       NLL Gamma Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_gaussian_scorer.html">
       NLL Gaussian Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_laplace_scorer.html">
       NLL Laplace Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.nll_poisson_scorer.html">
       NLL Poisson Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.norm_scorer.html">
       Norm Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.pyod_scorer.html">
       PyOD Scorer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.ad.scorers.wasserstein_scorer.html">
       Wasserstein Scorer
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.ad.utils.html">
     Utils for Anomaly Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.dataprocessing.html">
   Data Processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.dataprocessing.dtw.html">
     Dynamic Time Warping (DTW)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.dtw.dtw.html">
       Dynamic Time Warping (DTW)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.dtw.window.html">
       DTW Windows
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.dataprocessing.encoders.html">
     Time Axis Encoders
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.encoders.encoder_base.html">
       Encoder Base Classes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.encoders.encoders.html">
       Time Axes Encoders
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.dataprocessing.transformers.html">
     Data Transformers
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.base_data_transformer.html">
       Data Transformer Base Class
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.boxcox.html">
       Box-Cox Transformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.diff.html">
       Differencing Transformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.fittable_data_transformer.html">
       Fittable Data Transformer Base Class
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.invertible_data_transformer.html">
       Invertible Data Transformer Base Class
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.mappers.html">
       Mapper and InvertibleMapper
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.midas.html">
       Mixed-data sampling (MIDAS) Transformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.missing_values_filler.html">
       Missing Values Filler
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.reconciliation.html">
       Hierarchical Reconciliation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.scaler.html">
       Scaler
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.static_covariates_transformer.html">
       Static Covariates Transformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.dataprocessing.transformers.window_transformer.html">
       Window Transformer
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.dataprocessing.pipeline.html">
     Pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.datasets.html">
   Datasets
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.explainability.html">
   Explainability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.explainability.explainability_result.html">
     Explainability Result
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.explainability.shap_explainer.html">
     Shap Explainer for RegressionModels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.explainability.tft_explainer.html">
     TFT Explainer for Temporal Fusion Transformer (TFTModel)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.metrics.html">
   Metrics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.metrics.metrics.html">
     Metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="darts.models.html">
   Models
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.models.filtering.html">
     Filtering Models
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.filtering.gaussian_process_filter.html">
       Gaussian Processes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.filtering.kalman_filter.html">
       Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.filtering.moving_average_filter.html">
       Moving Average
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="darts.models.forecasting.html">
     Forecasting Models
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.arima.html">
       ARIMA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.auto_arima.html">
       AutoARIMA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.baselines.html">
       Baseline Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.block_rnn_model.html">
       Block Recurrent Neural Networks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.catboost_model.html">
       CatBoost model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.conformal_models.html">
       Conformal Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.croston.html">
       Croston method
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.dlinear.html">
       D-Linear
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.exponential_smoothing.html">
       Exponential Smoothing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.fft.html">
       Fast Fourier Transform
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.global_baseline_models.html">
       Global Baseline Models (Naive)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.kalman_forecaster.html">
       Kalman Filter Forecaster
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.lgbm.html">
       LightGBM Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.linear_regression_model.html">
       Linear Regression model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.nbeats.html">
       N-BEATS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.nhits.html">
       N-HiTS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.nlinear.html">
       N-Linear
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.prophet_model.html">
       Facebook Prophet
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.random_forest.html">
       Random Forest
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.regression_ensemble_model.html">
       Regression ensemble model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.regression_model.html">
       Regression Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.rnn_model.html">
       Recurrent Neural Networks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.sf_auto_arima.html">
       StatsForecastAutoARIMA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.sf_auto_ces.html">
       StatsForecastAutoCES
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.sf_auto_ets.html">
       StatsForecastAutoETS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.sf_auto_tbats.html">
       StatsForecastAutoTBATS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.sf_auto_theta.html">
       StatsForecastAutoTheta
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.tbats_model.html">
       BATS and TBATS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.tcn_model.html">
       Temporal Convolutional Network
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.tft_model.html">
       Temporal Fusion Transformer (TFT)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.theta.html">
       Theta Method
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.tide_model.html">
       Time-series Dense Encoder (TiDE)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.transformer_model.html">
       Transformer Model
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Time-Series Mixer (TSMixer)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.varima.html">
       VARIMA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.models.forecasting.xgboost.html">
       XGBoost Model
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="darts.utils.html">
   Utils
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="darts.utils.data.html">
     TimeSeries Datasets
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.utils.data.horizon_based_dataset.html">
       Horizon-Based Training Dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.utils.data.inference_dataset.html">
       Inference Dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.utils.data.sequential_dataset.html">
       Sequential Training Dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.utils.data.shifted_dataset.html">
       Shifted Training Dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="darts.utils.data.training_dataset.html">
       Training Datasets Base Classes
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.likelihood_models.html">
     Likelihood Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.losses.html">
     PyTorch Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.missing_values.html">
     Utils for filling missing values
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.model_selection.html">
     Model selection utilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.statistics.html">
     Time Series Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.timeseries_generation.html">
     Utils for time series generation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.torch.html">
     Utils for Pytorch and its usage
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.ts_utils.html">
     Additional util functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="darts.utils.utils.html">
     Additional util functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="darts.timeseries.html">
   Timeseries
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                

<nav id="bd-toc-nav">
    
</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <span class="target" id="module-darts.models.forecasting.tsmixer_model"></span><section id="time-series-mixer-tsmixer">
<h1>Time-Series Mixer (TSMixer)<a class="headerlink" href="#time-series-mixer-tsmixer" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">darts.models.forecasting.tsmixer_model.</span></span><span class="sig-name descname"><span class="pre">TSMixerModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_chunk_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_chunk_shift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ff_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ReLU'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LayerNorm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_before</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_static_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/tsmixer_model.html#TSMixerModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">MixedCovariatesTorchModel</span></code></p>
<p>Time-Series Mixer (TSMixer): An All-MLP Architecture for Time Series.</p>
<p>This is an implementation of the TSMixer architecture, as outlined in <a class="reference internal" href="#r46be1e563d84-1" id="id1">[1]</a>. A major part of the architecture
was adopted from <a class="reference external" href="https://github.com/ditschuk/pytorch-tsmixer">this PyTorch implementation</a>. Additional
changes were applied to increase model performance and efficiency.</p>
<p>TSMixer forecasts time series data by integrating historical time series data, future known inputs, and static
contextual information. It uses a combination of conditional feature mixing and mixer layers to process and
combine these different types of data for effective forecasting.</p>
<p>This model supports past covariates (known for <cite>input_chunk_length</cite> points before prediction time), future
covariates (known for <cite>output_chunk_length</cite> points after prediction time), static covariates, as well as
probabilistic forecasting.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps in the past to take as a model input (per chunk). Applies to the target
series, and past and/or future covariates (if the model supports it).
Also called: Encoder length</p></li>
<li><p><strong>output_chunk_length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of time steps predicted at once (per chunk) by the internal model. Also, the number of future values
from future covariates to use as a model input (if the model supports future covariates). It is not the same
as forecast horizon <cite>n</cite> used in <cite>predict()</cite>, which is the desired number of prediction points generated
using either a one-shot- or autoregressive forecast. Setting <cite>n &lt;= output_chunk_length</cite> prevents
auto-regression. This is useful when the covariates don’t extend far enough into the future, or to prohibit
the model from using future values of past and / or future covariates for prediction (depending on the
model’s covariate support).
Also called: Decoder length</p></li>
<li><p><strong>output_chunk_shift</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Optionally, the number of steps to shift the start of the output chunk into the future (relative to the
input chunk end). This will create a gap between the input and output. If the model supports
<cite>future_covariates</cite>, the future values are extracted from the shifted output chunk. Predictions will start
<cite>output_chunk_shift</cite> steps after the end of the target <cite>series</cite>. If <cite>output_chunk_shift</cite> is set, the model
cannot generate autoregressive predictions (<cite>n &gt; output_chunk_length</cite>).</p></li>
<li><p><strong>hidden_size</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The hidden state size / size of the second feed-forward layer in the feature mixing MLP.</p></li>
<li><p><strong>ff_size</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The size of the first feed-forward layer in the feature mixing MLP.</p></li>
<li><p><strong>num_blocks</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of mixer blocks in the model. The number includes the first block and all subsequent blocks.</p></li>
<li><p><strong>activation</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The name of the activation function to use in the mixer layers. Default: <cite>“ReLU”</cite>. Must be one of
<cite>“ReLU”, “RReLU”, “PReLU”, “ELU”, “Softplus”, “Tanh”, “SELU”, “LeakyReLU”, “Sigmoid”, “GELU”</cite>.</p></li>
<li><p><strong>dropout</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Fraction of neurons affected by dropout. This is compatible with Monte Carlo dropout at inference time
for model uncertainty estimation (enabled with <code class="docutils literal notranslate"><span class="pre">mc_dropout=True</span></code> at prediction time).</p></li>
<li><p><strong>norm_type</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]) – The type of <cite>LayerNorm</cite> variant to use.  Default: <cite>“LayerNorm”</cite>. If a string, must be one of
<cite>“LayerNormNoBias”, “LayerNorm”, “TimeBatchNorm2d”</cite>. Otherwise, must be a custom <cite>nn.Module</cite>.</p></li>
<li><p><strong>normalize_before</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to apply layer normalization before or after mixer layer.</p></li>
<li><p><strong>use_static_covariates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the model should use static covariate information in case the input <cite>series</cite> passed to <code class="docutils literal notranslate"><span class="pre">fit()</span></code>
contain static covariates. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, and static covariates are available at fitting time, will enforce
that all target <cite>series</cite> have the same static covariate dimensionality in <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">predict()</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Optional arguments to initialize the pytorch_lightning.Module, pytorch_lightning.Trainer, and
Darts’ <code class="xref py py-class docutils literal notranslate"><span class="pre">TorchForecastingModel</span></code>.</p></li>
<li><p><strong>loss_fn</strong> – PyTorch loss function used for training.
This parameter will be ignored for probabilistic models if the <code class="docutils literal notranslate"><span class="pre">likelihood</span></code> parameter is specified.
Default: <code class="docutils literal notranslate"><span class="pre">torch.nn.MSELoss()</span></code>.</p></li>
<li><p><strong>likelihood</strong> – One of Darts’ <a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Likelihood</span></code></a> models to be used for
probabilistic forecasts. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>torch_metrics</strong> – A torch metric or a <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code> used for evaluation. A full list of available metrics can be found
at <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/">https://torchmetrics.readthedocs.io/en/latest/</a>. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>optimizer_cls</strong> – The PyTorch optimizer class to be used. Default: <code class="docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code>.</p></li>
<li><p><strong>optimizer_kwargs</strong> – Optionally, some keyword arguments for the PyTorch optimizer (e.g., <code class="docutils literal notranslate"><span class="pre">{'lr':</span> <span class="pre">1e-3}</span></code>
for specifying a learning rate). Otherwise, the default values of the selected <code class="docutils literal notranslate"><span class="pre">optimizer_cls</span></code>
will be used. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_cls</strong> – Optionally, the PyTorch learning rate scheduler class to be used. Specifying <code class="docutils literal notranslate"><span class="pre">None</span></code> corresponds
to using a constant learning rate. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>lr_scheduler_kwargs</strong> – Optionally, some keyword arguments for the PyTorch learning rate scheduler. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>use_reversible_instance_norm</strong> – Whether to use reversible instance normalization <cite>RINorm</cite> against distribution shift as shown in <a href="#id30"><span class="problematic" id="id2">[3]_</span></a>.
It is only applied to the features of the target series and not the covariates.</p></li>
<li><p><strong>batch_size</strong> – Number of time series (input and output sequences) used in each training pass. Default: <code class="docutils literal notranslate"><span class="pre">32</span></code>.</p></li>
<li><p><strong>n_epochs</strong> – Number of epochs over which to train the model. Default: <code class="docutils literal notranslate"><span class="pre">100</span></code>.</p></li>
<li><p><strong>model_name</strong> – Name of the model. Used for creating checkpoints and saving torch.Tensorboard data. If not specified,
defaults to the following string <code class="docutils literal notranslate"><span class="pre">&quot;YYYY-mm-dd_HH_MM_SS_torch_model_run_PID&quot;</span></code>, where the initial part
of the name is formatted with the local date and time, while PID is the processed ID (preventing models
spawned at the same time by different processes to share the same model_name). E.g.,
<code class="docutils literal notranslate"><span class="pre">&quot;2021-06-14_09_53_32_torch_model_run_44607&quot;</span></code>.</p></li>
<li><p><strong>work_dir</strong> – Path of the working directory, where to save checkpoints and torch.Tensorboard summaries.
Default: current working directory.</p></li>
<li><p><strong>log_torch.Tensorboard</strong> – If set, use torch.Tensorboard to log the different parameters. The logs will be located in:
<code class="docutils literal notranslate"><span class="pre">&quot;{work_dir}/darts_logs/{model_name}/logs/&quot;</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>nr_epochs_val_period</strong> – Number of epochs to wait before evaluating the validation loss (if a validation
<code class="docutils literal notranslate"><span class="pre">TimeSeries</span></code> is passed to the <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.fit" title="darts.models.forecasting.tsmixer_model.TSMixerModel.fit"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit()</span></code></a> method). Default: <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><strong>force_reset</strong> – If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, any previously-existing model with the same name will be reset (all checkpoints will
be discarded). Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>save_checkpoints</strong> – Whether to automatically save the untrained model and checkpoints from training.
To load the model from checkpoint, call <code class="xref py py-func docutils literal notranslate"><span class="pre">MyModelClass.load_from_checkpoint()</span></code>, where
<code class="xref py py-class docutils literal notranslate"><span class="pre">MyModelClass</span></code> is the <code class="xref py py-class docutils literal notranslate"><span class="pre">TorchForecastingModel</span></code> class that was used (such as <code class="xref py py-class docutils literal notranslate"><span class="pre">TFTModel</span></code>,
<code class="xref py py-class docutils literal notranslate"><span class="pre">NBEATSModel</span></code>, etc.). If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the model can still be manually saved using
<a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.save" title="darts.models.forecasting.tsmixer_model.TSMixerModel.save"><code class="xref py py-func docutils literal notranslate"><span class="pre">save()</span></code></a> and loaded using <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load" title="darts.models.forecasting.tsmixer_model.TSMixerModel.load"><code class="xref py py-func docutils literal notranslate"><span class="pre">load()</span></code></a>. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>add_encoders</strong> – <p>A large number of past and future covariates can be automatically generated with <cite>add_encoders</cite>.
This can be done by adding multiple pre-defined index encoders and/or custom user-made functions that
will be used as index encoders. Additionally, a transformer such as Darts’ <code class="xref py py-class docutils literal notranslate"><span class="pre">Scaler</span></code> can be added to
transform the generated covariates. This happens all under one hood and only needs to be specified at
model creation.
Read <code class="xref py py-meth docutils literal notranslate"><span class="pre">SequentialEncoder</span></code> to find out more about
<code class="docutils literal notranslate"><span class="pre">add_encoders</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>. An example showing some of <code class="docutils literal notranslate"><span class="pre">add_encoders</span></code> features:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">encode_year</span><span class="p">(</span><span class="n">idx</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">year</span> <span class="o">-</span> <span class="mi">1950</span><span class="p">)</span> <span class="o">/</span> <span class="mi">50</span>

<span class="n">add_encoders</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">&#39;cyclic&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;future&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;month&#39;</span><span class="p">]},</span>
    <span class="s1">&#39;datetime_attribute&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;future&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;hour&#39;</span><span class="p">,</span> <span class="s1">&#39;dayofweek&#39;</span><span class="p">]},</span>
    <span class="s1">&#39;position&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;past&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;relative&#39;</span><span class="p">],</span> <span class="s1">&#39;future&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;relative&#39;</span><span class="p">]},</span>
    <span class="s1">&#39;custom&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;past&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">encode_year</span><span class="p">]},</span>
    <span class="s1">&#39;transformer&#39;</span><span class="p">:</span> <span class="n">Scaler</span><span class="p">(),</span>
    <span class="s1">&#39;tz&#39;</span><span class="p">:</span> <span class="s1">&#39;CET&#39;</span>
<span class="p">}</span>
</pre></div>
</div>
</p></li>
<li><p><strong>random_state</strong> – Control the randomness of the weight’s initialization. Check this
<a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-random_state">link</a> for more details.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>pl_trainer_kwargs</strong> – <p>By default <code class="xref py py-class docutils literal notranslate"><span class="pre">TorchForecastingModel</span></code> creates a PyTorch Lightning Trainer with several useful presets
that performs the training, validation and prediction processes. These presets include automatic
checkpointing, torch.Tensorboard logging, setting the torch device and more.
With <code class="docutils literal notranslate"><span class="pre">pl_trainer_kwargs</span></code> you can add additional kwargs to instantiate the PyTorch Lightning trainer
object. Check the <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html">PL Trainer documentation</a> for more information about the
supported kwargs. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Running on GPU(s) is also possible using <code class="docutils literal notranslate"><span class="pre">pl_trainer_kwargs</span></code> by specifying keys <code class="docutils literal notranslate"><span class="pre">&quot;accelerator&quot;,</span>
<span class="pre">&quot;devices&quot;,</span> <span class="pre">and</span> <span class="pre">&quot;auto_select_gpus&quot;</span></code>. Some examples for setting the devices inside the <code class="docutils literal notranslate"><span class="pre">pl_trainer_kwargs</span></code>
dict:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">{&quot;accelerator&quot;:</span> <span class="pre">&quot;cpu&quot;}</span></code> for CPU,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">{&quot;accelerator&quot;:</span> <span class="pre">&quot;gpu&quot;,</span> <span class="pre">&quot;devices&quot;:</span> <span class="pre">[i]}</span></code> to use only GPU <code class="docutils literal notranslate"><span class="pre">i</span></code> (<code class="docutils literal notranslate"><span class="pre">i</span></code> must be an integer),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">{&quot;accelerator&quot;:</span> <span class="pre">&quot;gpu&quot;,</span> <span class="pre">&quot;devices&quot;:</span> <span class="pre">-1,</span> <span class="pre">&quot;auto_select_gpus&quot;:</span> <span class="pre">True}</span></code> to use all available GPUS.</p></li>
</ul>
<p>For more info, see here:
<a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-flags">https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-flags</a> , and
<a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/accelerators/gpu_basic.html#train-on-multiple-gpus">https://pytorch-lightning.readthedocs.io/en/stable/accelerators/gpu_basic.html#train-on-multiple-gpus</a></p>
<p>With parameter <code class="docutils literal notranslate"><span class="pre">&quot;callbacks&quot;</span></code> you can add custom or PyTorch-Lightning built-in callbacks to Darts’
<code class="xref py py-class docutils literal notranslate"><span class="pre">TorchForecastingModel</span></code>. Below is an example for adding EarlyStopping to the training process.
The model will stop training early if the validation loss <cite>val_loss</cite> does not improve beyond
specifications. For more information on callbacks, visit:
<a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/callbacks.html">PyTorch Lightning Callbacks</a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.callbacks.early_stopping</span><span class="w"> </span><span class="kn">import</span> <span class="n">EarlyStopping</span>

<span class="c1"># stop training when validation loss does not decrease more than 0.05 (`min_delta`) over</span>
<span class="c1"># a period of 5 epochs (`patience`)</span>
<span class="n">my_stopper</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">min_delta</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">pl_trainer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;callbacks&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">my_stopper</span><span class="p">]}</span>
</pre></div>
</div>
<p>Note that you can also use a custom PyTorch Lightning Trainer for training and prediction with optional
parameter <code class="docutils literal notranslate"><span class="pre">trainer</span></code> in <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.fit" title="darts.models.forecasting.tsmixer_model.TSMixerModel.fit"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit()</span></code></a> and <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.predict" title="darts.models.forecasting.tsmixer_model.TSMixerModel.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p>
</p></li>
<li><p><strong>show_warnings</strong> – whether to show warnings raised from PyTorch Lightning. Useful to detect potential issues of
your forecasting use case. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r46be1e563d84-1"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p><a class="reference external" href="https://arxiv.org/abs/2303.06053">https://arxiv.org/abs/2303.06053</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">darts.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">WeatherDataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">darts.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">TSMixerModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">series</span> <span class="o">=</span> <span class="n">WeatherDataset</span><span class="p">()</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># predicting temperatures</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="s1">&#39;T (degC)&#39;</span><span class="p">][:</span><span class="mi">100</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># optionally, use past observed rainfall (pretending to be unknown beyond index 100)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">past_cov</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="s1">&#39;rain (mm)&#39;</span><span class="p">][:</span><span class="mi">100</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># optionally, use future atmospheric pressure (pretending this component is a forecast)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">future_cov</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="s1">&#39;p (mbar)&#39;</span><span class="p">][:</span><span class="mi">106</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">TSMixerModel</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">input_chunk_length</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">output_chunk_length</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">use_reversible_instance_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">n_epochs</span><span class="o">=</span><span class="mi">20</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">past_covariates</span><span class="o">=</span><span class="n">past_cov</span><span class="p">,</span> <span class="n">future_covariates</span><span class="o">=</span><span class="n">future_cov</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
<span class="go">array([[3.92519848],</span>
<span class="go">    [4.05650312],</span>
<span class="go">    [4.21781987],</span>
<span class="go">    [4.29394973],</span>
<span class="go">    [4.4122863 ],</span>
<span class="go">    [4.42762751]])</span>
</pre></div>
</div>
<p class="rubric">Attributes</p>
<table class="autosummary longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.considers_static_covariates" title="darts.models.forecasting.tsmixer_model.TSMixerModel.considers_static_covariates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">considers_static_covariates</span></code></a></p></td>
<td><p>Whether the model considers static covariates, if there are any.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.extreme_lags" title="darts.models.forecasting.tsmixer_model.TSMixerModel.extreme_lags"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extreme_lags</span></code></a></p></td>
<td><p>A 8-tuple containing in order: (min target lag, max target lag, min past covariate lag, max past covariate lag, min future covariate lag, max future covariate lag, output shift, max target lag train (only for RNNModel)).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.min_train_samples" title="darts.models.forecasting.tsmixer_model.TSMixerModel.min_train_samples"><code class="xref py py-obj docutils literal notranslate"><span class="pre">min_train_samples</span></code></a></p></td>
<td><p>The minimum number of samples for training the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.output_chunk_length" title="darts.models.forecasting.tsmixer_model.TSMixerModel.output_chunk_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_chunk_length</span></code></a></p></td>
<td><p>Number of time steps predicted at once by the model, not defined for statistical models.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.output_chunk_shift" title="darts.models.forecasting.tsmixer_model.TSMixerModel.output_chunk_shift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_chunk_shift</span></code></a></p></td>
<td><p>Number of time steps that the output/prediction starts after the end of the input.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_future_covariates" title="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_future_covariates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_future_covariates</span></code></a></p></td>
<td><p>Whether model supports future covariates</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_likelihood_parameter_prediction" title="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_likelihood_parameter_prediction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_likelihood_parameter_prediction</span></code></a></p></td>
<td><p>Whether model instance supports direct prediction of likelihood parameters</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_multivariate" title="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_multivariate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_multivariate</span></code></a></p></td>
<td><p>Whether the model considers more than one variate in the time series.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_optimized_historical_forecasts" title="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_optimized_historical_forecasts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_optimized_historical_forecasts</span></code></a></p></td>
<td><p>Whether the model supports optimized historical forecasts</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_past_covariates" title="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_past_covariates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_past_covariates</span></code></a></p></td>
<td><p>Whether model supports past covariates</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_probabilistic_prediction" title="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_probabilistic_prediction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_probabilistic_prediction</span></code></a></p></td>
<td><p>Checks if the forecasting model with this configuration supports probabilistic predictions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_sample_weight" title="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_sample_weight"><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_sample_weight</span></code></a></p></td>
<td><p>Whether model supports sample weight for training.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_static_covariates" title="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_static_covariates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_static_covariates</span></code></a></p></td>
<td><p>Whether model supports static covariates</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_transferrable_series_prediction" title="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_transferrable_series_prediction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_transferrable_series_prediction</span></code></a></p></td>
<td><p>Whether the model supports prediction for any input <cite>series</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.uses_future_covariates" title="darts.models.forecasting.tsmixer_model.TSMixerModel.uses_future_covariates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">uses_future_covariates</span></code></a></p></td>
<td><p>Whether the model uses future covariates, once fitted.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.uses_past_covariates" title="darts.models.forecasting.tsmixer_model.TSMixerModel.uses_past_covariates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">uses_past_covariates</span></code></a></p></td>
<td><p>Whether the model uses past covariates, once fitted.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.uses_static_covariates" title="darts.models.forecasting.tsmixer_model.TSMixerModel.uses_static_covariates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">uses_static_covariates</span></code></a></p></td>
<td><p>Whether the model uses static covariates, once fitted.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 69%" />
<col style="width: 31%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>epochs_trained</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>input_chunk_length</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>likelihood</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>model_created</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>model_params</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table class="autosummary longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.backtest" title="darts.models.forecasting.tsmixer_model.TSMixerModel.backtest"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backtest</span></code></a>(series[, past_covariates, ...])</p></td>
<td><p>Compute error values that the model produced for historical forecasts on (potentially multiple) <cite>series</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.fit" title="darts.models.forecasting.tsmixer_model.TSMixerModel.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(series[, past_covariates, ...])</p></td>
<td><p>Fit/train the model on one or multiple series.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.fit_from_dataset" title="darts.models.forecasting.tsmixer_model.TSMixerModel.fit_from_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_from_dataset</span></code></a>(train_dataset[, ...])</p></td>
<td><p>Train the model with a specific <code class="xref py py-class docutils literal notranslate"><span class="pre">darts.utils.data.TrainingDataset</span></code> instance.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.generate_fit_encodings" title="darts.models.forecasting.tsmixer_model.TSMixerModel.generate_fit_encodings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate_fit_encodings</span></code></a>(series[, ...])</p></td>
<td><p>Generates the covariate encodings that were used/generated for fitting the model and returns a tuple of past, and future covariates series with the original and encoded covariates stacked together.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.generate_fit_predict_encodings" title="darts.models.forecasting.tsmixer_model.TSMixerModel.generate_fit_predict_encodings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate_fit_predict_encodings</span></code></a>(n, series[, ...])</p></td>
<td><p>Generates covariate encodings for training and inference/prediction and returns a tuple of past, and future covariates series with the original and encoded covariates stacked together.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.generate_predict_encodings" title="darts.models.forecasting.tsmixer_model.TSMixerModel.generate_predict_encodings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate_predict_encodings</span></code></a>(n, series[, ...])</p></td>
<td><p>Generates covariate encodings for the inference/prediction set and returns a tuple of past, and future covariates series with the original and encoded covariates stacked together.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.gridsearch" title="darts.models.forecasting.tsmixer_model.TSMixerModel.gridsearch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gridsearch</span></code></a>(parameters, series[, ...])</p></td>
<td><p>Find the best hyper-parameters among a given set using a grid search.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.historical_forecasts" title="darts.models.forecasting.tsmixer_model.TSMixerModel.historical_forecasts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">historical_forecasts</span></code></a>(series[, ...])</p></td>
<td><p>Generates historical forecasts by simulating predictions at various points in time throughout the history of the provided (potentially multiple) <cite>series</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load" title="darts.models.forecasting.tsmixer_model.TSMixerModel.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(path[, pl_trainer_kwargs])</p></td>
<td><p>Loads a model from a given file path.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load_from_checkpoint" title="darts.models.forecasting.tsmixer_model.TSMixerModel.load_from_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code></a>(model_name[, work_dir, ...])</p></td>
<td><p>Load the model from automatically saved checkpoints under '{work_dir}/darts_logs/{model_name}/checkpoints/'.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load_weights" title="darts.models.forecasting.tsmixer_model.TSMixerModel.load_weights"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_weights</span></code></a>(path[, load_encoders, skip_checks])</p></td>
<td><p>Loads the weights from a manually saved model (saved with <code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load_weights_from_checkpoint" title="darts.models.forecasting.tsmixer_model.TSMixerModel.load_weights_from_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_weights_from_checkpoint</span></code></a>([model_name, ...])</p></td>
<td><p>Load only the weights from automatically saved checkpoints under '{work_dir}/darts_logs/{model_name}/ checkpoints/'.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.lr_find" title="darts.models.forecasting.tsmixer_model.TSMixerModel.lr_find"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lr_find</span></code></a>(series[, past_covariates, ...])</p></td>
<td><p>A wrapper around PyTorch Lightning's <cite>Tuner.lr_find()</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.predict" title="darts.models.forecasting.tsmixer_model.TSMixerModel.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(n[, series, past_covariates, ...])</p></td>
<td><p>Predict the <code class="docutils literal notranslate"><span class="pre">n</span></code> time step following the end of the training series, or of the specified <code class="docutils literal notranslate"><span class="pre">series</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.predict_from_dataset" title="darts.models.forecasting.tsmixer_model.TSMixerModel.predict_from_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_from_dataset</span></code></a>(n, input_series_dataset)</p></td>
<td><p>This method allows for predicting with a specific <code class="xref py py-class docutils literal notranslate"><span class="pre">darts.utils.data.InferenceDataset</span></code> instance.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.reset_model" title="darts.models.forecasting.tsmixer_model.TSMixerModel.reset_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_model</span></code></a>()</p></td>
<td><p>Resets the model object and removes all stored data - model, checkpoints, loggers and training history.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.residuals" title="darts.models.forecasting.tsmixer_model.TSMixerModel.residuals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">residuals</span></code></a>(series[, past_covariates, ...])</p></td>
<td><p>Compute the residuals that the model produced for historical forecasts on (potentially multiple) <cite>series</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.save" title="darts.models.forecasting.tsmixer_model.TSMixerModel.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>([path, clean])</p></td>
<td><p>Saves the model under a given path.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.to_cpu" title="darts.models.forecasting.tsmixer_model.TSMixerModel.to_cpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_cpu</span></code></a>()</p></td>
<td><p>Updates the PyTorch Lightning Trainer parameters to move the model to CPU the next time <a href="#id3"><span class="problematic" id="id4">:fun:`fit()`</span></a> or <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.predict" title="darts.models.forecasting.tsmixer_model.TSMixerModel.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">predict()</span></code></a> is called.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.backtest">
<span class="sig-name descname"><span class="pre">backtest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_covariates=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_covariates=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">historical_forecasts=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forecast_horizon=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_length=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_format='value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrain=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overlap_end=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_points_only=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric=&lt;function</span> <span class="pre">mape&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">mean&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_warnings=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_optimization=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_transformers=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.backtest" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute error values that the model produced for historical forecasts on (potentially multiple) <cite>series</cite>.</p>
<p>If <cite>historical_forecasts</cite> are provided, the metric(s) (given by the <cite>metric</cite> function) is evaluated directly on
all forecasts and actual values. The same <cite>series</cite> and <cite>last_points_only</cite> value must be passed that were used
to generate the historical forecasts. Finally, the method returns an optional <cite>reduction</cite> (the mean by default)
of all these metric scores.</p>
<p>If <cite>historical_forecasts</cite> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, it first generates the historical forecasts with the parameters given
below (see <a class="reference internal" href="darts.models.forecasting.forecasting_model.html#darts.models.forecasting.forecasting_model.ForecastingModel.historical_forecasts" title="darts.models.forecasting.forecasting_model.ForecastingModel.historical_forecasts"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ForecastingModel.historical_forecasts()</span></code></a> for more info) and then
evaluates as described above.</p>
<p>The metric(s) can be further customized <cite>metric_kwargs</cite> (e.g. control the aggregation over components, time
steps, multiple series, other required arguments such as <cite>q</cite> for quantile metrics, …).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]]) – A (sequence of) target time series used to successively train (if <cite>retrain</cite> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>) and compute
the historical forecasts.</p></li>
<li><p><strong>past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a (sequence of) past-observed covariate time series for every input time series in <cite>series</cite>.
This applies only if the model supports past covariates.</p></li>
<li><p><strong>future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a (sequence of) future-known covariate time series for every input time series in <cite>series</cite>.
This applies only if the model supports future covariates.</p></li>
<li><p><strong>historical_forecasts</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the (or a sequence of / a sequence of sequences of) historical forecasts time series to be
evaluated. Corresponds to the output of <a class="reference internal" href="darts.models.forecasting.forecasting_model.html#darts.models.forecasting.forecasting_model.ForecastingModel.historical_forecasts" title="darts.models.forecasting.forecasting_model.ForecastingModel.historical_forecasts"><code class="xref py py-meth docutils literal notranslate"><span class="pre">historical_forecasts()</span></code></a>. The same <cite>series</cite> and
<cite>last_points_only</cite> values must be passed that were used to generate the historical forecasts. If provided,
will skip historical forecasting and ignore all parameters except <cite>series</cite>, <cite>last_points_only</cite>, <cite>metric</cite>,
and <cite>reduction</cite>.</p></li>
<li><p><strong>forecast_horizon</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The forecast horizon for the predictions.</p></li>
<li><p><strong>num_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of times a prediction is sampled from a probabilistic model. Use values <code class="docutils literal notranslate"><span class="pre">&gt;1</span></code> only for probabilistic
models.</p></li>
<li><p><strong>train_length</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, use a fixed length / number of time steps for every constructed training set (rolling window
mode). Only effective when <cite>retrain</cite> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>. The default is <code class="docutils literal notranslate"><span class="pre">None</span></code>, where it uses all time
steps up until the prediction time (expanding window mode). If larger than the number of available time
steps, uses the expanding mode. Needs to be at least <cite>min_train_series_length</cite>.</p></li>
<li><p><strong>start</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Timestamp</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, the first point in time at which a prediction is computed. This parameter supports:
<code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas.Timestamp</span></code>, and <code class="docutils literal notranslate"><span class="pre">None</span></code>.
If a <code class="docutils literal notranslate"><span class="pre">float</span></code>, it is the proportion of the time series that should lie before the first prediction point.
If an <code class="docutils literal notranslate"><span class="pre">int</span></code>, it is either the index position of the first prediction point for <cite>series</cite> with a
<cite>pd.DatetimeIndex</cite>, or the index value for <cite>series</cite> with a <cite>pd.RangeIndex</cite>. The latter can be changed to
the index position with <cite>start_format=”position”</cite>.
If a <code class="docutils literal notranslate"><span class="pre">pandas.Timestamp</span></code>, it is the time stamp of the first prediction point.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the first prediction point will automatically be set to:</p>
<ul>
<li><p>the first predictable point if <cite>retrain</cite> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, or <cite>retrain</cite> is a Callable and the first
predictable point is earlier than the first trainable point.</p></li>
<li><p>the first trainable point if <cite>retrain</cite> is <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">int</span></code> (given <cite>train_length</cite>),
or <cite>retrain</cite> is a <code class="docutils literal notranslate"><span class="pre">Callable</span></code> and the first trainable point is earlier than the first predictable point.</p></li>
<li><p>the first trainable point (given <cite>train_length</cite>) otherwise</p></li>
</ul>
<dl class="simple">
<dt>Note: If <cite>start</cite> is not within the trainable / forecastable points, uses the closest valid start point that</dt><dd><p>is a round multiple of <cite>stride</cite> ahead of <cite>start</cite>. Raises a <cite>ValueError</cite>, if no valid start point exists.</p>
</dd>
<dt>Note: If the model uses a shifted output (<cite>output_chunk_shift &gt; 0</cite>), then the first predicted point is also</dt><dd><p>shifted by <cite>output_chunk_shift</cite> points into the future.</p>
</dd>
<dt>Note: If <cite>start</cite> is outside the possible historical forecasting times, will ignore the parameter</dt><dd><p>(default behavior with <code class="docutils literal notranslate"><span class="pre">None</span></code>) and start at the first trainable/predictable point.</p>
</dd>
</dl>
</p></li>
<li><p><strong>start_format</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[‘position’, ‘value’]) – Defines the <cite>start</cite> format.
If set to <code class="docutils literal notranslate"><span class="pre">'position'</span></code>, <cite>start</cite> corresponds to the index position of the first predicted point and can
range from <cite>(-len(series), len(series) - 1)</cite>.
If set to <code class="docutils literal notranslate"><span class="pre">'value'</span></code>, <cite>start</cite> corresponds to the index value/label of the first predicted point. Will raise
an error if the value is not in <cite>series</cite>’ index. Default: <code class="docutils literal notranslate"><span class="pre">'value'</span></code>.</p></li>
<li><p><strong>stride</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of time steps between two consecutive predictions.</p></li>
<li><p><strong>retrain</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[…, <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]]) – <p>Whether and/or on which condition to retrain the model before predicting.
This parameter supports 3 different types: <code class="docutils literal notranslate"><span class="pre">bool</span></code>, (positive) <code class="docutils literal notranslate"><span class="pre">int</span></code>, and <code class="docutils literal notranslate"><span class="pre">Callable</span></code> (returning a
<code class="docutils literal notranslate"><span class="pre">bool</span></code>).
In the case of <code class="docutils literal notranslate"><span class="pre">bool</span></code>: retrain the model at each step (<cite>True</cite>), or never retrain the model (<cite>False</cite>).
In the case of <code class="docutils literal notranslate"><span class="pre">int</span></code>: the model is retrained every <cite>retrain</cite> iterations.
In the case of <code class="docutils literal notranslate"><span class="pre">Callable</span></code>: the model is retrained whenever callable returns <cite>True</cite>.
The callable must have the following positional arguments:</p>
<ul>
<li><p><cite>counter</cite> (int): current <cite>retrain</cite> iteration</p></li>
<li><p><cite>pred_time</cite> (pd.Timestamp or int): timestamp of forecast time (end of the training series)</p></li>
<li><p><cite>train_series</cite> (TimeSeries): train series up to <cite>pred_time</cite></p></li>
<li><p><cite>past_covariates</cite> (TimeSeries): past_covariates series up to <cite>pred_time</cite></p></li>
<li><p><cite>future_covariates</cite> (TimeSeries): future_covariates series up to <cite>min(pred_time + series.freq *
forecast_horizon, series.end_time())</cite></p></li>
</ul>
<p>Note: if any optional <cite>*_covariates</cite> are not passed to <cite>historical_forecast</cite>, <code class="docutils literal notranslate"><span class="pre">None</span></code> will be passed
to the corresponding retrain function argument.
Note: some models require being retrained every time and do not support anything other than
<cite>retrain=True</cite>.
Note: also controls the retraining of the <cite>data_transformers</cite>.</p>
</p></li>
<li><p><strong>overlap_end</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the returned forecasts can go beyond the series’ end or not.</p></li>
<li><p><strong>last_points_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return only the last point of each historical forecast. If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the method returns a
single <code class="docutils literal notranslate"><span class="pre">TimeSeries</span></code> (for each time series in <cite>series</cite>) containing the successive point forecasts.
Otherwise, returns a list of historical <code class="docutils literal notranslate"><span class="pre">TimeSeries</span></code> forecasts.</p></li>
<li><p><strong>metric</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[…, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]]], <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[…, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]]]]]) – A metric function or a list of metric functions. Each metric must either be a Darts metric (see <a class="reference external" href="https://unit8co.github.io/darts/generated_api/darts.metrics.html">here</a>), or a custom metric that has an
identical signature as Darts’ metrics, uses decorators <a class="reference internal" href="darts.metrics.metrics.html#darts.metrics.metrics.multi_ts_support" title="darts.metrics.metrics.multi_ts_support"><code class="xref py py-func docutils literal notranslate"><span class="pre">multi_ts_support()</span></code></a> and
<a class="reference internal" href="darts.metrics.metrics.html#darts.metrics.metrics.multi_ts_support" title="darts.metrics.metrics.multi_ts_support"><code class="xref py py-func docutils literal notranslate"><span class="pre">multi_ts_support()</span></code></a>, and returns the metric score.</p></li>
<li><p><strong>reduction</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[…, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – A function used to combine the individual error scores obtained when <cite>last_points_only</cite> is set to <cite>False</cite>.
When providing several metric functions, the function will receive the argument <cite>axis = 1</cite> to obtain single
value for each metric function.
If explicitly set to <cite>None</cite>, the method will return a list of the individual error scores instead.
Set to <code class="docutils literal notranslate"><span class="pre">np.mean</span></code> by default.</p></li>
<li><p><strong>verbose</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to print the progress.</p></li>
<li><p><strong>show_warnings</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to show warnings related to historical forecasts optimization, or parameters <cite>start</cite> and
<cite>train_length</cite>.</p></li>
<li><p><strong>predict_likelihood_parameters</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set to <cite>True</cite>, the model predicts the parameters of its <cite>likelihood</cite> instead of the target. Only
supported for probabilistic models with a likelihood, <cite>num_samples = 1</cite> and <cite>n&lt;=output_chunk_length</cite>.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>enable_optimization</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to use the optimized version of <cite>historical_forecasts</cite> when supported and available.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>data_transformers</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.dataprocessing.transformers.base_data_transformer.html#darts.dataprocessing.transformers.base_data_transformer.BaseDataTransformer" title="darts.dataprocessing.transformers.base_data_transformer.BaseDataTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseDataTransformer</span></code></a>, <a class="reference internal" href="darts.dataprocessing.pipeline.html#darts.dataprocessing.pipeline.Pipeline" title="darts.dataprocessing.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, a dictionary of <cite>BaseDataTransformer</cite> or <cite>Pipeline</cite> to apply to the corresponding series
(possibles keys; “series”, “past_covariates”, “future_covariates”). If provided, all input series must be
in the un-transformed space. For fittable transformer / pipeline:</p>
<ul>
<li><p>if <cite>retrain=True</cite>, the data transformer re-fit on the training data at each historical forecast step.</p></li>
<li><p>if <cite>retrain=False</cite>, the data transformer transforms the series once before all the forecasts.</p></li>
</ul>
<p>The fitted transformer is used to transform the input during both training and prediction.
If the transformation is invertible, the forecasts will be inverse-transformed.
Only effective when <cite>historical_forecasts=None</cite>.</p>
</p></li>
<li><p><strong>metric_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Additional arguments passed to <cite>metric()</cite>, such as <cite>‘n_jobs’</cite> for parallelization, <cite>‘component_reduction’</cite>
for reducing the component wise metrics, seasonality <cite>‘m’</cite> for scaled metrics, etc. Will pass arguments to
each metric separately and only if they are present in the corresponding metric signature. Parameter
<cite>‘insample’</cite> for scaled metrics (e.g. mase`, <cite>rmsse</cite>, …) is ignored, as it is handled internally.</p></li>
<li><p><strong>fit_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some additional arguments passed to the model <cite>fit()</cite> method.</p></li>
<li><p><strong>predict_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some additional arguments passed to the model <cite>predict()</cite> method.</p></li>
<li><p><strong>sample_weight</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some sample weights to apply to the target <cite>series</cite> labels for training. Only effective when
<cite>retrain</cite> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>. They are applied per observation, per label (each step in
<cite>output_chunk_length</cite>), and per component.
If a series or sequence of series, then those weights are used. If the weight series only have a single
component / column, then the weights are applied globally to all components in <cite>series</cite>. Otherwise, for
component-specific weights, the number of components must match those of <cite>series</cite>.
If a string, then the weights are generated using built-in weighting functions. The available options are
<cite>“linear”</cite> or <cite>“exponential”</cite> decay - the further in the past, the lower the weight. The weights are
computed per time <cite>series</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><em>float</em> – A single backtest score for single uni/multivariate series, a single <cite>metric</cite> function and:</p>
<ul>
<li><p><cite>historical_forecasts</cite> generated with <cite>last_points_only=True</cite></p></li>
<li><p><cite>historical_forecasts</cite> generated with <cite>last_points_only=False</cite> and using a backtest <cite>reduction</cite></p></li>
</ul>
</li>
<li><p><em>np.ndarray</em> – An numpy array of backtest scores. For single series and one of:</p>
<ul>
<li><p>a single <cite>metric</cite> function, <cite>historical_forecasts</cite> generated with <cite>last_points_only=False</cite>
and backtest <cite>reduction=None</cite>. The output has shape (n forecasts, <a href="#id5"><span class="problematic" id="id6">*</span></a>).</p></li>
<li><p>multiple <cite>metric</cite> functions and <cite>historical_forecasts</cite> generated with <cite>last_points_only=False</cite>.
The output has shape (<a href="#id7"><span class="problematic" id="id8">*</span></a>, n metrics) when using a backtest <cite>reduction</cite>, and (n forecasts, <a href="#id9"><span class="problematic" id="id10">*</span></a>, n metrics)
when <cite>reduction=None</cite></p></li>
<li><p>multiple uni/multivariate series including <cite>series_reduction</cite> and at least one of
<cite>component_reduction=None</cite> or <cite>time_reduction=None</cite> for “per time step metrics”</p></li>
</ul>
</li>
<li><p><em>List[float]</em> – Same as for type <cite>float</cite> but for a sequence of series. The returned metric list has length
<cite>len(series)</cite> with the <cite>float</cite> metric for each input <cite>series</cite>.</p></li>
<li><p><em>List[np.ndarray]</em> – Same as for type <cite>np.ndarray</cite> but for a sequence of series. The returned metric list has length
<cite>len(series)</cite> with the <cite>np.ndarray</cite> metrics for each input <cite>series</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.considers_static_covariates">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">considers_static_covariates</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.considers_static_covariates" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether the model considers static covariates, if there are any.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.epochs_trained">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">epochs_trained</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.epochs_trained" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.extreme_lags">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">extreme_lags</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.extreme_lags" title="Permalink to this definition">¶</a></dt>
<dd><p>A 8-tuple containing in order:
(min target lag, max target lag, min past covariate lag, max past covariate lag, min future covariate
lag, max future covariate lag, output shift, max target lag train (only for RNNModel)). If 0 is the index of the
first prediction, then all lags are relative to this index.</p>
<p>See examples below.</p>
<dl class="simple">
<dt>If the model wasn’t fitted with:</dt><dd><ul class="simple">
<li><p>target (concerning RegressionModels only): then the first element should be <cite>None</cite>.</p></li>
<li><p>past covariates: then the third and fourth elements should be <cite>None</cite>.</p></li>
<li><p>future covariates: then the fifth and sixth elements should be <cite>None</cite>.</p></li>
</ul>
</dd>
</dl>
<p>Should be overridden by models that use past or future covariates, and/or for model that have minimum target
lag and maximum target lags potentially different from -1 and 0.</p>
<p class="rubric">Notes</p>
<p>maximum target lag (second value) cannot be <cite>None</cite> and is always larger than or equal to 0.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionModel</span><span class="p">(</span><span class="n">lags</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_chunk_length</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_series</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">extreme_lags</span>
<span class="go">(-3, 1, None, None, None, None, 0, None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionModel</span><span class="p">(</span><span class="n">lags</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_chunk_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">output_chunk_shift</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_series</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">extreme_lags</span>
<span class="go">(-3, 1, None, None, None, None, 2, None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionModel</span><span class="p">(</span><span class="n">lags</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">],</span> <span class="n">lags_past_covariates</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">output_chunk_length</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_series</span><span class="p">,</span> <span class="n">past_covariates</span><span class="o">=</span><span class="n">past_covariates</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">extreme_lags</span>
<span class="go">(-5, 6, -4, -1,  None, None, 0, None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionModel</span><span class="p">(</span><span class="n">lags</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">lags_future_covariates</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">output_chunk_length</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_series</span><span class="p">,</span> <span class="n">future_covariates</span><span class="o">=</span><span class="n">future_covariates</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">extreme_lags</span>
<span class="go">(-5, 6, None, None, 4, 6, 0, None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">NBEATSModel</span><span class="p">(</span><span class="n">input_chunk_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">output_chunk_length</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_series</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">extreme_lags</span>
<span class="go">(-10, 6, None, None, None, None, 0, None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">NBEATSModel</span><span class="p">(</span><span class="n">input_chunk_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">output_chunk_length</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">lags_future_covariates</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_series</span><span class="p">,</span> <span class="n">future_covariates</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">extreme_lags</span>
<span class="go">(-10, 6, None, None, 4, 6, 0, None)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_series</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_past_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_future_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_samples_per_ts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit/train the model on one or multiple series.</p>
<p>This method wraps around <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.fit_from_dataset" title="darts.models.forecasting.tsmixer_model.TSMixerModel.fit_from_dataset"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit_from_dataset()</span></code></a>, constructing a default training
dataset for this model. If you need more control on how the series are sliced for training, consider
calling <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.fit_from_dataset" title="darts.models.forecasting.tsmixer_model.TSMixerModel.fit_from_dataset"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit_from_dataset()</span></code></a> with a custom <code class="xref py py-class docutils literal notranslate"><span class="pre">darts.utils.data.TrainingDataset</span></code>.</p>
<p>Training is performed with a PyTorch Lightning Trainer. It uses a default Trainer object from presets and
<code class="docutils literal notranslate"><span class="pre">pl_trainer_kwargs</span></code> used at model creation. You can also use a custom Trainer with optional parameter
<code class="docutils literal notranslate"><span class="pre">trainer</span></code>. For more information on PyTorch Lightning Trainers check out <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html">this link</a> .</p>
<p>This function can be called several times to do some extra training. If <code class="docutils literal notranslate"><span class="pre">epochs</span></code> is specified, the model
will be trained for some (extra) <code class="docutils literal notranslate"><span class="pre">epochs</span></code> epochs.</p>
<p>Below, all possible parameters are documented, but not all models support all parameters. For instance,
all the <code class="xref py py-class docutils literal notranslate"><span class="pre">PastCovariatesTorchModel</span></code> support only <code class="docutils literal notranslate"><span class="pre">past_covariates</span></code> and not <code class="docutils literal notranslate"><span class="pre">future_covariates</span></code>.
Darts will complain if you try fitting a model with the wrong covariates argument.</p>
<p>When handling covariates, Darts will try to use the time axes of the target and the covariates
to come up with the right time slices. So the covariates can be longer than needed; as long as the time axes
are correct Darts will handle them correctly. It will also complain if their time span is not sufficient.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]]) – A series or sequence of series serving as target (i.e. what the model will be trained to forecast)</p></li>
<li><p><strong>past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a series or sequence of series specifying past-observed covariates</p></li>
<li><p><strong>future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a series or sequence of series specifying future-known covariates</p></li>
<li><p><strong>val_series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, one or a sequence of validation target series, which will be used to compute the validation
loss throughout training and keep track of the best performing models.</p></li>
<li><p><strong>val_past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the past covariates corresponding to the validation series (must match <code class="docutils literal notranslate"><span class="pre">covariates</span></code>)</p></li>
<li><p><strong>val_future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the future covariates corresponding to the validation series (must match <code class="docutils literal notranslate"><span class="pre">covariates</span></code>)</p></li>
<li><p><strong>val_sample_weight</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Same as for <cite>sample_weight</cite> but for the evaluation dataset.</p></li>
<li><p><strong>trainer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a custom PyTorch-Lightning Trainer object to perform training. Using a custom <code class="docutils literal notranslate"><span class="pre">trainer</span></code> will
override Darts’ default trainer.</p></li>
<li><p><strong>verbose</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Whether to print the progress. Ignored if there is a <cite>ProgressBar</cite> callback in
<cite>pl_trainer_kwargs</cite>.</p></li>
<li><p><strong>epochs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – If specified, will train the model for <code class="docutils literal notranslate"><span class="pre">epochs</span></code> (additional) epochs, irrespective of what <code class="docutils literal notranslate"><span class="pre">n_epochs</span></code>
was provided to the model constructor.</p></li>
<li><p><strong>max_samples_per_ts</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a maximum number of samples to use per time series. Models are trained in a supervised fashion
by constructing slices of (input, output) examples. On long time series, this can result in unnecessarily
large number of training samples. This parameter upper-bounds the number of training samples per time
series (taking only the most recent samples in each series). Leaving to None does not apply any
upper bound.</p></li>
<li><p><strong>dataloader_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, a dictionary of keyword arguments used to create the PyTorch <cite>DataLoader</cite> instances for the
training and validation datasets. For more information on <cite>DataLoader</cite>, check out <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">this link</a>.
By default, Darts configures parameters (“batch_size”, “shuffle”, “drop_last”, “collate_fn”, “pin_memory”)
for seamless forecasting. Changing them should be done with care to avoid unexpected behavior.</p>
</p></li>
<li><p><strong>sample_weight</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some sample weights to apply to the target <cite>series</cite> labels. They are applied per observation,
per label (each step in <cite>output_chunk_length</cite>), and per component.
If a series or sequence of series, then those weights are used. If the weight series only have a single
component / column, then the weights are applied globally to all components in <cite>series</cite>. Otherwise, for
component-specific weights, the number of components must match those of <cite>series</cite>.
If a string, then the weights are generated using built-in weighting functions. The available options are
<cite>“linear”</cite> or <cite>“exponential”</cite> decay - the further in the past, the lower the weight. The weights are
computed globally based on the length of the longest series in <cite>series</cite>. Then for each series, the weights
are extracted from the end of the global weights. This gives a common time weighting across all series.</p></li>
<li><p><strong>val_sample_weight</strong> – Same as for <cite>sample_weight</cite> but for the evaluation dataset.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Fitted model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.fit_from_dataset">
<span class="sig-name descname"><span class="pre">fit_from_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.fit_from_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the model with a specific <code class="xref py py-class docutils literal notranslate"><span class="pre">darts.utils.data.TrainingDataset</span></code> instance.
These datasets implement a PyTorch <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>, and specify how the target and covariates are sliced
for training. If you are not sure which training dataset to use, consider calling <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.fit" title="darts.models.forecasting.tsmixer_model.TSMixerModel.fit"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit()</span></code></a> instead,
which will create a default training dataset appropriate for this model.</p>
<p>Training is performed with a PyTorch Lightning Trainer. It uses a default Trainer object from presets and
<code class="docutils literal notranslate"><span class="pre">pl_trainer_kwargs</span></code> used at model creation. You can also use a custom Trainer with optional parameter
<code class="docutils literal notranslate"><span class="pre">trainer</span></code>. For more information on PyTorch Lightning Trainers check out <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html">this link</a>.</p>
<p>This function can be called several times to do some extra training. If <code class="docutils literal notranslate"><span class="pre">epochs</span></code> is specified, the model
will be trained for some (extra) <code class="docutils literal notranslate"><span class="pre">epochs</span></code> epochs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> (<a class="reference internal" href="darts.utils.data.training_dataset.html#darts.utils.data.training_dataset.TrainingDataset" title="darts.utils.data.training_dataset.TrainingDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingDataset</span></code></a>) – A training dataset with a type matching this model (e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">PastCovariatesTrainingDataset</span></code> for
<code class="xref py py-class docutils literal notranslate"><span class="pre">PastCovariatesTorchModel</span></code>).</p></li>
<li><p><strong>val_dataset</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.utils.data.training_dataset.html#darts.utils.data.training_dataset.TrainingDataset" title="darts.utils.data.training_dataset.TrainingDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingDataset</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – A training dataset with a type matching this model (e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">PastCovariatesTrainingDataset</span></code> for
:class:<a href="#id13"><span class="problematic" id="id14">`</span></a>PastCovariatesTorchModel`s), representing the validation set (to track the validation loss).</p></li>
<li><p><strong>trainer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a custom PyTorch-Lightning Trainer object to perform prediction. Using a custom <cite>trainer</cite> will
override Darts’ default trainer.</p></li>
<li><p><strong>verbose</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Whether to print the progress. Ignored if there is a <cite>ProgressBar</cite> callback in
<cite>pl_trainer_kwargs</cite>.</p></li>
<li><p><strong>epochs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – If specified, will train the model for <code class="docutils literal notranslate"><span class="pre">epochs</span></code> (additional) epochs, irrespective of what <code class="docutils literal notranslate"><span class="pre">n_epochs</span></code>
was provided to the model constructor.</p></li>
<li><p><strong>dataloader_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, a dictionary of keyword arguments used to create the PyTorch <cite>DataLoader</cite> instances for the
training and validation datasets. For more information on <cite>DataLoader</cite>, check out <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">this link</a>.
By default, Darts configures parameters (“batch_size”, “shuffle”, “drop_last”, “collate_fn”, “pin_memory”)
for seamless forecasting. Changing them should be done with care to avoid unexpected behavior.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Fitted model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.generate_fit_encodings">
<span class="sig-name descname"><span class="pre">generate_fit_encodings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.generate_fit_encodings" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates the covariate encodings that were used/generated for fitting the model and returns a tuple of
past, and future covariates series with the original and encoded covariates stacked together. The encodings are
generated by the encoders defined at model creation with parameter <cite>add_encoders</cite>. Pass the same <cite>series</cite>,
<cite>past_covariates</cite>, and  <cite>future_covariates</cite> that you used to train/fit the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]]) – The series or sequence of series with the target values used when fitting the model.</p></li>
<li><p><strong>past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the series or sequence of series with the past-observed covariates used when fitting the model.</p></li>
<li><p><strong>future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the series or sequence of series with the future-known covariates used when fitting the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple of (past covariates, future covariates). Each covariate contains the original as well as the
encoded covariates.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Union[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>, Sequence[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>]], Union[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>, Sequence[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.generate_fit_predict_encodings">
<span class="sig-name descname"><span class="pre">generate_fit_predict_encodings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.generate_fit_predict_encodings" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates covariate encodings for training and inference/prediction and returns a tuple of past, and future
covariates series with the original and encoded covariates stacked together. The encodings are generated by the
encoders defined at model creation with parameter <cite>add_encoders</cite>. Pass the same <cite>series</cite>, <cite>past_covariates</cite>,
and <cite>future_covariates</cite> that you intend to use for training and prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of prediction time steps after the end of <cite>series</cite> intended to be used for prediction.</p></li>
<li><p><strong>series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]]) – The series or sequence of series with target values intended to be used for training and prediction.</p></li>
<li><p><strong>past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the past-observed covariates series intended to be used for training and prediction. The
dimensions must match those of the covariates used for training.</p></li>
<li><p><strong>future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the future-known covariates series intended to be used for prediction. The dimensions must
match those of the covariates used for training.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple of (past covariates, future covariates). Each covariate contains the original as well as the
encoded covariates.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Union[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>, Sequence[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>]], Union[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>, Sequence[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.generate_predict_encodings">
<span class="sig-name descname"><span class="pre">generate_predict_encodings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.generate_predict_encodings" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates covariate encodings for the inference/prediction set and returns a tuple of past, and future
covariates series with the original and encoded covariates stacked together. The encodings are generated by the
encoders defined at model creation with parameter <cite>add_encoders</cite>. Pass the same <cite>series</cite>, <cite>past_covariates</cite>,
and <cite>future_covariates</cite> that you intend to use for prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of prediction time steps after the end of <cite>series</cite> intended to be used for prediction.</p></li>
<li><p><strong>series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]]) – The series or sequence of series with target values intended to be used for prediction.</p></li>
<li><p><strong>past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the past-observed covariates series intended to be used for prediction. The dimensions must
match those of the covariates used for training.</p></li>
<li><p><strong>future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the future-known covariates series intended to be used for prediction. The dimensions must
match those of the covariates used for training.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple of (past covariates, future covariates). Each covariate contains the original as well as the
encoded covariates.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Union[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>, Sequence[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>]], Union[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>, Sequence[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.gridsearch">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">gridsearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_covariates=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_covariates=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forecast_horizon=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_format='value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_points_only=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_warnings=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_series=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_fitted_values=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric=&lt;function</span> <span class="pre">mape&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">mean&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_random_samples=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_transformers=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.gridsearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the best hyper-parameters among a given set using a grid search.</p>
<p>This function has 3 modes of operation: Expanding window mode, split mode and fitted value mode.
The three modes of operation evaluate every possible combination of hyper-parameter values
provided in the <cite>parameters</cite> dictionary by instantiating the <cite>model_class</cite> subclass
of ForecastingModel with each combination, and returning the best-performing model with regard
to the <cite>metric</cite> function. The <cite>metric</cite> function is expected to return an error value,
thus the model resulting in the smallest <cite>metric</cite> output will be chosen.</p>
<p>The relationship of the training data and test data depends on the mode of operation.</p>
<p>Expanding window mode (activated when <cite>forecast_horizon</cite> is passed):
For every hyperparameter combination, the model is repeatedly trained and evaluated on different
splits of <cite>series</cite>. This process is accomplished by using
the <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.backtest" title="darts.models.forecasting.tsmixer_model.TSMixerModel.backtest"><code class="xref py py-func docutils literal notranslate"><span class="pre">backtest()</span></code></a> function as a subroutine to produce historic forecasts starting from <cite>start</cite>
that are compared against the ground truth values of <cite>series</cite>.
Note that the model is retrained for every single prediction, thus this mode is slower.</p>
<p>Split window mode (activated when <cite>val_series</cite> is passed):
This mode will be used when the <cite>val_series</cite> argument is passed.
For every hyper-parameter combination, the model is trained on <cite>series</cite> and
evaluated on <cite>val_series</cite>.</p>
<p>Fitted value mode (activated when <cite>use_fitted_values</cite> is set to <cite>True</cite>):
For every hyper-parameter combination, the model is trained on <cite>series</cite>
and evaluated on the resulting fitted values.
Not all models have fitted values, and this method raises an error if the model doesn’t have a <cite>fitted_values</cite>
member. The fitted values are the result of the fit of the model on <cite>series</cite>. Comparing with the
fitted values can be a quick way to assess the model, but one cannot see if the model is overfitting the series.</p>
<p>Derived classes must ensure that a single instance of a model will not share parameters with the other
instances, e.g., saving models in the same path. Otherwise, an unexpected behavior can arise while running
several models in parallel (when <code class="docutils literal notranslate"><span class="pre">n_jobs</span> <span class="pre">!=</span> <span class="pre">1</span></code>). If this cannot be avoided, then gridsearch
should be redefined, forcing <code class="docutils literal notranslate"><span class="pre">n_jobs</span> <span class="pre">=</span> <span class="pre">1</span></code>.</p>
<p>Currently this method only supports deterministic predictions (i.e. when models’ predictions
have only 1 sample).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_class</strong> – The ForecastingModel subclass to be tuned for ‘series’.</p></li>
<li><p><strong>parameters</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>) – A dictionary containing as keys hyperparameter names, and as values lists of values for the
respective hyperparameter.</p></li>
<li><p><strong>series</strong> (<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>) – The target series used as input and target for training.</p></li>
<li><p><strong>past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a past-observed covariate series. This applies only if the model supports past covariates.</p></li>
<li><p><strong>future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a future-known covariate series. This applies only if the model supports future covariates.</p></li>
<li><p><strong>forecast_horizon</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The integer value of the forecasting horizon. Activates expanding window mode.</p></li>
<li><p><strong>stride</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Only used in expanding window mode. The number of time steps between two consecutive predictions.</p></li>
<li><p><strong>start</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Timestamp</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Only used in expanding window mode. Optionally, the first point in time at which a prediction is computed.
This parameter supports: <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas.Timestamp</span></code>, and <code class="docutils literal notranslate"><span class="pre">None</span></code>.
If a <code class="docutils literal notranslate"><span class="pre">float</span></code>, it is the proportion of the time series that should lie before the first prediction point.
If an <code class="docutils literal notranslate"><span class="pre">int</span></code>, it is either the index position of the first prediction point for <cite>series</cite> with a
<cite>pd.DatetimeIndex</cite>, or the index value for <cite>series</cite> with a <cite>pd.RangeIndex</cite>. The latter can be changed to
the index position with <cite>start_format=”position”</cite>.
If a <code class="docutils literal notranslate"><span class="pre">pandas.Timestamp</span></code>, it is the time stamp of the first prediction point.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the first prediction point will automatically be set to:</p>
<ul>
<li><p>the first predictable point if <cite>retrain</cite> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, or <cite>retrain</cite> is a Callable and the first
predictable point is earlier than the first trainable point.</p></li>
<li><p>the first trainable point if <cite>retrain</cite> is <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">int</span></code> (given <cite>train_length</cite>),
or <cite>retrain</cite> is a Callable and the first trainable point is earlier than the first predictable point.</p></li>
<li><p>the first trainable point (given <cite>train_length</cite>) otherwise</p></li>
</ul>
<dl class="simple">
<dt>Note: If <cite>start</cite> is not within the trainable / forecastable points, uses the closest valid start point that</dt><dd><p>is a round multiple of <cite>stride</cite> ahead of <cite>start</cite>. Raises a <cite>ValueError</cite>, if no valid start point exists.</p>
</dd>
<dt>Note: If the model uses a shifted output (<cite>output_chunk_shift &gt; 0</cite>), then the first predicted point is also</dt><dd><p>shifted by <cite>output_chunk_shift</cite> points into the future.</p>
</dd>
<dt>Note: If <cite>start</cite> is outside the possible historical forecasting times, will ignore the parameter</dt><dd><p>(default behavior with <code class="docutils literal notranslate"><span class="pre">None</span></code>) and start at the first trainable/predictable point.</p>
</dd>
</dl>
</p></li>
<li><p><strong>start_format</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[‘position’, ‘value’]) – Only used in expanding window mode. Defines the <cite>start</cite> format. Only effective when <cite>start</cite> is an integer
and <cite>series</cite> is indexed with a <cite>pd.RangeIndex</cite>.
If set to ‘position’, <cite>start</cite> corresponds to the index position of the first predicted point and can range
from <cite>(-len(series), len(series) - 1)</cite>.
If set to ‘value’, <cite>start</cite> corresponds to the index value/label of the first predicted point. Will raise
an error if the value is not in <cite>series</cite>’ index. Default: <code class="docutils literal notranslate"><span class="pre">'value'</span></code></p></li>
<li><p><strong>last_points_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Only used in expanding window mode. Whether to use the whole forecasts or only the last point of each
forecast to compute the error.</p></li>
<li><p><strong>show_warnings</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Only used in expanding window mode. Whether to show warnings related to the <cite>start</cite> parameter.</p></li>
<li><p><strong>val_series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The TimeSeries instance used for validation in split mode. If provided, this series must start right after
the end of <cite>series</cite>; so that a proper comparison of the forecast can be made.</p></li>
<li><p><strong>use_fitted_values</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If <cite>True</cite>, uses the comparison with the fitted values.
Raises an error if <code class="docutils literal notranslate"><span class="pre">fitted_values</span></code> is not an attribute of <cite>model_class</cite>.</p></li>
<li><p><strong>metric</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]) – <p>A metric function that returns the error between two <cite>TimeSeries</cite> as a float value . Must either be one of
Darts’ “aggregated over time” metrics (see <a class="reference external" href="https://unit8co.github.io/darts/generated_api/darts.metrics.html">here</a>), or a custom metric that as input two
<cite>TimeSeries</cite> and returns the error</p>
</p></li>
<li><p><strong>reduction</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]) – A reduction function (mapping array to float) describing how to aggregate the errors obtained
on the different validation series when backtesting. By default it’ll compute the mean of errors.</p></li>
<li><p><strong>verbose</strong> – Whether to print the progress.</p></li>
<li><p><strong>n_jobs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of jobs to run in parallel. Parallel jobs are created only when there are two or more parameters
combinations to evaluate. Each job will instantiate, train, and evaluate a different instance of the model.
Defaults to <cite>1</cite> (sequential). Setting the parameter to <cite>-1</cite> means using all the available cores.</p></li>
<li><p><strong>n_random_samples</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The number/ratio of hyperparameter combinations to select from the full parameter grid. This will perform
a random search instead of using the full grid.
If an integer, <cite>n_random_samples</cite> is the number of parameter combinations selected from the full grid and
must be between <cite>0</cite> and the total number of parameter combinations.
If a float, <cite>n_random_samples</cite> is the ratio of parameter combinations selected from the full grid and must
be between <cite>0</cite> and <cite>1</cite>. Defaults to <cite>None</cite>, for which random selection will be ignored.</p></li>
<li><p><strong>data_transformers</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.dataprocessing.transformers.base_data_transformer.html#darts.dataprocessing.transformers.base_data_transformer.BaseDataTransformer" title="darts.dataprocessing.transformers.base_data_transformer.BaseDataTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseDataTransformer</span></code></a>, <a class="reference internal" href="darts.dataprocessing.pipeline.html#darts.dataprocessing.pipeline.Pipeline" title="darts.dataprocessing.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, a dictionary of <cite>BaseDataTransformer</cite> or <cite>Pipeline</cite> to apply to the corresponding series
(possibles keys; “series”, “past_covariates”, “future_covariates”). If provided, all input series must be
in the un-transformed space. For fittable transformer / pipeline:</p>
<ul>
<li><p>if <cite>retrain=True</cite>, the data transformer re-fit on the training data at each historical forecast step.</p></li>
<li><p>if <cite>retrain=False</cite>, the data transformer transforms the series once before all the forecasts.</p></li>
</ul>
<p>The fitted transformer is used to transform the input during both training and prediction.
If the transformation is invertible, the forecasts will be inverse-transformed.</p>
</p></li>
<li><p><strong>fit_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Additional arguments passed to the model <cite>fit()</cite> method.</p></li>
<li><p><strong>predict_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Additional arguments passed to the model <cite>predict()</cite> method.</p></li>
<li><p><strong>sample_weight</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some sample weights to apply to the target <cite>series</cite> labels for training. Only effective when
<cite>retrain</cite> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>. They are applied per observation, per label (each step in
<cite>output_chunk_length</cite>), and per component.
If a series, then those weights are used. If the weight series only have a single component / column, then
the weights are applied globally to all components in <cite>series</cite>. Otherwise, for component-specific weights,
the number of components must match those of <cite>series</cite>.
If a string, then the weights are generated using built-in weighting functions. The available options are
<cite>“linear”</cite> or <cite>“exponential”</cite> decay - the further in the past, the lower the weight.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple containing an untrained <cite>model_class</cite> instance created from the best-performing hyper-parameters,
along with a dictionary containing these best hyper-parameters,
and metric score for the best hyper-parameters.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="darts.models.forecasting.forecasting_model.html#darts.models.forecasting.forecasting_model.ForecastingModel" title="darts.models.forecasting.forecasting_model.ForecastingModel">ForecastingModel</a>, Dict, float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.historical_forecasts">
<span class="sig-name descname"><span class="pre">historical_forecasts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forecast_horizon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overlap_end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_points_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_warnings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_optimization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_transformers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.historical_forecasts" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates historical forecasts by simulating predictions at various points in time throughout the history of
the provided (potentially multiple) <cite>series</cite>. This process involves retrospectively applying the model to
different time steps, as if the forecasts were made in real-time at those specific moments. This allows for an
evaluation of the model’s performance over the entire duration of the series, providing insights into its
predictive accuracy and robustness across different historical periods.</p>
<p>There are two main modes for this method:</p>
<ul class="simple">
<li><p>Re-training Mode (Default, <cite>retrain=True</cite>): The model is re-trained at each step of the simulation, and
generates a forecast using the updated model. In case of multiple series, the model is re-trained on each
series independently (global training is not yet supported).</p></li>
<li><p>Pre-trained Mode (<cite>retrain=False</cite>): The forecasts are generated at each step of the simulation without
re-training. It is only supported for pre-trained global forecasting models. This mode is significantly
faster as it skips the re-training step.</p></li>
</ul>
<p>By choosing the appropriate mode, you can balance between computational efficiency and the need for up-to-date
model training.</p>
<p><strong>Re-training Mode:</strong> This mode repeatedly builds a training set by either expanding from the beginning of
the <cite>series</cite> or by using a fixed-length <cite>train_length</cite> (the start point can also be configured with <cite>start</cite>
and <cite>start_format</cite>). The model is then trained on this training set, and a forecast of length <cite>forecast_horizon</cite>
is generated. Subsequently, the end of the training set is moved forward by <cite>stride</cite> time steps, and the process
is repeated.</p>
<p><strong>Pre-trained Mode:</strong> This mode is only supported for pre-trained global forecasting models. It uses the same
simulation steps as in the <em>Re-training Mode</em> (ignoring <cite>train_length</cite>), but generates the forecasts directly
without re-training.</p>
<p>By default, with <cite>last_points_only=True</cite>, this method returns a single time series (or a sequence of time
series) composed of the last point from each historical forecast. This time series will thus have a frequency of
<cite>series.freq * stride</cite>.
If <cite>last_points_only=False</cite>, it will instead return a list (or a sequence of lists) of the full historical
forecast series each with frequency <cite>series.freq</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]]) – A (sequence of) target time series used to successively train (if <cite>retrain</cite> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>) and compute
the historical forecasts.</p></li>
<li><p><strong>past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a (sequence of) past-observed covariate time series for every input time series in <cite>series</cite>.
This applies only if the model supports past covariates.</p></li>
<li><p><strong>future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a (sequence of) future-known covariate time series for every input time series in <cite>series</cite>.
This applies only if the model supports future covariates.</p></li>
<li><p><strong>forecast_horizon</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The forecast horizon for the predictions.</p></li>
<li><p><strong>num_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of times a prediction is sampled from a probabilistic model. Use values <code class="docutils literal notranslate"><span class="pre">&gt;1</span></code> only for probabilistic
models.</p></li>
<li><p><strong>train_length</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, use a fixed length / number of time steps for every constructed training set (rolling window
mode). Only effective when <cite>retrain</cite> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>. The default is <code class="docutils literal notranslate"><span class="pre">None</span></code>, where it uses all time
steps up until the prediction time (expanding window mode). If larger than the number of available time
steps, uses the expanding mode. Needs to be at least <cite>min_train_series_length</cite>.</p></li>
<li><p><strong>start</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Timestamp</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, the first point in time at which a prediction is computed. This parameter supports:
<code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas.Timestamp</span></code>, and <code class="docutils literal notranslate"><span class="pre">None</span></code>.
If a <code class="docutils literal notranslate"><span class="pre">float</span></code>, it is the proportion of the time series that should lie before the first prediction point.
If an <code class="docutils literal notranslate"><span class="pre">int</span></code>, it is either the index position of the first prediction point for <cite>series</cite> with a
<cite>pd.DatetimeIndex</cite>, or the index value for <cite>series</cite> with a <cite>pd.RangeIndex</cite>. The latter can be changed to
the index position with <cite>start_format=”position”</cite>.
If a <code class="docutils literal notranslate"><span class="pre">pandas.Timestamp</span></code>, it is the time stamp of the first prediction point.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the first prediction point will automatically be set to:</p>
<ul>
<li><p>the first predictable point if <cite>retrain</cite> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, or <cite>retrain</cite> is a Callable and the first
predictable point is earlier than the first trainable point.</p></li>
<li><p>the first trainable point if <cite>retrain</cite> is <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">int</span></code> (given <cite>train_length</cite>),
or <cite>retrain</cite> is a <code class="docutils literal notranslate"><span class="pre">Callable</span></code> and the first trainable point is earlier than the first predictable point.</p></li>
<li><p>the first trainable point (given <cite>train_length</cite>) otherwise</p></li>
</ul>
<dl class="simple">
<dt>Note: If <cite>start</cite> is not within the trainable / forecastable points, uses the closest valid start point that</dt><dd><p>is a round multiple of <cite>stride</cite> ahead of <cite>start</cite>. Raises a <cite>ValueError</cite>, if no valid start point exists.</p>
</dd>
<dt>Note: If the model uses a shifted output (<cite>output_chunk_shift &gt; 0</cite>), then the first predicted point is also</dt><dd><p>shifted by <cite>output_chunk_shift</cite> points into the future.</p>
</dd>
<dt>Note: If <cite>start</cite> is outside the possible historical forecasting times, will ignore the parameter</dt><dd><p>(default behavior with <code class="docutils literal notranslate"><span class="pre">None</span></code>) and start at the first trainable/predictable point.</p>
</dd>
</dl>
</p></li>
<li><p><strong>start_format</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[‘position’, ‘value’]) – Defines the <cite>start</cite> format.
If set to <code class="docutils literal notranslate"><span class="pre">'position'</span></code>, <cite>start</cite> corresponds to the index position of the first predicted point and can
range from <cite>(-len(series), len(series) - 1)</cite>.
If set to <code class="docutils literal notranslate"><span class="pre">'value'</span></code>, <cite>start</cite> corresponds to the index value/label of the first predicted point. Will raise
an error if the value is not in <cite>series</cite>’ index. Default: <code class="docutils literal notranslate"><span class="pre">'value'</span></code>.</p></li>
<li><p><strong>stride</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of time steps between two consecutive predictions.</p></li>
<li><p><strong>retrain</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[…, <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]]) – <p>Whether and/or on which condition to retrain the model before predicting.
This parameter supports 3 different types: <code class="docutils literal notranslate"><span class="pre">bool</span></code>, (positive) <code class="docutils literal notranslate"><span class="pre">int</span></code>, and <code class="docutils literal notranslate"><span class="pre">Callable</span></code> (returning a
<code class="docutils literal notranslate"><span class="pre">bool</span></code>).
In the case of <code class="docutils literal notranslate"><span class="pre">bool</span></code>: retrain the model at each step (<cite>True</cite>), or never retrain the model (<cite>False</cite>).
In the case of <code class="docutils literal notranslate"><span class="pre">int</span></code>: the model is retrained every <cite>retrain</cite> iterations.
In the case of <code class="docutils literal notranslate"><span class="pre">Callable</span></code>: the model is retrained whenever callable returns <cite>True</cite>.
The callable must have the following positional arguments:</p>
<ul>
<li><p><cite>counter</cite> (int): current <cite>retrain</cite> iteration</p></li>
<li><p><cite>pred_time</cite> (pd.Timestamp or int): timestamp of forecast time (end of the training series)</p></li>
<li><p><cite>train_series</cite> (TimeSeries): train series up to <cite>pred_time</cite></p></li>
<li><p><cite>past_covariates</cite> (TimeSeries): past_covariates series up to <cite>pred_time</cite></p></li>
<li><p><cite>future_covariates</cite> (TimeSeries): future_covariates series up to <cite>min(pred_time + series.freq *
forecast_horizon, series.end_time())</cite></p></li>
</ul>
<p>Note: if any optional <cite>*_covariates</cite> are not passed to <cite>historical_forecast</cite>, <code class="docutils literal notranslate"><span class="pre">None</span></code> will be passed
to the corresponding retrain function argument.
Note: some models require being retrained every time and do not support anything other than
<cite>retrain=True</cite>.
Note: also controls the retraining of the <cite>data_transformers</cite>.</p>
</p></li>
<li><p><strong>overlap_end</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the returned forecasts can go beyond the series’ end or not.</p></li>
<li><p><strong>last_points_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return only the last point of each historical forecast. If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the method returns a
single <code class="docutils literal notranslate"><span class="pre">TimeSeries</span></code> (for each time series in <cite>series</cite>) containing the successive point forecasts.
Otherwise, returns a list of historical <code class="docutils literal notranslate"><span class="pre">TimeSeries</span></code> forecasts.</p></li>
<li><p><strong>verbose</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to print the progress.</p></li>
<li><p><strong>show_warnings</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to show warnings related to historical forecasts optimization, or parameters <cite>start</cite> and
<cite>train_length</cite>.</p></li>
<li><p><strong>predict_likelihood_parameters</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set to <cite>True</cite>, the model predicts the parameters of its <cite>likelihood</cite> instead of the target. Only
supported for probabilistic models with a likelihood, <cite>num_samples = 1</cite> and <cite>n&lt;=output_chunk_length</cite>.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>enable_optimization</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to use the optimized version of <cite>historical_forecasts</cite> when supported and available.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>data_transformers</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.dataprocessing.transformers.base_data_transformer.html#darts.dataprocessing.transformers.base_data_transformer.BaseDataTransformer" title="darts.dataprocessing.transformers.base_data_transformer.BaseDataTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseDataTransformer</span></code></a>, <a class="reference internal" href="darts.dataprocessing.pipeline.html#darts.dataprocessing.pipeline.Pipeline" title="darts.dataprocessing.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, a dictionary of <cite>BaseDataTransformer</cite> or <cite>Pipeline</cite> to apply to the corresponding series
(possibles keys; “series”, “past_covariates”, “future_covariates”). If provided, all input series must be
in the un-transformed space. For fittable transformer / pipeline:</p>
<ul>
<li><p>if <cite>retrain=True</cite>, the data transformer re-fit on the training data at each historical forecast step.</p></li>
<li><p>if <cite>retrain=False</cite>, the data transformer transforms the series once before all the forecasts.</p></li>
</ul>
<p>The fitted transformer is used to transform the input during both training and prediction.
If the transformation is invertible, the forecasts will be inverse-transformed.</p>
</p></li>
<li><p><strong>fit_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some additional arguments passed to the model <cite>fit()</cite> method.</p></li>
<li><p><strong>predict_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some additional arguments passed to the model <cite>predict()</cite> method.</p></li>
<li><p><strong>sample_weight</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some sample weights to apply to the target <cite>series</cite> labels for training. Only effective when
<cite>retrain</cite> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>. They are applied per observation, per label (each step in
<cite>output_chunk_length</cite>), and per component.
If a series or sequence of series, then those weights are used. If the weight series only have a single
component / column, then the weights are applied globally to all components in <cite>series</cite>. Otherwise, for
component-specific weights, the number of components must match those of <cite>series</cite>.
If a string, then the weights are generated using built-in weighting functions. The available options are
<cite>“linear”</cite> or <cite>“exponential”</cite> decay - the further in the past, the lower the weight. The weights are
computed per time <cite>series</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><em>TimeSeries</em> – A single historical forecast for a single <cite>series</cite> and <cite>last_points_only=True</cite>: it contains only the
predictions at step <cite>forecast_horizon</cite> from all historical forecasts.</p></li>
<li><p><em>List[TimeSeries]</em> – A list of historical forecasts for:</p>
<ul>
<li><p>a sequence (list) of <cite>series</cite> and <cite>last_points_only=True</cite>: for each series, it contains only the
predictions at step <cite>forecast_horizon</cite> from all historical forecasts.</p></li>
<li><p>a single <cite>series</cite> and <cite>last_points_only=False</cite>: for each historical forecast, it contains the entire
horizon <cite>forecast_horizon</cite>.</p></li>
</ul>
</li>
<li><p><em>List[List[TimeSeries]]</em> – A list of lists of historical forecasts for a sequence of <cite>series</cite> and <cite>last_points_only=False</cite>. For each
series, and historical forecast, it contains the entire horizon <cite>forecast_horizon</cite>. The outer list
is over the series provided in the input sequence, and the inner lists contain the historical forecasts for
each series.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.input_chunk_length">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_chunk_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.input_chunk_length" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.likelihood">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">likelihood</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><span class="pre">Likelihood</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.likelihood" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="darts.utils.likelihood_models.html#darts.utils.likelihood_models.Likelihood" title="darts.utils.likelihood_models.Likelihood"><code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.load">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pl_trainer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads a model from a given file path.</p>
<p>Example for loading a general save from <code class="xref py py-class docutils literal notranslate"><span class="pre">RNNModel</span></code>:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">darts.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">RNNModel</span>

<span class="n">model_loaded</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>Example for loading an <code class="xref py py-class docutils literal notranslate"><span class="pre">RNNModel</span></code> to GPU:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">darts.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">RNNModel</span>

<span class="n">model_loaded</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">pl_trainer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;accelerator&quot;</span><span class="p">:</span> <span class="s2">&quot;gpu&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Path from which to load the model. If no path was specified when saving the model, the automatically
generated path ending with “.pt” has to be provided.</p></li>
<li><p><strong>pl_trainer_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a set of kwargs to create a new Lightning Trainer used to configure the model for downstream
tasks (e.g. prediction).
Some examples include specifying the batch size or moving the model to CPU/GPU(s). Check the
<a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html">Lightning Trainer documentation</a>
for more information about the supported kwargs.</p></li>
<li><p><strong>**kwargs</strong> – Additional kwargs for PyTorch Lightning’s <code class="xref py py-func docutils literal notranslate"><span class="pre">LightningModule.load_from_checkpoint()</span></code> method,
For more information, read the <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#load-from-checkpoint">official documentation</a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchForecastingModel</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.load_from_checkpoint">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">work_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load_from_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the model from automatically saved checkpoints under ‘{work_dir}/darts_logs/{model_name}/checkpoints/’.
This method is used for models that were created with <code class="docutils literal notranslate"><span class="pre">save_checkpoints=True</span></code>.</p>
<p>If you manually saved your model, consider using <code class="xref py py-meth docutils literal notranslate"><span class="pre">load()</span></code>.</p>
<p>Example for loading a <code class="xref py py-class docutils literal notranslate"><span class="pre">RNNModel</span></code> from checkpoint (<code class="docutils literal notranslate"><span class="pre">model_name</span></code> is the <code class="docutils literal notranslate"><span class="pre">model_name</span></code> used at model
creation):</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">darts.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">RNNModel</span>

<span class="n">model_loaded</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">best</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>If <code class="docutils literal notranslate"><span class="pre">file_name</span></code> is given, returns the model saved under
‘{work_dir}/darts_logs/{model_name}/checkpoints/{file_name}’.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">file_name</span></code> is not given, will try to restore the best checkpoint (if <code class="docutils literal notranslate"><span class="pre">best</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>) or the most
recent checkpoint (if <code class="docutils literal notranslate"><span class="pre">best</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> from ‘{work_dir}/darts_logs/{model_name}/checkpoints/’.</p>
<p>Example for loading an <code class="xref py py-class docutils literal notranslate"><span class="pre">RNNModel</span></code> checkpoint to CPU that was saved on GPU:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">darts.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">RNNModel</span>

<span class="n">model_loaded</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">best</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model_loaded</span><span class="o">.</span><span class="n">to_cpu</span><span class="p">()</span>
</pre></div>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The name of the model, used to retrieve the checkpoints folder’s name.</p></li>
<li><p><strong>work_dir</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Working directory (containing the checkpoints folder). Defaults to current working directory.</p></li>
<li><p><strong>file_name</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The name of the checkpoint file. If not specified, use the most recent one.</p></li>
<li><p><strong>best</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set, will retrieve the best model (according to validation loss) instead of the most recent one. Only
is ignored when <code class="docutils literal notranslate"><span class="pre">file_name</span></code> is given.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional kwargs for PyTorch Lightning’s <code class="xref py py-func docutils literal notranslate"><span class="pre">LightningModule.load_from_checkpoint()</span></code> method,
such as <code class="docutils literal notranslate"><span class="pre">map_location</span></code> to load the model onto a different device than the one from which it was saved.
For more information, read the <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#load-from-checkpoint">official documentation</a>.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The corresponding trained <code class="xref py py-class docutils literal notranslate"><span class="pre">TorchForecastingModel</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>TorchForecastingModel</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.load_weights">
<span class="sig-name descname"><span class="pre">load_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_encoders</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_checks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads the weights from a manually saved model (saved with <code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code>).</p>
<p>Note: This method needs to be able to access the darts model checkpoint (.pt) in order to load the encoders
and perform sanity checks on the model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Path from which to load the model’s weights. If no path was specified when saving the model, the
automatically generated path ending with “.pt” has to be provided.</p></li>
<li><p><strong>load_encoders</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set, will load the encoders from the model to enable direct call of fit() or predict().
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>skip_checks</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set, will disable the loading of the encoders and the sanity checks on model parameters
(not recommended). Cannot be used with <cite>load_encoders=True</cite>. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional kwargs for PyTorch’s <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load" title="darts.models.forecasting.tsmixer_model.TSMixerModel.load"><code class="xref py py-func docutils literal notranslate"><span class="pre">load()</span></code></a> method, such as <code class="docutils literal notranslate"><span class="pre">map_location</span></code> to load the model onto a
different device than the one from which it was saved.
For more information, read the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.load.html">official documentation</a>.</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.load_weights_from_checkpoint">
<span class="sig-name descname"><span class="pre">load_weights_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">work_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_encoders</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_checks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load_weights_from_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Load only the weights from automatically saved checkpoints under ‘{work_dir}/darts_logs/{model_name}/
checkpoints/’. This method is used for models that were created with <code class="docutils literal notranslate"><span class="pre">save_checkpoints=True</span></code> and
that need to be re-trained or fine-tuned with different optimizer or learning rate scheduler. However,
it can also be used to load weights for inference.</p>
<p>To resume an interrupted training, please consider using <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_from_checkpoint()</span></code> which also reload the trainer, optimizer and
learning rate scheduler states.</p>
<p>For manually saved model, consider using <code class="xref py py-meth docutils literal notranslate"><span class="pre">load()</span></code> or
<code class="xref py py-meth docutils literal notranslate"><span class="pre">load_weights()</span></code> instead.</p>
<p>Note: This method needs to be able to access the darts model checkpoint (.pt) in order to load the encoders
and perform sanity checks on the model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The name of the model, used to retrieve the checkpoints folder’s name. Default: <code class="docutils literal notranslate"><span class="pre">self.model_name</span></code>.</p></li>
<li><p><strong>work_dir</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Working directory (containing the checkpoints folder). Defaults to current working directory.</p></li>
<li><p><strong>file_name</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – The name of the checkpoint file. If not specified, use the most recent one.</p></li>
<li><p><strong>best</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set, will retrieve the best model (according to validation loss) instead of the most recent one. Only
is ignored when <code class="docutils literal notranslate"><span class="pre">file_name</span></code> is given. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>strict</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – <p>If set, strictly enforce that the keys in state_dict match the keys returned by this module’s state_dict().
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.
For more information, read the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=load_state_dict#torch.nn.Module.load_state_dict">official documentation</a>.</p>
</p></li>
<li><p><strong>load_encoders</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set, will load the encoders from the model to enable direct call of fit() or predict().
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>skip_checks</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set, will disable the loading of the encoders and the sanity checks on model parameters
(not recommended). Cannot be used with <cite>load_encoders=True</cite>. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional kwargs for PyTorch’s <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.load" title="darts.models.forecasting.tsmixer_model.TSMixerModel.load"><code class="xref py py-func docutils literal notranslate"><span class="pre">load()</span></code></a> method, such as <code class="docutils literal notranslate"><span class="pre">map_location</span></code> to load the model onto a
different device than the one from which it was saved.
For more information, read the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.load.html">official documentation</a>.</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.lr_find">
<span class="sig-name descname"><span class="pre">lr_find</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_series</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_past_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_future_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_samples_per_ts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'exponential'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stop_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.lr_find" title="Permalink to this definition">¶</a></dt>
<dd><p>A wrapper around PyTorch Lightning’s <cite>Tuner.lr_find()</cite>. Performs a range test of good initial learning rates,
to reduce the amount of guesswork in picking a good starting learning rate. For more information on PyTorch
Lightning’s Tuner check out
<a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.tuner.tuning.Tuner.html">this link</a>.
It is recommended to increase the number of <cite>epochs</cite> if the tuner did not give satisfactory results.
Consider creating a new model object with the suggested learning rate for example using model creation
parameters <cite>optimizer_cls</cite>, <cite>optimizer_kwargs</cite>, <cite>lr_scheduler_cls</cite>, and <cite>lr_scheduler_kwargs</cite>.</p>
<p>Example using a <code class="xref py py-class docutils literal notranslate"><span class="pre">RNNModel</span></code>:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">AirPassengersDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">NBEATSModel</span>

<span class="n">series</span> <span class="o">=</span> <span class="n">AirPassengersDataset</span><span class="p">()</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">train</span><span class="p">,</span> <span class="n">val</span> <span class="o">=</span> <span class="n">series</span><span class="p">[:</span><span class="o">-</span><span class="mi">18</span><span class="p">],</span> <span class="n">series</span><span class="p">[</span><span class="o">-</span><span class="mi">18</span><span class="p">:]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NBEATSModel</span><span class="p">(</span><span class="n">input_chunk_length</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">output_chunk_length</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># run the learning rate tuner</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">series</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">val_series</span><span class="o">=</span><span class="n">val</span><span class="p">)</span>
<span class="c1"># plot the results</span>
<span class="n">results</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">suggest</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># create a new model with the suggested learning rate</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NBEATSModel</span><span class="p">(</span>
    <span class="n">input_chunk_length</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">output_chunk_length</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">optimizer_cls</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
    <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">suggestion</span><span class="p">()}</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]]) – A series or sequence of series serving as target (i.e. what the model will be trained to forecast)</p></li>
<li><p><strong>past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a series or sequence of series specifying past-observed covariates</p></li>
<li><p><strong>future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a series or sequence of series specifying future-known covariates</p></li>
<li><p><strong>val_series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, one or a sequence of validation target series, which will be used to compute the validation
loss throughout training and keep track of the best performing models.</p></li>
<li><p><strong>val_past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the past covariates corresponding to the validation series (must match <code class="docutils literal notranslate"><span class="pre">covariates</span></code>)</p></li>
<li><p><strong>val_future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the future covariates corresponding to the validation series (must match <code class="docutils literal notranslate"><span class="pre">covariates</span></code>)</p></li>
<li><p><strong>sample_weight</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some sample weights to apply to the target <cite>series</cite> labels. They are applied per observation,
per label (each step in <cite>output_chunk_length</cite>), and per component.
If a series or sequence of series, then those weights are used. If the weight series only have a single
component / column, then the weights are applied globally to all components in <cite>series</cite>. Otherwise, for
component-specific weights, the number of components must match those of <cite>series</cite>.
If a string, then the weights are generated using built-in weighting functions. The available options are
<cite>“linear”</cite> or <cite>“exponential”</cite> decay - the further in the past, the lower the weight. The weights are
computed globally based on the length of the longest series in <cite>series</cite>. Then for each series, the weights
are extracted from the end of the global weights. This gives a common time weighting across all series.</p></li>
<li><p><strong>val_sample_weight</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Same as for <cite>sample_weight</cite> but for the evaluation dataset.</p></li>
<li><p><strong>trainer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a custom PyTorch-Lightning Trainer object to perform training. Using a custom <code class="docutils literal notranslate"><span class="pre">trainer</span></code> will
override Darts’ default trainer.</p></li>
<li><p><strong>verbose</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Whether to print the progress. Ignored if there is a <cite>ProgressBar</cite> callback in
<cite>pl_trainer_kwargs</cite>.</p></li>
<li><p><strong>epochs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – If specified, will train the model for <code class="docutils literal notranslate"><span class="pre">epochs</span></code> (additional) epochs, irrespective of what <code class="docutils literal notranslate"><span class="pre">n_epochs</span></code>
was provided to the model constructor.</p></li>
<li><p><strong>max_samples_per_ts</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a maximum number of samples to use per time series. Models are trained in a supervised fashion
by constructing slices of (input, output) examples. On long time series, this can result in unnecessarily
large number of training samples. This parameter upper-bounds the number of training samples per time
series (taking only the most recent samples in each series). Leaving to None does not apply any
upper bound.</p></li>
<li><p><strong>dataloader_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, a dictionary of keyword arguments used to create the PyTorch <cite>DataLoader</cite> instances for the
training and validation datasets. For more information on <cite>DataLoader</cite>, check out <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">this link</a>.
By default, Darts configures parameters (“batch_size”, “shuffle”, “drop_last”, “collate_fn”, “pin_memory”)
for seamless forecasting. Changing them should be done with care to avoid unexpected behavior.</p>
</p></li>
<li><p><strong>min_lr</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – minimum learning rate to investigate</p></li>
<li><p><strong>max_lr</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – maximum learning rate to investigate</p></li>
<li><p><strong>num_training</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of learning rates to test</p></li>
<li><p><strong>mode</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Search strategy to update learning rate after each batch:
‘exponential’: Increases the learning rate exponentially.
‘linear’: Increases the learning rate linearly.</p></li>
<li><p><strong>early_stop_threshold</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Threshold for stopping the search. If the loss at any point is larger
than early_stop_threshold*best_loss then the search is stopped.
To disable, set to <cite>None</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><cite>_LRFinder</cite> object of Lightning containing the results of the LR sweep.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>lr_finder</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.min_train_samples">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">min_train_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.min_train_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>The minimum number of samples for training the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.model_created">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_created</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.model_created" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.model_params">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_params</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.model_params" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.output_chunk_length">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_chunk_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.output_chunk_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of time steps predicted at once by the model, not defined for statistical models.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.output_chunk_shift">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_chunk_shift</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.output_chunk_shift" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of time steps that the output/prediction starts after the end of the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">series</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_covariates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roll_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mc_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_warnings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the <code class="docutils literal notranslate"><span class="pre">n</span></code> time step following the end of the training series, or of the specified <code class="docutils literal notranslate"><span class="pre">series</span></code>.</p>
<p>Prediction is performed with a PyTorch Lightning Trainer. It uses a default Trainer object from presets and
<code class="docutils literal notranslate"><span class="pre">pl_trainer_kwargs</span></code> used at model creation. You can also use a custom Trainer with optional parameter
<code class="docutils literal notranslate"><span class="pre">trainer</span></code>. For more information on PyTorch Lightning Trainers check out <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html">this link</a> .</p>
<p>Below, all possible parameters are documented, but not all models support all parameters. For instance,
all the <code class="xref py py-class docutils literal notranslate"><span class="pre">PastCovariatesTorchModel</span></code> support only <code class="docutils literal notranslate"><span class="pre">past_covariates</span></code> and not <code class="docutils literal notranslate"><span class="pre">future_covariates</span></code>.
Darts will complain if you try calling <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.predict" title="darts.models.forecasting.tsmixer_model.TSMixerModel.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">predict()</span></code></a> on a model with the wrong covariates argument.</p>
<p>Darts will also complain if the provided covariates do not have a sufficient time span.
In general, not all models require the same covariates’ time spans:</p>
<ul>
<li><div class="line-block">
<div class="line">Models relying on past covariates require the last <code class="docutils literal notranslate"><span class="pre">input_chunk_length</span></code> of the <code class="docutils literal notranslate"><span class="pre">past_covariates</span></code></div>
<div class="line">points to be known at prediction time. For horizon values <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">&gt;</span> <span class="pre">output_chunk_length</span></code>, these models</div>
<div class="line">require at least the next <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">-</span> <span class="pre">output_chunk_length</span></code> future values to be known as well.</div>
</div>
</li>
<li><div class="line-block">
<div class="line">Models relying on future covariates require the next <code class="docutils literal notranslate"><span class="pre">n</span></code> values to be known.</div>
<div class="line">In addition (for <code class="xref py py-class docutils literal notranslate"><span class="pre">DualCovariatesTorchModel</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">MixedCovariatesTorchModel</span></code>), they also</div>
<div class="line">require the “historic” values of these future covariates (over the past <code class="docutils literal notranslate"><span class="pre">input_chunk_length</span></code>).</div>
</div>
</li>
</ul>
<p>When handling covariates, Darts will try to use the time axes of the target and the covariates
to come up with the right time slices. So the covariates can be longer than needed; as long as the time axes
are correct Darts will handle them correctly. It will also complain if their time span is not sufficient.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of time steps after the end of the training time series for which to produce predictions</p></li>
<li><p><strong>series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a series or sequence of series, representing the history of the target series whose
future is to be predicted. If specified, the method returns the forecasts of these
series. Otherwise, the method returns the forecast of the (single) training series.</p></li>
<li><p><strong>past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the past-observed covariates series needed as inputs for the model.
They must match the covariates used for training in terms of dimension.</p></li>
<li><p><strong>future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the future-known covariates series needed as inputs for the model.
They must match the covariates used for training in terms of dimension.</p></li>
<li><p><strong>trainer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a custom PyTorch-Lightning Trainer object to perform prediction. Using a custom <code class="docutils literal notranslate"><span class="pre">trainer</span></code>
will override Darts’ default trainer.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Size of batches during prediction. Defaults to the models’ training <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> value.</p></li>
<li><p><strong>verbose</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Whether to print the progress. Ignored if there is a <cite>ProgressBar</cite> callback in
<cite>pl_trainer_kwargs</cite>.</p></li>
<li><p><strong>n_jobs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of jobs to run in parallel. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. Defaults to <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><strong>roll_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – For self-consuming predictions, i.e. <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">&gt;</span> <span class="pre">output_chunk_length</span></code>, determines how many
outputs of the model are fed back into it at every iteration of feeding the predicted target
(and optionally future covariates) back into the model. If this parameter is not provided,
it will be set <code class="docutils literal notranslate"><span class="pre">output_chunk_length</span></code> by default.</p></li>
<li><p><strong>num_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of times a prediction is sampled from a probabilistic model. Must be <cite>1</cite> for deterministic models.</p></li>
<li><p><strong>dataloader_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, a dictionary of keyword arguments used to create the PyTorch <cite>DataLoader</cite> instance for the
inference/prediction dataset. For more information on <cite>DataLoader</cite>, check out <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">this link</a>.
By default, Darts configures parameters (“batch_size”, “shuffle”, “drop_last”, “collate_fn”, “pin_memory”)
for seamless forecasting. Changing them should be done with care to avoid unexpected behavior.</p>
</p></li>
<li><p><strong>mc_dropout</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Optionally, enable monte carlo dropout for predictions using neural network based models.
This allows bayesian approximation by specifying an implicit prior over learned models.</p></li>
<li><p><strong>predict_likelihood_parameters</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set to <cite>True</cite>, the model predicts the parameters of its <cite>likelihood</cite> instead of the target. Only
supported for probabilistic models with a likelihood, <cite>num_samples = 1</cite> and <cite>n&lt;=output_chunk_length</cite>.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>show_warnings</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Optionally, control whether warnings are shown. Not effective for all models.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>One or several time series containing the forecasts of <code class="docutils literal notranslate"><span class="pre">series</span></code>, or the forecast of the training series
if <code class="docutils literal notranslate"><span class="pre">series</span></code> is not specified and the model has been trained on a single series.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>, Sequence[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.predict_from_dataset">
<span class="sig-name descname"><span class="pre">predict_from_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_series_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roll_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mc_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.predict_from_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>This method allows for predicting with a specific <code class="xref py py-class docutils literal notranslate"><span class="pre">darts.utils.data.InferenceDataset</span></code> instance.
These datasets implement a PyTorch <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>, and specify how the target and covariates are sliced
for inference. In most cases, you’ll rather want to call <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.predict" title="darts.models.forecasting.tsmixer_model.TSMixerModel.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">predict()</span></code></a> instead, which will create an
appropriate <code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceDataset</span></code> for you.</p>
<p>Prediction is performed with a PyTorch Lightning Trainer. It uses a default Trainer object from presets and
<code class="docutils literal notranslate"><span class="pre">pl_trainer_kwargs</span></code> used at model creation. You can also use a custom Trainer with optional parameter
<code class="docutils literal notranslate"><span class="pre">trainer</span></code>. For more information on PyTorch Lightning Trainers check out <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html">this link</a> .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of time steps after the end of the training time series for which to produce predictions</p></li>
<li><p><strong>input_series_dataset</strong> (<a class="reference internal" href="darts.utils.data.inference_dataset.html#darts.utils.data.inference_dataset.InferenceDataset" title="darts.utils.data.inference_dataset.InferenceDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceDataset</span></code></a>) – Optionally, a series or sequence of series, representing the history of the target series’ whose
future is to be predicted. If specified, the method returns the forecasts of these
series. Otherwise, the method returns the forecast of the (single) training series.</p></li>
<li><p><strong>trainer</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a custom PyTorch-Lightning Trainer object to perform prediction.  Using a custom <code class="docutils literal notranslate"><span class="pre">trainer</span></code>
will override Darts’ default trainer.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Size of batches during prediction. Defaults to the models <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> value.</p></li>
<li><p><strong>verbose</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Whether to print the progress. Ignored if there is a <cite>ProgressBar</cite> callback in
<cite>pl_trainer_kwargs</cite>.</p></li>
<li><p><strong>n_jobs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of jobs to run in parallel. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. Defaults to <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><strong>roll_size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – For self-consuming predictions, i.e. <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">&gt;</span> <span class="pre">output_chunk_length</span></code>, determines how many
outputs of the model are fed back into it at every iteration of feeding the predicted target
(and optionally future covariates) back into the model. If this parameter is not provided,
it will be set <code class="docutils literal notranslate"><span class="pre">output_chunk_length</span></code> by default.</p></li>
<li><p><strong>num_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of times a prediction is sampled from a probabilistic model. Must be <cite>1</cite> for deterministic models.</p></li>
<li><p><strong>dataloader_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, a dictionary of keyword arguments used to create the PyTorch <cite>DataLoader</cite> instance for the
inference/prediction dataset. For more information on <cite>DataLoader</cite>, check out <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">this link</a>.
By default, Darts configures parameters (“batch_size”, “shuffle”, “drop_last”, “collate_fn”, “pin_memory”)
for seamless forecasting. Changing them should be done with care to avoid unexpected behavior.</p>
</p></li>
<li><p><strong>mc_dropout</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Optionally, enable monte carlo dropout for predictions using neural network based models.
This allows bayesian approximation by specifying an implicit prior over learned models.</p></li>
<li><p><strong>predict_likelihood_parameters</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set to <cite>True</cite>, the model predicts the parameters of its <cite>likelihood</cite> instead of the target. Only
supported for probabilistic models with a likelihood, <cite>num_samples = 1</cite> and <cite>n&lt;=output_chunk_length</cite>.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns one or more forecasts for time series.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Sequence[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries">TimeSeries</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.reset_model">
<span class="sig-name descname"><span class="pre">reset_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.reset_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the model object and removes all stored data - model, checkpoints, loggers and training history.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.residuals">
<span class="sig-name descname"><span class="pre">residuals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_covariates=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_covariates=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">historical_forecasts=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forecast_horizon=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_length=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_format='value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrain=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overlap_end=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_points_only=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric=&lt;function</span> <span class="pre">err&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_warnings=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_likelihood_parameters=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_optimization=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_transformers=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values_only=False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.residuals" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the residuals that the model produced for historical forecasts on (potentially multiple) <cite>series</cite>.</p>
<p>This function computes the difference (or one of Darts’ “per time step” metrics) between the actual
observations from <cite>series</cite> and the fitted values obtained by training the model on <cite>series</cite> (or using a
pre-trained model with <cite>retrain=False</cite>). Not all models support fitted values, so we use historical forecasts
as an approximation for them.</p>
<p>In sequence this method performs:</p>
<ul class="simple">
<li><p>use pre-computed <cite>historical_forecasts</cite> or compute historical forecasts for each series (see
<a class="reference internal" href="darts.models.forecasting.forecasting_model.html#darts.models.forecasting.forecasting_model.ForecastingModel.historical_forecasts" title="darts.models.forecasting.forecasting_model.ForecastingModel.historical_forecasts"><code class="xref py py-meth docutils literal notranslate"><span class="pre">historical_forecasts()</span></code></a> for more details).
How the historical forecasts are generated can be configured with parameters <cite>num_samples</cite>, <cite>train_length</cite>,
<cite>start</cite>, <cite>start_format</cite>, <cite>forecast_horizon</cite>, <cite>stride</cite>, <cite>retrain</cite>, <cite>last_points_only</cite>, <cite>fit_kwargs</cite>, and
<cite>predict_kwargs</cite>.</p></li>
<li><p>compute a backtest using a “per time step” <cite>metric</cite> between the historical forecasts and <cite>series</cite> per
component/column and time step (see
<a class="reference internal" href="darts.models.forecasting.forecasting_model.html#darts.models.forecasting.forecasting_model.ForecastingModel.backtest" title="darts.models.forecasting.forecasting_model.ForecastingModel.backtest"><code class="xref py py-meth docutils literal notranslate"><span class="pre">backtest()</span></code></a> for more details). By default,
uses the residuals <a class="reference internal" href="darts.metrics.metrics.html#darts.metrics.metrics.err" title="darts.metrics.metrics.err"><code class="xref py py-func docutils literal notranslate"><span class="pre">err()</span></code></a> (error) as a <cite>metric</cite>.</p></li>
<li><p>create and return <cite>TimeSeries</cite> (or simply a np.ndarray with <cite>values_only=True</cite>) with the time index from
historical forecasts, and values from the metrics per component and time step.</p></li>
</ul>
<p>This method works for single or multiple univariate or multivariate series.
It uses the median prediction (when dealing with stochastic forecasts).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>series</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]]) – A (sequence of) target time series used to successively train (if <cite>retrain</cite> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>) and compute
the historical forecasts.</p></li>
<li><p><strong>past_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a (sequence of) past-observed covariate time series for every input time series in <cite>series</cite>.
This applies only if the model supports past covariates.</p></li>
<li><p><strong>future_covariates</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, a (sequence of) future-known covariate time series for every input time series in <cite>series</cite>.
This applies only if the model supports future covariates.</p></li>
<li><p><strong>historical_forecasts</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, the (or a sequence of / a sequence of sequences of) historical forecasts time series to be
evaluated. Corresponds to the output of <a class="reference internal" href="darts.models.forecasting.forecasting_model.html#darts.models.forecasting.forecasting_model.ForecastingModel.historical_forecasts" title="darts.models.forecasting.forecasting_model.ForecastingModel.historical_forecasts"><code class="xref py py-meth docutils literal notranslate"><span class="pre">historical_forecasts()</span></code></a>. The same <cite>series</cite> and
<cite>last_points_only</cite> values must be passed that were used to generate the historical forecasts. If provided,
will skip historical forecasting and ignore all parameters except <cite>series</cite>, <cite>last_points_only</cite>, <cite>metric</cite>,
and <cite>reduction</cite>.</p></li>
<li><p><strong>forecast_horizon</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The forecast horizon for the predictions.</p></li>
<li><p><strong>num_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of times a prediction is sampled from a probabilistic model. Use values <code class="docutils literal notranslate"><span class="pre">&gt;1</span></code> only for probabilistic
models.</p></li>
<li><p><strong>train_length</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, use a fixed length / number of time steps for every constructed training set (rolling window
mode). Only effective when <cite>retrain</cite> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>. The default is <code class="docutils literal notranslate"><span class="pre">None</span></code>, where it uses all time
steps up until the prediction time (expanding window mode). If larger than the number of available time
steps, uses the expanding mode. Needs to be at least <cite>min_train_series_length</cite>.</p></li>
<li><p><strong>start</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Timestamp</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, the first point in time at which a prediction is computed. This parameter supports:
<code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas.Timestamp</span></code>, and <code class="docutils literal notranslate"><span class="pre">None</span></code>.
If a <code class="docutils literal notranslate"><span class="pre">float</span></code>, it is the proportion of the time series that should lie before the first prediction point.
If an <code class="docutils literal notranslate"><span class="pre">int</span></code>, it is either the index position of the first prediction point for <cite>series</cite> with a
<cite>pd.DatetimeIndex</cite>, or the index value for <cite>series</cite> with a <cite>pd.RangeIndex</cite>. The latter can be changed to
the index position with <cite>start_format=”position”</cite>.
If a <code class="docutils literal notranslate"><span class="pre">pandas.Timestamp</span></code>, it is the time stamp of the first prediction point.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the first prediction point will automatically be set to:</p>
<ul>
<li><p>the first predictable point if <cite>retrain</cite> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, or <cite>retrain</cite> is a Callable and the first
predictable point is earlier than the first trainable point.</p></li>
<li><p>the first trainable point if <cite>retrain</cite> is <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">int</span></code> (given <cite>train_length</cite>),
or <cite>retrain</cite> is a <code class="docutils literal notranslate"><span class="pre">Callable</span></code> and the first trainable point is earlier than the first predictable point.</p></li>
<li><p>the first trainable point (given <cite>train_length</cite>) otherwise</p></li>
</ul>
<dl class="simple">
<dt>Note: If <cite>start</cite> is not within the trainable / forecastable points, uses the closest valid start point that</dt><dd><p>is a round multiple of <cite>stride</cite> ahead of <cite>start</cite>. Raises a <cite>ValueError</cite>, if no valid start point exists.</p>
</dd>
<dt>Note: If the model uses a shifted output (<cite>output_chunk_shift &gt; 0</cite>), then the first predicted point is also</dt><dd><p>shifted by <cite>output_chunk_shift</cite> points into the future.</p>
</dd>
<dt>Note: If <cite>start</cite> is outside the possible historical forecasting times, will ignore the parameter</dt><dd><p>(default behavior with <code class="docutils literal notranslate"><span class="pre">None</span></code>) and start at the first trainable/predictable point.</p>
</dd>
</dl>
</p></li>
<li><p><strong>start_format</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[‘position’, ‘value’]) – Defines the <cite>start</cite> format.
If set to <code class="docutils literal notranslate"><span class="pre">'position'</span></code>, <cite>start</cite> corresponds to the index position of the first predicted point and can
range from <cite>(-len(series), len(series) - 1)</cite>.
If set to <code class="docutils literal notranslate"><span class="pre">'value'</span></code>, <cite>start</cite> corresponds to the index value/label of the first predicted point. Will raise
an error if the value is not in <cite>series</cite>’ index. Default: <code class="docutils literal notranslate"><span class="pre">'value'</span></code>.</p></li>
<li><p><strong>stride</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of time steps between two consecutive predictions.</p></li>
<li><p><strong>retrain</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[…, <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]]) – <p>Whether and/or on which condition to retrain the model before predicting.
This parameter supports 3 different types: <code class="docutils literal notranslate"><span class="pre">bool</span></code>, (positive) <code class="docutils literal notranslate"><span class="pre">int</span></code>, and <code class="docutils literal notranslate"><span class="pre">Callable</span></code> (returning a
<code class="docutils literal notranslate"><span class="pre">bool</span></code>).
In the case of <code class="docutils literal notranslate"><span class="pre">bool</span></code>: retrain the model at each step (<cite>True</cite>), or never retrain the model (<cite>False</cite>).
In the case of <code class="docutils literal notranslate"><span class="pre">int</span></code>: the model is retrained every <cite>retrain</cite> iterations.
In the case of <code class="docutils literal notranslate"><span class="pre">Callable</span></code>: the model is retrained whenever callable returns <cite>True</cite>.
The callable must have the following positional arguments:</p>
<ul>
<li><p><cite>counter</cite> (int): current <cite>retrain</cite> iteration</p></li>
<li><p><cite>pred_time</cite> (pd.Timestamp or int): timestamp of forecast time (end of the training series)</p></li>
<li><p><cite>train_series</cite> (TimeSeries): train series up to <cite>pred_time</cite></p></li>
<li><p><cite>past_covariates</cite> (TimeSeries): past_covariates series up to <cite>pred_time</cite></p></li>
<li><p><cite>future_covariates</cite> (TimeSeries): future_covariates series up to <cite>min(pred_time + series.freq *
forecast_horizon, series.end_time())</cite></p></li>
</ul>
<p>Note: if any optional <cite>*_covariates</cite> are not passed to <cite>historical_forecast</cite>, <code class="docutils literal notranslate"><span class="pre">None</span></code> will be passed
to the corresponding retrain function argument.
Note: some models require being retrained every time and do not support anything other than
<cite>retrain=True</cite>.
Note: also controls the retraining of the <cite>data_transformers</cite>.</p>
</p></li>
<li><p><strong>overlap_end</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether the returned forecasts can go beyond the series’ end or not.</p></li>
<li><p><strong>last_points_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return only the last point of each historical forecast. If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the method returns a
single <code class="docutils literal notranslate"><span class="pre">TimeSeries</span></code> (for each time series in <cite>series</cite>) containing the successive point forecasts.
Otherwise, returns a list of historical <code class="docutils literal notranslate"><span class="pre">TimeSeries</span></code> forecasts.</p></li>
<li><p><strong>metric</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[…, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]]]) – <p>Either one of Darts’ “per time step” metrics (see <a class="reference external" href="https://unit8co.github.io/darts/generated_api/darts.metrics.html">here</a>), or a custom metric that has an
identical signature as Darts’ “per time step” metrics, uses decorators
<a class="reference internal" href="darts.metrics.metrics.html#darts.metrics.metrics.multi_ts_support" title="darts.metrics.metrics.multi_ts_support"><code class="xref py py-func docutils literal notranslate"><span class="pre">multi_ts_support()</span></code></a> and <a class="reference internal" href="darts.metrics.metrics.html#darts.metrics.metrics.multi_ts_support" title="darts.metrics.metrics.multi_ts_support"><code class="xref py py-func docutils literal notranslate"><span class="pre">multi_ts_support()</span></code></a>,
and returns one value per time step.</p>
</p></li>
<li><p><strong>verbose</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to print the progress.</p></li>
<li><p><strong>show_warnings</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to show warnings related to historical forecasts optimization, or parameters <cite>start</cite> and
<cite>train_length</cite>.</p></li>
<li><p><strong>predict_likelihood_parameters</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If set to <cite>True</cite>, the model predicts the parameters of its <cite>likelihood</cite> instead of the target. Only
supported for probabilistic models with a likelihood, <cite>num_samples = 1</cite> and <cite>n&lt;=output_chunk_length</cite>.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>enable_optimization</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to use the optimized version of <cite>historical_forecasts</cite> when supported and available.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>data_transformers</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.dataprocessing.transformers.base_data_transformer.html#darts.dataprocessing.transformers.base_data_transformer.BaseDataTransformer" title="darts.dataprocessing.transformers.base_data_transformer.BaseDataTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseDataTransformer</span></code></a>, <a class="reference internal" href="darts.dataprocessing.pipeline.html#darts.dataprocessing.pipeline.Pipeline" title="darts.dataprocessing.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>]], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – <p>Optionally, a dictionary of <cite>BaseDataTransformer</cite> or <cite>Pipeline</cite> to apply to the corresponding series
(possibles keys; “series”, “past_covariates”, “future_covariates”). If provided, all input series must be
in the un-transformed space. For fittable transformer / pipeline:</p>
<ul>
<li><p>if <cite>retrain=True</cite>, the data transformer re-fit on the training data at each historical forecast step.</p></li>
<li><p>if <cite>retrain=False</cite>, the data transformer transforms the series once before all the forecasts.</p></li>
</ul>
<p>The fitted transformer is used to transform the input during both training and prediction.
If the transformation is invertible, the forecasts will be inverse-transformed.
Only effective when <cite>historical_forecasts=None</cite>.</p>
</p></li>
<li><p><strong>metric_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Additional arguments passed to <cite>metric()</cite>, such as <cite>‘n_jobs’</cite> for parallelization, <cite>‘m’</cite> for scaled
metrics, etc. Will pass arguments only if they are present in the corresponding metric signature. Ignores
reduction arguments <cite>“series_reduction”, “component_reduction”, “time_reduction”</cite>, and parameter
<cite>‘insample’</cite> for scaled metrics (e.g. mase`, <cite>rmsse</cite>, …), as they are handled internally.</p></li>
<li><p><strong>fit_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some additional arguments passed to the model <cite>fit()</cite> method.</p></li>
<li><p><strong>predict_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some additional arguments passed to the model <cite>predict()</cite> method.</p></li>
<li><p><strong>sample_weight</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optionally, some sample weights to apply to the target <cite>series</cite> labels for training. Only effective when
<cite>retrain</cite> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>. They are applied per observation, per label (each step in
<cite>output_chunk_length</cite>), and per component.
If a series or sequence of series, then those weights are used. If the weight series only have a single
component / column, then the weights are applied globally to all components in <cite>series</cite>. Otherwise, for
component-specific weights, the number of components must match those of <cite>series</cite>.
If a string, then the weights are generated using built-in weighting functions. The available options are
<cite>“linear”</cite> or <cite>“exponential”</cite> decay - the further in the past, the lower the weight. The weights are
computed per time <cite>series</cite>.</p></li>
<li><p><strong>values_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the residuals as <cite>np.ndarray</cite>. If <cite>False</cite>, returns residuals as <cite>TimeSeries</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>], <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<a class="reference internal" href="darts.timeseries.html#darts.timeseries.TimeSeries" title="darts.timeseries.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>]]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><em>TimeSeries</em> – Residual <cite>TimeSeries</cite> for a single <cite>series</cite> and <cite>historical_forecasts</cite> generated with
<cite>last_points_only=True</cite>.</p></li>
<li><p><em>List[TimeSeries]</em> – A list of residual <cite>TimeSeries</cite> for a sequence (list) of <cite>series</cite> with <cite>last_points_only=True</cite>.
The residual list has length <cite>len(series)</cite>.</p></li>
<li><p><em>List[List[TimeSeries]]</em> – A list of lists of residual <cite>TimeSeries</cite> for a sequence of <cite>series</cite> with <cite>last_points_only=False</cite>.
The outer residual list has length <cite>len(series)</cite>. The inner lists consist of the residuals from
all possible series-specific historical forecasts.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the model under a given path.</p>
<p>Creates two files under <code class="docutils literal notranslate"><span class="pre">path</span></code> (model object) and <code class="docutils literal notranslate"><span class="pre">path</span></code>.ckpt (checkpoint).</p>
<p>Note: Pickle errors may occur when saving models with custom classes. In this case, consider using
the <cite>clean</cite> flag to strip the saved model from training related attributes.</p>
<p>Example for saving and loading a <code class="xref py py-class docutils literal notranslate"><span class="pre">RNNModel</span></code>:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">darts.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">RNNModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="n">input_chunk_length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;my_model.pt&quot;</span><span class="p">)</span>
<span class="n">model_loaded</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;my_model.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Path under which to save the model at its current state. Please avoid path starting with “last-” or
“best-” to avoid collision with Pytorch-Ligthning checkpoints. If no path is specified, the model
is automatically saved under <code class="docutils literal notranslate"><span class="pre">&quot;{ModelClass}_{YYYY-mm-dd_HH_MM_SS}.pt&quot;</span></code>.
E.g., <code class="docutils literal notranslate"><span class="pre">&quot;RNNModel_2020-01-01_12_00_00.pt&quot;</span></code>.</p></li>
<li><p><strong>clean</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – <p>Whether to store a cleaned version of the model. If <cite>True</cite>, the training series and covariates are removed.
Additionally, removes all Lightning Trainer-related parameters (passed with <cite>pl_trainer_kwargs</cite> at model
creation).</p>
<p>Note: After loading a model stored with <cite>clean=True</cite>, a <cite>series</cite> must be passed ‘predict()’,
<cite>historical_forecasts()</cite> and other forecasting methods.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_future_covariates">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_future_covariates</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_future_covariates" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether model supports future covariates</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_likelihood_parameter_prediction">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_likelihood_parameter_prediction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_likelihood_parameter_prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether model instance supports direct prediction of likelihood parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_multivariate">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_multivariate</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_multivariate" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether the model considers more than one variate in the time series.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_optimized_historical_forecasts">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_optimized_historical_forecasts</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_optimized_historical_forecasts" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether the model supports optimized historical forecasts</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_past_covariates">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_past_covariates</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_past_covariates" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether model supports past covariates</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_probabilistic_prediction">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_probabilistic_prediction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_probabilistic_prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks if the forecasting model with this configuration supports probabilistic predictions.</p>
<p>By default, returns False. Needs to be overwritten by models that do support
probabilistic predictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_sample_weight">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_sample_weight</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_sample_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether model supports sample weight for training.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_static_covariates">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_static_covariates</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_static_covariates" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether model supports static covariates</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.supports_transferrable_series_prediction">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_transferrable_series_prediction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.supports_transferrable_series_prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether the model supports prediction for any input <cite>series</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.to_cpu">
<span class="sig-name descname"><span class="pre">to_cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.to_cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the PyTorch Lightning Trainer parameters to move the model to CPU the next time <a href="#id28"><span class="problematic" id="id29">:fun:`fit()`</span></a> or
<a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.predict" title="darts.models.forecasting.tsmixer_model.TSMixerModel.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">predict()</span></code></a> is called.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.uses_future_covariates">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">uses_future_covariates</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.uses_future_covariates" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether the model uses future covariates, once fitted.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.uses_past_covariates">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">uses_past_covariates</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.uses_past_covariates" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether the model uses past covariates, once fitted.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TSMixerModel.uses_static_covariates">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">uses_static_covariates</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TSMixerModel.uses_static_covariates" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether the model uses static covariates, once fitted.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">darts.models.forecasting.tsmixer_model.</span></span><span class="sig-name descname"><span class="pre">TimeBatchNorm2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/tsmixer_model.html#TimeBatchNorm2d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm2d</span></code></p>
<p>A batch normalization layer that normalizes over the last two dimensions of a Tensor.</p>
<p class="rubric">Methods</p>
<table class="autosummary longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.add_module" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.add_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_module</span></code></a>(name, module)</p></td>
<td><p>Add a child module to the current module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.apply" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Apply <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.bfloat16" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.bfloat16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfloat16</span></code></a>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.buffers" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">buffers</span></code></a>([recurse])</p></td>
<td><p>Return an iterator over module buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.children" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">children</span></code></a>()</p></td>
<td><p>Return an iterator over immediate children modules.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.compile" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(*args, **kwargs)</p></td>
<td><p>Compile this Module's forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cpu" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu</span></code></a>()</p></td>
<td><p>Move all model parameters and buffers to the CPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cuda" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cuda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda</span></code></a>([device])</p></td>
<td><p>Move all model parameters and buffers to the GPU.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.double" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.double"><code class="xref py py-obj docutils literal notranslate"><span class="pre">double</span></code></a>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">double</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.eval" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code></a>()</p></td>
<td><p>Set the module in evaluation mode.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.extra_repr" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.extra_repr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extra_repr</span></code></a>()</p></td>
<td><p>Return the extra representation of the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.float" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">float</span></code> datatype.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.forward" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(x)</p></td>
<td><p>Define the computation performed at every call.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_buffer" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_buffer</span></code></a>(target)</p></td>
<td><p>Return the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_extra_state" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_extra_state</span></code></a>()</p></td>
<td><p>Return any extra state to include in the module's state_dict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_parameter" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_parameter</span></code></a>(target)</p></td>
<td><p>Return the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_submodule" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_submodule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_submodule</span></code></a>(target)</p></td>
<td><p>Return the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.half" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.half"><code class="xref py py-obj docutils literal notranslate"><span class="pre">half</span></code></a>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">half</span></code> datatype.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.ipu" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.ipu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ipu</span></code></a>([device])</p></td>
<td><p>Move all model parameters and buffers to the IPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>(state_dict[, strict, assign])</p></td>
<td><p>Copy parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.modules" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">modules</span></code></a>()</p></td>
<td><p>Return an iterator over all modules in the network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.mtia" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.mtia"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mtia</span></code></a>([device])</p></td>
<td><p>Move all model parameters and buffers to the MTIA.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_buffers" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_buffers</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Return an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_children" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_children</span></code></a>()</p></td>
<td><p>Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_modules" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_modules</span></code></a>([memo, prefix, remove_duplicate])</p></td>
<td><p>Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_parameters" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters</span></code></a>([prefix, recurse, ...])</p></td>
<td><p>Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.parameters" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a>([recurse])</p></td>
<td><p>Return an iterator over module parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_backward_hook" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_backward_hook</span></code></a>(hook)</p></td>
<td><p>Register a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_buffer" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_buffer</span></code></a>(name, tensor[, persistent])</p></td>
<td><p>Add a buffer to the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_forward_hook" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook, *[, prepend, ...])</p></td>
<td><p>Register a forward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_forward_pre_hook" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook, *[, ...])</p></td>
<td><p>Register a forward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_full_backward_hook" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_full_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Register a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_full_backward_pre_hook" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_full_backward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_pre_hook</span></code></a>(hook[, prepend])</p></td>
<td><p>Register a backward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_load_state_dict_post_hook" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_load_state_dict_post_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_load_state_dict_post_hook</span></code></a>(hook)</p></td>
<td><p>Register a post-hook to be run after module's <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code> is called.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_load_state_dict_pre_hook" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_load_state_dict_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_load_state_dict_pre_hook</span></code></a>(hook)</p></td>
<td><p>Register a pre-hook to be run before module's <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code> is called.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_module" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_module</span></code></a>(name, module)</p></td>
<td><p>Alias for <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.add_module" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_parameter" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_parameter</span></code></a>(name, param)</p></td>
<td><p>Add a parameter to the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_state_dict_post_hook" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_state_dict_post_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_state_dict_post_hook</span></code></a>(hook)</p></td>
<td><p>Register a post-hook for the <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_state_dict_pre_hook" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_state_dict_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_state_dict_pre_hook</span></code></a>(hook)</p></td>
<td><p>Register a pre-hook for the <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.requires_grad_" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.requires_grad_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad_</span></code></a>([requires_grad])</p></td>
<td><p>Change if autograd should record operations on parameters in this module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.set_extra_state" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.set_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_extra_state</span></code></a>(state)</p></td>
<td><p>Set extra state contained in the loaded <cite>state_dict</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.set_submodule" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.set_submodule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_submodule</span></code></a>(target, module)</p></td>
<td><p>Set the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.share_memory" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.share_memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_memory</span></code></a>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code></a>(*args[, destination, prefix, ...])</p></td>
<td><p>Return a dictionary containing references to the whole state of the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.to" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>Move and/or cast the parameters and buffers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.to_empty" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.to_empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_empty</span></code></a>(*, device[, recurse])</p></td>
<td><p>Move the parameters and buffers to the specified device without copying storage.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.train" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>([mode])</p></td>
<td><p>Set the module in training mode.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.type" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code></a>(dst_type)</p></td>
<td><p>Casts all parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dst_type</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.xpu" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.xpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xpu</span></code></a>([device])</p></td>
<td><p>Move all model parameters and buffers to the XPU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.zero_grad" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>([set_to_none])</p></td>
<td><p>Reset gradients of all model parameters.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 70%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>__call__</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>reset_parameters</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>reset_running_stats</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.T_destination">
<span class="sig-name descname"><span class="pre">T_destination</span></span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.T_destination" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of TypeVar(‘T_destination’, bound=<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>])</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.add_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the child module. The child module can be
accessed from this module using the given name</p></li>
<li><p><strong>module</strong> (<em>Module</em>) – child module to be added to the module.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.affine">
<span class="sig-name descname"><span class="pre">affine</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.affine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p>
<p>Typical use includes initializing the parameters of a model
(see also <span class="xref std std-ref">nn-init-doc</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> -&gt; None) – function to be applied to each submodule</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.bfloat16">
<span class="sig-name descname"><span class="pre">bfloat16</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.bfloat16" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.buffers">
<span class="sig-name descname"><span class="pre">buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterator over module buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – module buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.call_super_init">
<span class="sig-name descname"><span class="pre">call_super_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.call_super_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.children" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterator over immediate children modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a child module</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.compile" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile this Module’s forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>This Module’s <cite>__call__</cite> method is compiled and all arguments are passed as-is
to <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>See <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code> for details on the arguments for this function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Move all model parameters and buffers to the CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cuda" title="Permalink to this definition">¶</a></dt>
<dd><p>Move all model parameters and buffers to the GPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing the optimizer if the module will
live on GPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.double" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">double</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.dump_patches">
<span class="sig-name descname"><span class="pre">dump_patches</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.dump_patches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.eps">
<span class="sig-name descname"><span class="pre">eps</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.eps" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the module in evaluation mode.</p>
<p>This has an effect only on certain modules. See the documentation of
particular modules for details of their behaviors in training/evaluation
mode, i.e. whether they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code>.</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.eval()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the extra representation of the module.</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.float" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">float</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/darts/models/forecasting/tsmixer_model.html#TimeBatchNorm2d.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the buffer
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The buffer referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not a
buffer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Return any extra state to include in the module’s state_dict.</p>
<p>Implement this and a corresponding <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.set_extra_state" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.set_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_extra_state()</span></code></a> for your module
if you need to store extra state. This function is called when building the
module’s <cite>state_dict()</cite>.</p>
<p>Note that extra state should be picklable to ensure working serialization
of the state_dict. We only provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Any extra state to store in the module’s state_dict</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_parameter">
<span class="sig-name descname"><span class="pre">get_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the Parameter
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Parameter referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> which has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To check whether or not we have the <code class="docutils literal notranslate"><span class="pre">linear</span></code> submodule, we
would call <code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.linear&quot;)</span></code>. To check whether
we have the <code class="docutils literal notranslate"><span class="pre">conv</span></code> submodule, we would call
<code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.net_c.conv&quot;)</span></code>.</p>
<p>The runtime of <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> is bounded by the degree
of module nesting in <code class="docutils literal notranslate"><span class="pre">target</span></code>. A query against
<code class="docutils literal notranslate"><span class="pre">named_modules</span></code> achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists, <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> should always be
used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The submodule referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.half" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">half</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.ipu">
<span class="sig-name descname"><span class="pre">ipu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.ipu" title="Permalink to this definition">¶</a></dt>
<dd><p>Move all model parameters and buffers to the IPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing the optimizer if the module will
live on IPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy parameters and buffers from <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> the optimizer must be created after
the call to <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">load_state_dict</span></code></a> unless
<code class="xref py py-func docutils literal notranslate"><span class="pre">get_swap_module_params_on_conversion()</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>dict</em>) – a dict containing parameters and
persistent buffers.</p></li>
<li><p><strong>strict</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to strictly enforce that the keys
in <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this module’s
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>assign</strong> (<em>bool</em><em>, </em><em>optional</em>) – When set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the properties of the tensors
in the current module are preserved whereas setting it to <code class="docutils literal notranslate"><span class="pre">True</span></code> preserves
properties of the Tensors in the state dict. The only
exception is the <code class="docutils literal notranslate"><span class="pre">requires_grad</span></code> field of <code class="xref py py-class docutils literal notranslate">
<span class="pre">Default:</span> <span class="pre">``False`</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>missing_keys</strong> is a list of str containing any keys that are expected</dt><dd><p>by this module but missing from the provided <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>unexpected_keys</strong> is a list of str containing the keys that are not</dt><dd><p>expected by this module but present in the provided <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a parameter or buffer is registered as <code class="docutils literal notranslate"><span class="pre">None</span></code> and its corresponding key
exists in <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>, <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> will raise a
<code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterator over all modules in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a module in the network</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.momentum">
<span class="sig-name descname"><span class="pre">momentum</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.momentum" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.mtia">
<span class="sig-name descname"><span class="pre">mtia</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.mtia" title="Permalink to this definition">¶</a></dt>
<dd><p>Move all model parameters and buffers to the MTIA.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing the optimizer if the module will
live on MTIA while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all buffer names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module. Defaults to True.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated buffers in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, torch.Tensor)</em> – Tuple containing the name and buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_children">
<span class="sig-name descname"><span class="pre">named_children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_children" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>(str, Module)</em> – Tuple containing a name and child module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_modules">
<span class="sig-name descname"><span class="pre">named_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>memo</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Set</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – a memo to store the set of modules already added to the result</p></li>
<li><p><strong>prefix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – a prefix that will be added to the name of the module</p></li>
<li><p><strong>remove_duplicate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – whether to remove the duplicated module instances in the result
or not</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Module)</em> – Tuple of name and module</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
<li><p><strong>remove_duplicate</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to remove the duplicated
parameters in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(str, Parameter)</em> – Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.num_features">
<span class="sig-name descname"><span class="pre">num_features</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.num_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>Parameter</em> – module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a backward hook on the module.</p>
<p>This function is deprecated in favor of <code class="xref py py-meth docutils literal notranslate"><span class="pre">register_full_backward_hook()</span></code> and
the behavior of this function will change in future versions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the module’s state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">persistent</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this module’s
<a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the buffer. The buffer can be accessed
from this module using the given name</p></li>
<li><p><strong>tensor</strong> (<em>Tensor</em><em> or </em><em>None</em>) – buffer to be registered. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations
that run on buffers, such as <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cuda" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>, are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
the buffer is <strong>not</strong> included in the module’s <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>) – whether the buffer is part of this module’s
<a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">always_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_forward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.forward" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
output. It can modify the input inplace but it will not have effect on
forward since this is called after <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.forward" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called. The hook
should have the following signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the forward hook will be passed the
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> given to the forward function and be expected to return the
output possibly modified. The hook should have the following signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired
before all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_hook()</span></code> will fire before all hooks
registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the
kwargs given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>always_call</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be run regardless of
whether an exception is raised while calling the Module.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_forward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.forward" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is false or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
input. User can either return a tuple or a single modified value in the
hook. We will wrap the value into a tuple if a single value is returned
(unless that value is already a tuple). The hook should have the
following signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is true, the forward pre-hook will be passed the
kwargs given to the forward function. And if the hook modifies the
input, both the args and kwargs should be returned. The hook should have
the following signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">a</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">modified</span> <span class="nb">input</span> <span class="ow">and</span> <span class="n">kwargs</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_pre_hook()</span></code> will fire before all
hooks registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<em>bool</em>) – If true, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the kwargs
given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_full_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to a module
are computed, i.e. the hook will execute if and only if the gradients with
respect to module outputs are computed. The hook should have the following
signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in
subsequent computations. <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for all non-Tensor
arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_full_backward_pre_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_full_backward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a backward pre-hook on the module.</p>
<p>The hook will be called every time the gradients for the module are computed.
The hook should have the following signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> is a tuple. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the output that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> in
subsequent computations. Entries in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for
all non-Tensor arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<em>bool</em>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_pre_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_load_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_load_state_dict_post_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a post-hook to be run after module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code> is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, incompatible_keys) -&gt; None</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">module</span></code> argument is the current module that this hook is registered
on, and the <code class="docutils literal notranslate"><span class="pre">incompatible_keys</span></code> argument is a <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> consisting
of attributes <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>. <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code>
is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the missing keys and
<code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the unexpected keys.</p>
<p>The given incompatible_keys can be modified inplace if needed.</p>
<p>Note that the checks performed when calling <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">strict=True</span></code> are affected by modifications the hook makes to
<code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> or <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>, as expected. Additions to either
set of keys will result in an error being thrown when <code class="docutils literal notranslate"><span class="pre">strict=True</span></code>, and
clearing out both missing and unexpected keys will avoid an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_load_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_load_state_dict_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a pre-hook to be run before module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code> is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs) -&gt; None  # noqa: B950</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>Callable</em>) – Callable hook that will be invoked before
loading the state dict.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_module">
<span class="sig-name descname"><span class="pre">register_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.add_module" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_parameter">
<span class="sig-name descname"><span class="pre">register_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of the parameter. The parameter can be accessed
from this module using the given name</p></li>
<li><p><strong>param</strong> (<em>Parameter</em><em> or </em><em>None</em>) – parameter to be added to the module. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations that run on parameters, such as <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cuda" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>,
are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the parameter is <strong>not</strong> included in the
module’s <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_state_dict_post_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a post-hook for the <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> method.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, state_dict, prefix, local_metadata) -&gt; None</p>
</dd>
</dl>
<p>The registered hooks can modify the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> inplace.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.register_state_dict_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a pre-hook for the <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> method.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, prefix, keep_vars) -&gt; None</p>
</dd>
</dl>
<p>The registered hooks can be used to perform pre-processing before the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>
call is made.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.requires_grad_" title="Permalink to this definition">¶</a></dt>
<dd><p>Change if autograd should record operations on parameters in this module.</p>
<p>This method sets the parameters’ <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.requires_grad_()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<em>bool</em>) – whether autograd should record operations on
parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.reset_running_stats">
<span class="sig-name descname"><span class="pre">reset_running_stats</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.reset_running_stats" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.set_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Set extra state contained in the loaded <cite>state_dict</cite>.</p>
<p>This function is called from <a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state
found within the <cite>state_dict</cite>. Implement this function and a corresponding
<a class="reference internal" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_extra_state" title="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.get_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_extra_state()</span></code></a> for your module if you need to store extra state within its
<cite>state_dict</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>dict</em>) – Extra state from the <cite>state_dict</cite></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.set_submodule">
<span class="sig-name descname"><span class="pre">set_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.set_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To overide the <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> with a new submodule <code class="docutils literal notranslate"><span class="pre">Linear</span></code>, you
would call
<code class="docutils literal notranslate"><span class="pre">set_submodule(&quot;net_b.net_c.conv&quot;,</span> <span class="pre">nn.Linear(33,</span> <span class="pre">16))</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p></li>
<li><p><strong>module</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – The module to set the submodule to.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If the target string is empty</p></li>
<li><p><strong>AttributeError</strong> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p></li>
</ul>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.share_memory">
<span class="sig-name descname"><span class="pre">share_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.share_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>~T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a dictionary containing references to the whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to <code class="docutils literal notranslate"><span class="pre">None</span></code> are not included.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned object is a shallow copy. It contains references
to the module’s parameters and buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> also accepts positional arguments for
<code class="docutils literal notranslate"><span class="pre">destination</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> in order. However,
this is being deprecated and keyword arguments will be enforced in
future releases.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please avoid the use of argument <code class="docutils literal notranslate"><span class="pre">destination</span></code> as it is not
designed for end-users.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>destination</strong> (<em>dict</em><em>, </em><em>optional</em>) – If provided, the state of module will
be updated into the dict and the same object is returned.
Otherwise, an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> will be created and returned.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em>) – a prefix added to parameter and buffer
names to compose the keys in state_dict. Default: <code class="docutils literal notranslate"><span class="pre">''</span></code>.</p></li>
<li><p><strong>keep_vars</strong> (<em>bool</em><em>, </em><em>optional</em>) – by default the <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> s
returned in the state dict are detached from autograd. If it’s
set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, detaching will not be performed.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary containing a whole state of the module</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.to" title="Permalink to this definition">¶</a></dt>
<dd><p>Move and/or cast the parameters and buffers.</p>
<p>This can be called as</p>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memory_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.channels_last</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Its signature is similar to <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code>, but only accepts
floating point or complex <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>s. In addition, this method will
only cast the floating point or complex parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>
(if given). The integral parameters and buffers will be moved
<code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>See below for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>) – the desired device of the parameters
and buffers in this module</p></li>
<li><p><strong>dtype</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code>) – the desired floating point or complex dtype of
the parameters and buffers in this module</p></li>
<li><p><strong>tensor</strong> (<em>torch.Tensor</em>) – Tensor whose dtype and device are the desired
dtype and device for all parameters and buffers in this module</p></li>
<li><p><strong>memory_format</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.memory_format</span></code>) – the desired memory
format for 4D parameters and buffers in this module (keyword
only argument)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +IGNORE_WANT(&quot;non-deterministic&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gpu1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">gpu1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16, device=&#39;cuda:1&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.3741+0.j,  0.2382+0.j],</span>
<span class="go">        [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">))</span>
<span class="go">tensor([[0.6122+0.j, 0.1150+0.j],</span>
<span class="go">        [0.6122+0.j, 0.1150+0.j],</span>
<span class="go">        [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.to_empty" title="Permalink to this definition">¶</a></dt>
<dd><p>Move the parameters and buffers to the specified device without copying storage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>) – The desired device of the parameters
and buffers in this module.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – Whether parameters and buffers of submodules should
be recursively moved to the specified device.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.track_running_stats">
<span class="sig-name descname"><span class="pre">track_running_stats</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.track_running_stats" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the module in training mode.</p>
<p>This has an effect only on certain modules. See the documentation of
particular modules for details of their behaviors in training/evaluation
mode, i.e., whether they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.type">
<span class="sig-name descname"><span class="pre">type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.type" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dst_type</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dst_type</strong> (<em>type</em><em> or </em><em>string</em>) – the desired type</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.xpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Move all model parameters and buffers to the XPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#darts.models.forecasting.tsmixer_model.TimeBatchNorm2d.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset gradients of all model parameters.</p>
<p>See similar function under <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code> for more context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>set_to_none</strong> (<em>bool</em>) – instead of setting to zero, set the grads to None.
See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for details.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="darts.models.forecasting.transformer_model.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Transformer Model</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="darts.models.forecasting.varima.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">VARIMA</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2020 - 2025, Unit8 SA (Apache 2.0 License).<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.0.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>