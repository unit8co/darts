
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Using Torch Models with GPUs and TPUs &#8212; darts  documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../_static/docs-favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Covariates" href="covariates.html" />
    <link rel="prev" title="Torch Forecasting Models" href="torch_forecasting_models.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/darts-logo-trim.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../README.html">
  Home
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../quickstart/00-quickstart.html">
  Quickstart
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../userguide.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../generated_api/darts.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../examples.html">
  Examples
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/unit8co/darts" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/unit8co" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="timeseries.html">
   <code class="docutils literal notranslate">
    <span class="pre">
     TimeSeries
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="forecasting_overview.html">
   Overview of Forecasting Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="torch_forecasting_models.html">
   Torch Forecasting Models
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Using Torch Models with GPUs and TPUs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="covariates.html">
   Covariates
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hyperparameter_optimization.html">
   Hyperparameter Optimization in Darts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="faq.html">
   Frequently Asked Questions
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#use-cpu">
   Use CPU
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#use-a-gpu">
   Use a GPU
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-gpu-support">
     Multi GPU support
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#use-a-tpu">
   Use a TPU
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="using-torch-models-with-gpus-and-tpus">
<h1>Using Torch Models with GPUs and TPUs<a class="headerlink" href="#using-torch-models-with-gpus-and-tpus" title="Permalink to this headline">¶</a></h1>
<p>This section was written for Darts 0.17.0 and later.</p>
<p>We assume that you already know about Torch Forecasting Models in Darts. If you’re new to the topic we recommend you to read the <a class="reference external" href="https://unit8co.github.io/darts/userguide/torch_forecasting_models.html">guide on Torch Forecasting Models</a> first. This guide also contains a section about performance recommendations, which we recommend reading first. Finally, here is also an <a class="reference external" href="https://unit8co.github.io/darts/examples/04-RNN-examples.html">Recurrent Neural Network (RNN) Model example</a>, on which this section is going to be based on.</p>
<section id="use-cpu">
<h2>Use CPU<a class="headerlink" href="#use-cpu" title="Permalink to this headline">¶</a></h2>
<p>By default all models will run on CPU. As shown in the RNN example above, we’ll import the Air Passenger dataset, as well as other necessary modules.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">darts.dataprocessing.transformers</span> <span class="kn">import</span> <span class="n">Scaler</span>
<span class="kn">from</span> <span class="nn">darts.models</span> <span class="kn">import</span> <span class="n">RNNModel</span>
<span class="kn">from</span> <span class="nn">darts.metrics</span> <span class="kn">import</span> <span class="n">mape</span>
<span class="kn">from</span> <span class="nn">darts.datasets</span> <span class="kn">import</span> <span class="n">AirPassengersDataset</span>
</pre></div>
</div>
<p>Now we read and scale the data like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read data:</span>
<span class="n">series</span> <span class="o">=</span> <span class="n">AirPassengersDataset</span><span class="p">()</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">series</span> <span class="o">=</span> <span class="n">series</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Create training and validation sets:</span>
<span class="n">train</span><span class="p">,</span> <span class="n">val</span> <span class="o">=</span> <span class="n">series</span><span class="o">.</span><span class="n">split_after</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="s2">&quot;19590101&quot;</span><span class="p">))</span>

<span class="c1"># Normalize the time series (note: we avoid fitting the transformer on the validation set)</span>
<span class="n">transformer</span> <span class="o">=</span> <span class="n">Scaler</span><span class="p">()</span>
<span class="n">train_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">val_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="n">series_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">series</span><span class="p">)</span>
</pre></div>
</div>
<p>Next we will create our RNN like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;RNN&quot;</span><span class="p">,</span>
    <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">n_epochs</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">},</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;Air_RNN&quot;</span><span class="p">,</span>
    <span class="n">log_tensorboard</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">training_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">input_chunk_length</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span>
    <span class="n">force_reset</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>and fit it to the data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_transformed</span><span class="p">,</span> <span class="n">val_series</span><span class="o">=</span><span class="n">val_transformed</span><span class="p">)</span>
</pre></div>
</div>
<p>where in the output we can see that no other processing unit is used to train our model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">used</span><span class="p">:</span> <span class="kc">False</span>
<span class="n">TPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">TPU</span> <span class="n">cores</span>
<span class="n">IPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">IPUs</span>

  <span class="o">|</span> <span class="n">Name</span>      <span class="o">|</span> <span class="n">Type</span>    <span class="o">|</span> <span class="n">Params</span>
<span class="o">--------------------------------------</span>
<span class="mi">0</span> <span class="o">|</span> <span class="n">criterion</span> <span class="o">|</span> <span class="n">MSELoss</span> <span class="o">|</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="o">|</span> <span class="n">rnn</span>       <span class="o">|</span> <span class="n">RNN</span>     <span class="o">|</span> <span class="mi">460</span>
<span class="mi">2</span> <span class="o">|</span> <span class="n">V</span>         <span class="o">|</span> <span class="n">Linear</span>  <span class="o">|</span> <span class="mi">21</span>
<span class="o">--------------------------------------</span>
<span class="mi">481</span>       <span class="n">Trainable</span> <span class="n">params</span>
<span class="mi">0</span>         <span class="n">Non</span><span class="o">-</span><span class="n">trainable</span> <span class="n">params</span>
<span class="mi">481</span>       <span class="n">Total</span> <span class="n">params</span>
<span class="mf">0.004</span>     <span class="n">Total</span> <span class="n">estimated</span> <span class="n">model</span> <span class="n">params</span> <span class="n">size</span> <span class="p">(</span><span class="n">MB</span><span class="p">)</span>

<span class="n">Epoch</span> <span class="mi">299</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="mi">8</span><span class="o">/</span><span class="mi">8</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">42.49</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="mf">0.00285</span><span class="p">,</span> <span class="n">v_num</span><span class="o">=</span><span class="n">logs</span><span class="p">]</span>
<span class="o">&lt;</span><span class="n">darts</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">forecasting</span><span class="o">.</span><span class="n">rnn_model</span><span class="o">.</span><span class="n">RNNModel</span> <span class="n">at</span> <span class="mh">0x7fc75901cb10</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Now the model is ready to start predicting, which won’t be shown here since it’s included in the example linked in the start of this guide.</p>
</section>
<section id="use-a-gpu">
<h2>Use a GPU<a class="headerlink" href="#use-a-gpu" title="Permalink to this headline">¶</a></h2>
<p>GPUs can dramatically improve the performance of your model in terms of processing time. By using an Accelerator in the <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#accelerator">Pytorch Lightning Trainer</a>, we can enjoy the benefits of a GPU. We only need to instruct our model to use our machine’s GPU through PyTorch Lightning Trainer parameters, which are expressed as the <code class="docutils literal notranslate"><span class="pre">pl_trainer_kwargs</span></code> dictionary, like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;RNN&quot;</span><span class="p">,</span>
    <span class="o">...</span>
    <span class="n">force_reset</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">pl_trainer_kwargs</span><span class="o">=</span><span class="p">{</span>
      <span class="s2">&quot;accelerator&quot;</span><span class="p">:</span> <span class="s2">&quot;gpu&quot;</span><span class="p">,</span>
      <span class="s2">&quot;devices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
<p>which now outputs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="n">used</span><span class="p">:</span> <span class="kc">True</span>
<span class="n">TPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">TPU</span> <span class="n">cores</span>
<span class="n">IPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">IPUs</span>
<span class="n">LOCAL_RANK</span><span class="p">:</span> <span class="mi">0</span> <span class="o">-</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="o">|</span> <span class="n">Name</span>      <span class="o">|</span> <span class="n">Type</span>    <span class="o">|</span> <span class="n">Params</span>
<span class="o">--------------------------------------</span>
<span class="mi">0</span> <span class="o">|</span> <span class="n">criterion</span> <span class="o">|</span> <span class="n">MSELoss</span> <span class="o">|</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="o">|</span> <span class="n">rnn</span>       <span class="o">|</span> <span class="n">RNN</span>     <span class="o">|</span> <span class="mi">460</span>
<span class="mi">2</span> <span class="o">|</span> <span class="n">V</span>         <span class="o">|</span> <span class="n">Linear</span>  <span class="o">|</span> <span class="mi">21</span>
<span class="o">--------------------------------------</span>
<span class="mi">481</span>       <span class="n">Trainable</span> <span class="n">params</span>
<span class="mi">0</span>         <span class="n">Non</span><span class="o">-</span><span class="n">trainable</span> <span class="n">params</span>
<span class="mi">481</span>       <span class="n">Total</span> <span class="n">params</span>
<span class="mf">0.004</span>     <span class="n">Total</span> <span class="n">estimated</span> <span class="n">model</span> <span class="n">params</span> <span class="n">size</span> <span class="p">(</span><span class="n">MB</span><span class="p">)</span>

<span class="n">Epoch</span> <span class="mi">299</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="mi">8</span><span class="o">/</span><span class="mi">8</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">39.81</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="mf">0.00285</span><span class="p">,</span> <span class="n">v_num</span><span class="o">=</span><span class="n">logs</span><span class="p">]</span>
<span class="o">&lt;</span><span class="n">darts</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">forecasting</span><span class="o">.</span><span class="n">rnn_model</span><span class="o">.</span><span class="n">RNNModel</span> <span class="n">at</span> <span class="mh">0x7ff1b5e4d4d0</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>From the output we can see that the GPU is both available and used. The rest of the code doesn’t require any change, i.e. it’s irrelevant if we are using a GPU or CPU.</p>
<section id="multi-gpu-support">
<h3>Multi GPU support<a class="headerlink" href="#multi-gpu-support" title="Permalink to this headline">¶</a></h3>
<p>Darts utilizes <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/accelerators/gpu_intermediate.html">Lightning’s multi GPU capabilities</a> to be able to capitalize on scalable hardware.</p>
<p>Multiple parallelization strategies exist for multiple GPU training, which - because of different strategies for multiprocessing and data handling - interact strongly with the execution environment.</p>
<p>Currently in Darts the <code class="docutils literal notranslate"><span class="pre">ddp_spawn</span></code> distribution strategy is tested.</p>
<p>As per the description of the <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/accelerators/gpu_intermediate.html#distributed-data-parallel-spawn">Lightning documentation</a> has some noteworthy limitations, eg. it <strong>can not run</strong> in:</p>
<ul class="simple">
<li><p>Jupyter Notebook, Google COLAB, Kaggle, etc.</p></li>
<li><p>In case you have a nested script without a root package</p></li>
</ul>
<p>This in practice means, that execution has to happen in a separate <code class="docutils literal notranslate"><span class="pre">.py</span></code> script, that has the following general context around the code executing the training:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">multiprocessing</span><span class="o">.</span><span class="n">freeze_support</span><span class="p">()</span>
</pre></div>
</div>
<p>The <strong>main</strong> pattern is necessary (see <a class="reference external" href="https://pytorch.org/docs/stable/notes/windows.html#multiprocessing-error-without-if-clause-protection">this</a>) even when your execution <strong>does not</strong> happen in a windows environment.</p>
<p>Beyond this, no other major modification to your models is necessary other than allowing multi GPU training in the <code class="docutils literal notranslate"><span class="pre">pl_trainer_args</span></code> for example like</p>
<p><code class="docutils literal notranslate"><span class="pre">pl_trainer_kwargs</span> <span class="pre">=</span> <span class="pre">{&quot;accelerator&quot;:</span> <span class="pre">&quot;gpu&quot;,</span> <span class="pre">&quot;devices&quot;:</span> <span class="pre">-1,</span> <span class="pre">&quot;auto_select_gpus&quot;:</span> <span class="pre">True}</span></code></p>
<p>This method automatically selects all available GPUs for training. Manual setting of the number of devices is also possible.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">ddp</span></code> family of strategies creates indiviual subprocesses for each GPU, so contents of the memory (notably the <code class="docutils literal notranslate"><span class="pre">Dataloder</span></code>) gets copied over. Thus, as per the <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/accelerators/gpu_intermediate.html#distributed-data-parallel">description of lightning docs</a> caution is advised in setting the <code class="docutils literal notranslate"><span class="pre">Dataloader(num_workers=N)</span></code> too high, since according to it:</p>
<p>“Dataloader(num_workers=N), where N is large, bottlenecks training with DDP… ie: it will be VERY slow or won’t work at all. This is a PyTorch limitation.”</p>
<p>Usage of other distribution strategies with Darts currently <em>might</em> very well work, but are yet untested and subject to individual setup / experimentation.</p>
</section>
</section>
<section id="use-a-tpu">
<h2>Use a TPU<a class="headerlink" href="#use-a-tpu" title="Permalink to this headline">¶</a></h2>
<p>Tensor Processing Unit (TPU) is an AI accelerator application-specific integrated circuit (ASIC) developed by Google specifically for neural network machine learning.</p>
<p>There are three main ways to get access to a TPU:</p>
<ul class="simple">
<li><p>Google Colab</p></li>
<li><p>Google Cloud (GCP)</p></li>
<li><p>Kaggle</p></li>
</ul>
<p>If you are using a TPU in the Google Colab kind of notebook, then you should first install these:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl
!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchtext==0.10.0 -f https://download.pytorch.org/whl/cu111/torch_stable.html
!pip install pyyaml==5.4.1
</pre></div>
</div>
<p>and then instruct our model to use a TPU or more. In our example we are using four TPUs, like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;RNN&quot;</span><span class="p">,</span>
    <span class="o">...</span>
    <span class="n">force_reset</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">pl_trainer_kwargs</span><span class="o">=</span><span class="p">{</span>
      <span class="s2">&quot;accelerator&quot;</span><span class="p">:</span> <span class="s2">&quot;tpu&quot;</span><span class="p">,</span>
      <span class="s2">&quot;tpu_cores&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
<p>which outputs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">TPU</span> <span class="n">has</span> <span class="n">started</span> <span class="n">up</span> <span class="n">successfully</span> <span class="k">with</span> <span class="n">version</span> <span class="n">pytorch</span><span class="o">-</span><span class="mf">1.9</span>
<span class="n">GPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">used</span><span class="p">:</span> <span class="kc">False</span>
<span class="n">TPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="n">TPU</span> <span class="n">cores</span>
<span class="n">IPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">IPUs</span>

  <span class="o">|</span> <span class="n">Name</span>      <span class="o">|</span> <span class="n">Type</span>    <span class="o">|</span> <span class="n">Params</span>
<span class="o">--------------------------------------</span>
<span class="mi">0</span> <span class="o">|</span> <span class="n">criterion</span> <span class="o">|</span> <span class="n">MSELoss</span> <span class="o">|</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="o">|</span> <span class="n">rnn</span>       <span class="o">|</span> <span class="n">RNN</span>     <span class="o">|</span> <span class="mi">460</span>
<span class="mi">2</span> <span class="o">|</span> <span class="n">V</span>         <span class="o">|</span> <span class="n">Linear</span>  <span class="o">|</span> <span class="mi">21</span>
<span class="o">--------------------------------------</span>
<span class="mi">481</span>       <span class="n">Trainable</span> <span class="n">params</span>
<span class="mi">0</span>         <span class="n">Non</span><span class="o">-</span><span class="n">trainable</span> <span class="n">params</span>
<span class="mi">481</span>       <span class="n">Total</span> <span class="n">params</span>
<span class="mf">0.002</span>     <span class="n">Total</span> <span class="n">estimated</span> <span class="n">model</span> <span class="n">params</span> <span class="n">size</span> <span class="p">(</span><span class="n">MB</span><span class="p">)</span>
<span class="n">Epoch</span> <span class="mi">299</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="mi">8</span><span class="o">/</span><span class="mi">8</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">8.52</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="mf">0.00285</span><span class="p">,</span> <span class="n">v_num</span><span class="o">=</span><span class="n">logs</span><span class="p">]</span>
<span class="o">&lt;</span><span class="n">darts</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">forecasting</span><span class="o">.</span><span class="n">rnn_model</span><span class="o">.</span><span class="n">RNNModel</span> <span class="n">at</span> <span class="mh">0x7ff1b5e4d4d0</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>From the output we can see that our model is using 4 TPUs.</p>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="torch_forecasting_models.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Torch Forecasting Models</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="covariates.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Covariates</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2020 - 2023, Unit8 SA (Apache 2.0 License).<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.3.2.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>