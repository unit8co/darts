
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>darts.utils.likelihood_models.torch &#8212; darts  documentation</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <link rel="shortcut icon" href="../../../../_static/docs-favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../../index.html">
  <img src="../../../../_static/darts-logo-trim.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../README.html">
  Home
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../quickstart/00-quickstart.html">
  Quickstart
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../userguide.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../generated_api/darts.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../examples.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../release_notes/RELEASE_NOTES.html">
  Release Notes
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/unit8co/darts" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/unit8co" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for darts.utils.likelihood_models.torch</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Likelihoods for `TorchForecastingModel`</span>
<span class="sd">---------------------------------------</span>

<span class="sd">The likelihood models contain all the logic needed to train and use Darts&#39; neural network models in</span>
<span class="sd">a probabilistic way. This essentially means computing an appropriate training loss and sample from the</span>
<span class="sd">distribution, given the parameters of the distribution.</span>

<span class="sd">By default, all versions will be trained using their negative log likelihood as a loss function</span>
<span class="sd">(hence performing maximum likelihood estimation when training the model).</span>
<span class="sd">However, most likelihoods also optionally support specifying time-independent &quot;prior&quot;</span>
<span class="sd">beliefs about the distribution parameters.</span>
<span class="sd">In such cases, the KL-divergence term is added to the loss in order to regularise it in the</span>
<span class="sd">direction of the specified prior distribution. (Note that this is technically not purely</span>
<span class="sd">a Bayesian approach as the priors are actual parameters values, and not distributions).</span>
<span class="sd">The parameter `prior_strength` controls the strength of the &quot;prior&quot; regularisation on the loss.</span>

<span class="sd">Some distributions (such as ``GaussianLikelihood``, and ``PoissonLikelihood``) are univariate,</span>
<span class="sd">in which case they are applied to model each component of multivariate series independently.</span>
<span class="sd">Some other distributions (such as ``DirichletLikelihood``) are multivariate,</span>
<span class="sd">in which case they will model all components of multivariate time series jointly.</span>

<span class="sd">Univariate likelihoods accept either scalar or array-like values for the optional prior parameters.</span>
<span class="sd">If a scalar is provided, it is used as a prior for all components of the series. If an array-like is provided,</span>
<span class="sd">the i-th value will be used as a prior for the i-th component of the series. Multivariate likelihoods</span>
<span class="sd">require array-like objects when specifying priors.</span>

<span class="sd">The target series used for training must always lie within the distribution&#39;s support, otherwise</span>
<span class="sd">errors will be raised during training. You can refer to the individual likelihoods&#39; documentation</span>
<span class="sd">to see what is the support. Similarly, the prior parameters also have to lie in some pre-defined domains.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">collections.abc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Bernoulli</span> <span class="k">as</span> <span class="n">_Bernoulli</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Beta</span> <span class="k">as</span> <span class="n">_Beta</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Cauchy</span> <span class="k">as</span> <span class="n">_Cauchy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">ContinuousBernoulli</span> <span class="k">as</span> <span class="n">_ContinuousBernoulli</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dirichlet</span> <span class="k">as</span> <span class="n">_Dirichlet</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Exponential</span> <span class="k">as</span> <span class="n">_Exponential</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Gamma</span> <span class="k">as</span> <span class="n">_Gamma</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Geometric</span> <span class="k">as</span> <span class="n">_Geometric</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Gumbel</span> <span class="k">as</span> <span class="n">_Gumbel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">HalfNormal</span> <span class="k">as</span> <span class="n">_HalfNormal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Laplace</span> <span class="k">as</span> <span class="n">_Laplace</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogNormal</span> <span class="k">as</span> <span class="n">_LogNormal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">NegativeBinomial</span> <span class="k">as</span> <span class="n">_NegativeBinomial</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Normal</span> <span class="k">as</span> <span class="n">_Normal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Poisson</span> <span class="k">as</span> <span class="n">_Poisson</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Weibull</span> <span class="k">as</span> <span class="n">_Weibull</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions.kl</span><span class="w"> </span><span class="kn">import</span> <span class="n">kl_divergence</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">darts.logging</span><span class="w"> </span><span class="kn">import</span> <span class="n">raise_if_not</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.utils.likelihood_models.base</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Likelihood</span><span class="p">,</span>
    <span class="n">LikelihoodType</span><span class="p">,</span>
    <span class="n">quantile_names</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># TODO: Table on README listing distribution, possible priors and wiki article</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.utils.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_quantiles</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">MIN_CAUCHY_GAMMA_SAMPLING</span> <span class="o">=</span> <span class="mf">1e-100</span>


<span class="c1"># Some utils for checking parameters&#39; domains</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_check</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">condition_str</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="p">(</span><span class="n">collections</span><span class="o">.</span><span class="n">abc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
        <span class="n">raise_if_not</span><span class="p">(</span>
            <span class="nb">all</span><span class="p">(</span><span class="n">predicate</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">param</span><span class="p">),</span>
            <span class="sa">f</span><span class="s2">&quot;All provided parameters </span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2"> must be </span><span class="si">{</span><span class="n">condition_str</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">raise_if_not</span><span class="p">(</span>
            <span class="n">predicate</span><span class="p">(</span><span class="n">param</span><span class="p">),</span>
            <span class="sa">f</span><span class="s2">&quot;The parameter </span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2"> must be </span><span class="si">{</span><span class="n">condition_str</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_strict_positive</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
    <span class="n">_check</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">param_name</span><span class="p">,</span> <span class="s2">&quot;strictly positive&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_in_open_0_1_intvl</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
    <span class="n">_check</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="n">param_name</span><span class="p">,</span> <span class="s2">&quot;in the open interval (0, 1)&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="TorchLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.TorchLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">TorchLikelihood</span><span class="p">(</span><span class="n">Likelihood</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">likelihood_type</span><span class="p">:</span> <span class="n">LikelihoodType</span><span class="p">,</span>
        <span class="n">parameter_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Abstract class for torch likelihood models.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        likelihood_type</span>
<span class="sd">            A pre-defined `LikelihoodType`.</span>
<span class="sd">        parameter_names</span>
<span class="sd">            The likelihood (distribution) parameter names.</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_strength</span> <span class="o">=</span> <span class="n">prior_strength</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">likelihood_type</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="n">parameter_names</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="TorchLikelihood.compute_loss"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.TorchLikelihood.compute_loss">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes a loss from a `model_output`, which represents the parameters of a given probability</span>
<span class="sd">        distribution for every ground truth value in `target`, and the `target` itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nllloss</span><span class="p">(</span><span class="n">params_out</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

        <span class="n">prior_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior_params</span>
        <span class="n">use_prior</span> <span class="o">=</span> <span class="n">prior_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span>
            <span class="n">p</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">prior_params</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">use_prior</span><span class="p">:</span>
            <span class="n">out_distr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distr_from_params</span><span class="p">(</span><span class="n">params_out</span><span class="p">)</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">params_out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
            <span class="n">prior_params</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="c1"># use model output as &quot;prior&quot; for parameters not specified as prior</span>
                <span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">prior_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">prior_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="n">params_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prior_params</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="n">prior_distr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distr_from_params</span><span class="p">(</span><span class="n">prior_params</span><span class="p">)</span>

            <span class="c1"># Loss regularization using the prior distribution</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_strength</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                <span class="n">kl_divergence</span><span class="p">(</span><span class="n">prior_distr</span><span class="p">,</span> <span class="n">out_distr</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_nllloss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params_out</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This is the basic way to compute the NLL loss. It can be overwritten by likelihoods for which</span>
<span class="sd">        PyTorch proposes a numerically better NLL loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out_distr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distr_from_params</span><span class="p">(</span><span class="n">params_out</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">out_distr</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">sample_weight</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Has to be overwritten by the Likelihood objects supporting specifying a prior distribution on the</span>
<span class="sd">        outputs. If it returns None, no prior will be used and the model will be trained with plain maximum likelihood.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a torch distribution built with the specified params</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the distribution parameters, obtained from the raw model outputs</span>
<span class="sd">        (e.g. applies softplus or sigmoids to get parameters in the expected domains).</span>
<span class="sd">        &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TorchLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.TorchLikelihood.sample">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Samples a prediction from the likelihood distribution and the predicted parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="TorchLikelihood.predict_likelihood_parameters"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.TorchLikelihood.predict_likelihood_parameters">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict_likelihood_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the distribution parameters as a single Tensor, extracted from the raw model outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">params</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># interleave the predicted parameters to group them by input series component</span>
            <span class="n">num_samples</span><span class="p">,</span> <span class="n">n_times</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span> <span class="n">n_params</span> <span class="o">=</span> <span class="n">model_output</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span>
                <span class="n">num_samples</span><span class="p">,</span>
                <span class="n">n_times</span><span class="p">,</span>
                <span class="n">n_components</span> <span class="o">*</span> <span class="n">n_params</span><span class="p">,</span>
            <span class="p">))</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_equality_attrs</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">ignore_attrs</span><span class="p">):</span>
        <span class="c1"># ignore the attributes listed in `ignore_attrs_equality` or inheriting from torch.nn.Module</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">likelihood</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ignore_attrs</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
        <span class="p">}</span></div>


<div class="viewcode-block" id="GaussianLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.GaussianLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GaussianLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">prior_mu</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_sigma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">beta_nll</span><span class="o">=</span><span class="mf">0.0</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Univariate Gaussian distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Normal_distribution</span>

<span class="sd">        Instead of the pure negative log likelihood (NLL) loss, the loss function used</span>
<span class="sd">        is the :math:`\\beta`-NLL loss [1]_, parameterized by ``beta_nll`` in (0, 1).</span>
<span class="sd">        For ``beta_nll=0`` it is equivalent to NLL, however larger values of ``beta_nll`` can</span>
<span class="sd">        mitigate issues with NLL causing effective under-sampling of poorly fit regions</span>
<span class="sd">        during training. ``beta_nll=1`` provides the same gradient for the mean as the MSE loss.</span>

<span class="sd">        - Univariate continuous distribution.</span>
<span class="sd">        - Support: :math:`\\mathbb{R}`.</span>
<span class="sd">        - Parameters: mean :math:`\\mu \\in \\mathbb{R}`, standard deviation :math:`\\sigma &gt; 0`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_mu</span>
<span class="sd">            mean of the prior Gaussian distribution (default: None).</span>
<span class="sd">        prior_sigma</span>
<span class="sd">            standard deviation (or scale) of the prior Gaussian distribution (default: None)</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        beta_nll</span>
<span class="sd">            The parameter :math:`0 \\leq \\beta \\leq 1` of the :math:`\\beta`-NLL loss [1]_.</span>
<span class="sd">            Default: 0. (equivalent to NLL)</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [1] Seitzer et al.,</span>
<span class="sd">               &quot;On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks&quot;</span>
<span class="sd">               https://arxiv.org/abs/2203.09168</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mu</span> <span class="o">=</span> <span class="n">prior_mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_sigma</span> <span class="o">=</span> <span class="n">prior_sigma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_nll</span> <span class="o">=</span> <span class="n">beta_nll</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_sigma</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nllloss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GaussianNLLLoss</span><span class="p">(</span><span class="n">full</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_nllloss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params_out</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>
        <span class="n">means_out</span><span class="p">,</span> <span class="n">sigmas_out</span> <span class="o">=</span> <span class="n">params_out</span>
        <span class="c1"># Note: GaussianNLLLoss expects variance (and not stdev)</span>
        <span class="n">cont_var</span> <span class="o">=</span> <span class="n">sigmas_out</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nllloss</span><span class="p">(</span><span class="n">means_out</span><span class="o">.</span><span class="n">contiguous</span><span class="p">(),</span> <span class="n">target</span><span class="o">.</span><span class="n">contiguous</span><span class="p">(),</span> <span class="n">cont_var</span><span class="p">)</span>
        <span class="c1"># apply Beta-NLL</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_nll</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="c1"># Note: there is no mean reduction if beta_nll &gt; 0, so we compute it here</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="p">(</span><span class="n">cont_var</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_nll</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">sample_weight</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_sigma</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">return</span> <span class="n">_Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

<div class="viewcode-block" id="GaussianLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.GaussianLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">):</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span></div>


<div class="viewcode-block" id="PoissonLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.PoissonLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">PoissonLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_lambda</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Poisson distribution. Can typically be used to model event counts during time intervals, when the events</span>
<span class="sd">        happen independently of the time since the last event.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Poisson_distribution</span>

<span class="sd">        - Univariate discrete distribution</span>
<span class="sd">        - Support: :math:`\\mathbb{N}_0` (natural numbers including 0).</span>
<span class="sd">        - Parameter: rate :math:`\\lambda &gt; 0`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_lambda</span>
<span class="sd">            rate :math:`\\lambda` of the prior Poisson distribution (default: None)</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_lambda</span> <span class="o">=</span> <span class="n">prior_lambda</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_lambda</span><span class="p">,</span> <span class="s2">&quot;lambda&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nllloss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PoissonNLLLoss</span><span class="p">(</span><span class="n">log_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">full</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Poisson</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lambda&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_nllloss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params_out</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>
        <span class="n">lambda_out</span> <span class="o">=</span> <span class="n">params_out</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nllloss</span><span class="p">(</span><span class="n">lambda_out</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">sample_weight</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_lambda</span><span class="p">,)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="n">lmbda</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">_Poisson</span><span class="p">(</span><span class="n">lmbda</span><span class="p">)</span>

<div class="viewcode-block" id="PoissonLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.PoissonLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">model_lambda</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">model_lambda</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">):</span>
        <span class="n">lmbda</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">lmbda</span></div>


<div class="viewcode-block" id="NegativeBinomialLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.NegativeBinomialLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">NegativeBinomialLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Negative Binomial distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Negative_binomial_distribution</span>

<span class="sd">        It does not support priors.</span>

<span class="sd">        - Univariate discrete distribution.</span>
<span class="sd">        - Support: :math:`\\mathbb{N}_0` (natural numbers including 0).</span>
<span class="sd">        - Parameters: number of failures :math:`r &gt; 0`, success probability :math:`p \\in (0, 1)`.</span>

<span class="sd">        Behind the scenes the distribution is reparameterized so that the actual outputs of the</span>
<span class="sd">        network are in terms of the mean :math:`\\mu` and shape :math:`\\alpha`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">NegativeBinomial</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="s2">&quot;p&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_r_and_p_from_mu_and_alpha</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="c1"># See https://en.wikipedia.org/wiki/Negative_binomial_distribution for the different parametrizations</span>
        <span class="n">r</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">alpha</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">r</span> <span class="o">/</span> <span class="p">(</span><span class="n">mu</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r</span><span class="p">,</span> <span class="n">p</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">params</span>
        <span class="n">r</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">NegativeBinomialLikelihood</span><span class="o">.</span><span class="n">_get_r_and_p_from_mu_and_alpha</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_NegativeBinomial</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<div class="viewcode-block" id="NegativeBinomialLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.NegativeBinomialLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">r</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">NegativeBinomialLikelihood</span><span class="o">.</span><span class="n">_get_r_and_p_from_mu_and_alpha</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_NegativeBinomial</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

<div class="viewcode-block" id="NegativeBinomialLikelihood.predict_likelihood_parameters"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.NegativeBinomialLikelihood.predict_likelihood_parameters">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict_likelihood_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Overwrite the parent since the parameters are extracted in two steps.&quot;&quot;&quot;</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">r</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">NegativeBinomialLikelihood</span><span class="o">.</span><span class="n">_get_r_and_p_from_mu_and_alpha</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">):</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span></div>


<div class="viewcode-block" id="BernoulliLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.BernoulliLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">BernoulliLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_p</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Bernoulli distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Bernoulli_distribution</span>

<span class="sd">        - Univariate discrete distribution.</span>
<span class="sd">        - Support: :math:`\\{0, 1\\}`.</span>
<span class="sd">        - Parameter: probability :math:`p \\in (0, 1)`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_p</span>
<span class="sd">            probability :math:`p` of the prior Bernoulli distribution (default: None)</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_p</span> <span class="o">=</span> <span class="n">prior_p</span>
        <span class="n">_check_in_open_0_1_intvl</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_p</span><span class="p">,</span> <span class="s2">&quot;p&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;p&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_p</span><span class="p">,)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">_Bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<div class="viewcode-block" id="BernoulliLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.BernoulliLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">model_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">model_p</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">model_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">p</span></div>


<div class="viewcode-block" id="BetaLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.BetaLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">BetaLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_beta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Beta distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Beta_distribution</span>

<span class="sd">        - Univariate continuous distribution.</span>
<span class="sd">        - Support: open interval :math:`(0,1)`</span>
<span class="sd">        - Parameters: shape parameters :math:`\\alpha &gt; 0` and :math:`\\beta &gt; 0`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_alpha</span>
<span class="sd">            shape parameter :math:`\\alpha` of the Beta distribution, strictly positive (default: None)</span>
<span class="sd">        prior_beta</span>
<span class="sd">            shape parameter :math:`\\beta` distribution, strictly positive (default: None)</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_alpha</span> <span class="o">=</span> <span class="n">prior_alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_beta</span> <span class="o">=</span> <span class="n">prior_beta</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_alpha</span><span class="p">,</span> <span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_beta</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Beta</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_alpha</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_beta</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">return</span> <span class="n">_Beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

<div class="viewcode-block" id="BetaLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.BetaLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_Beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">):</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span></div>


<div class="viewcode-block" id="CauchyLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.CauchyLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">CauchyLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_xzero</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Cauchy Distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Cauchy_distribution</span>

<span class="sd">        - Univariate continuous distribution.</span>
<span class="sd">        - Support: :math:`\\mathbb{R}`.</span>
<span class="sd">        - Parameters: location :math:`x_0 \\in \\mathbb{R}`, scale :math:`\\gamma &gt; 0`.</span>

<span class="sd">        Due to its fat tails, this distribution is typically harder to estimate,</span>
<span class="sd">        and your mileage may vary. Also be aware that it typically</span>
<span class="sd">        requires a large value for `num_samples` for sampling predictions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_xzero</span>
<span class="sd">            location parameter :math:`x_0` of the Cauchy distribution (default: None)</span>
<span class="sd">        prior_gamma</span>
<span class="sd">            scale parameter :math:`\\gamma` of the Cauchy distribution, strictly positive (default: None)</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_xzero</span> <span class="o">=</span> <span class="n">prior_xzero</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_gamma</span> <span class="o">=</span> <span class="n">prior_gamma</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_gamma</span><span class="p">,</span> <span class="s2">&quot;gamma&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Cauchy</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;xzero&quot;</span><span class="p">,</span> <span class="s2">&quot;gamma&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_xzero</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_gamma</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="n">xzero</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">return</span> <span class="n">_Cauchy</span><span class="p">(</span><span class="n">xzero</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)</span>

<div class="viewcode-block" id="CauchyLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.CauchyLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">xzero</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_Cauchy</span><span class="p">(</span><span class="n">xzero</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">):</span>
        <span class="n">xzero</span> <span class="o">=</span> <span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="c1"># We need this hack as sometimes the output of the softplus is 0 in practice for Cauchy...</span>
        <span class="n">gamma</span><span class="p">[</span><span class="n">gamma</span> <span class="o">&lt;</span> <span class="n">MIN_CAUCHY_GAMMA_SAMPLING</span><span class="p">]</span> <span class="o">=</span> <span class="n">MIN_CAUCHY_GAMMA_SAMPLING</span>
        <span class="k">return</span> <span class="n">xzero</span><span class="p">,</span> <span class="n">gamma</span></div>


<div class="viewcode-block" id="ContinuousBernoulliLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.ContinuousBernoulliLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ContinuousBernoulliLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_lambda</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Continuous Bernoulli distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Continuous_Bernoulli_distribution</span>

<span class="sd">        - Univariate continuous distribution.</span>
<span class="sd">        - Support: open interval :math:`(0, 1)`.</span>
<span class="sd">        - Parameter: shape :math:`\\lambda \\in (0,1)`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_lambda</span>
<span class="sd">            shape :math:`\\lambda` of the prior Continuous Bernoulli distribution (default: None)</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_lambda</span> <span class="o">=</span> <span class="n">prior_lambda</span>
        <span class="n">_check_in_open_0_1_intvl</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_lambda</span><span class="p">,</span> <span class="s2">&quot;lambda&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">ContinuousBernoulli</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lambda&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_lambda</span><span class="p">,)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="n">lmbda</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">_ContinuousBernoulli</span><span class="p">(</span><span class="n">lmbda</span><span class="p">)</span>

<div class="viewcode-block" id="ContinuousBernoulliLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.ContinuousBernoulliLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">model_lmbda</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_ContinuousBernoulli</span><span class="p">(</span><span class="n">model_lmbda</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">lmbda</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">model_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">lmbda</span></div>


<div class="viewcode-block" id="DirichletLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.DirichletLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DirichletLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_alphas</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Dirichlet distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Dirichlet_distribution</span>

<span class="sd">        - Multivariate continuous distribution, modeling all components of a time series jointly.</span>
<span class="sd">        - Support: The :math:`K`-dimensional simplex for series of dimension :math:`K`, i.e.,</span>
<span class="sd">          :math:`x_1, ..., x_K \\text{ with } x_i \\in (0,1),\\; \\sum_i^K{x_i}=1`.</span>
<span class="sd">        - Parameter: concentrations :math:`\\alpha_1, ..., \\alpha_K` with :math:`\\alpha_i &gt; 0`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_alphas</span>
<span class="sd">            concentrations parameters :math:`\\alpha` of the prior Dirichlet distribution.</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_alphas</span> <span class="o">=</span> <span class="n">prior_alphas</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_alphas</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Dirichlet</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_alphas</span><span class="p">,)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">alphas</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">_Dirichlet</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span>

<div class="viewcode-block" id="DirichletLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.DirichletLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">alphas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_Dirichlet</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

<div class="viewcode-block" id="DirichletLikelihood.predict_likelihood_parameters"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.DirichletLikelihood.predict_likelihood_parameters">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict_likelihood_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">alphas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">alphas</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">):</span>
        <span class="n">alphas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="n">model_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># take softmax over components</span>
        <span class="k">return</span> <span class="n">alphas</span></div>


<div class="viewcode-block" id="ExponentialLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.ExponentialLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ExponentialLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_lambda</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Exponential distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Exponential_distribution</span>

<span class="sd">        - Univariate continuous distribution.</span>
<span class="sd">        - Support: :math:`\\mathbb{R}_{&gt;0}`.</span>
<span class="sd">        - Parameter: rate :math:`\\lambda &gt; 0`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_lambda</span>
<span class="sd">            rate :math:`\\lambda` of the prior exponential distribution (default: None).</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_lambda</span> <span class="o">=</span> <span class="n">prior_lambda</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_lambda</span><span class="p">,</span> <span class="s2">&quot;lambda&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Exponential</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lambda&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_lambda</span><span class="p">,)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">lmbda</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">_Exponential</span><span class="p">(</span><span class="n">lmbda</span><span class="p">)</span>

<div class="viewcode-block" id="ExponentialLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.ExponentialLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">lmbda</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_Exponential</span><span class="p">(</span><span class="n">lmbda</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">lmbda</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">lmbda</span></div>


<div class="viewcode-block" id="GammaLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.GammaLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GammaLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_beta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gamma distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Gamma_distribution</span>

<span class="sd">        - Univariate continuous distribution</span>
<span class="sd">        - Support: :math:`\\mathbb{R}_{&gt;0}`.</span>
<span class="sd">        - Parameters: shape :math:`\\alpha &gt; 0` and rate :math:`\\beta &gt; 0`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_alpha</span>
<span class="sd">            shape :math:`\\alpha` of the prior gamma distribution (default: None).</span>
<span class="sd">        prior_beta</span>
<span class="sd">            rate :math:`\\beta` of the prior gamma distribution (default: None).</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_alpha</span> <span class="o">=</span> <span class="n">prior_alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_beta</span> <span class="o">=</span> <span class="n">prior_beta</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_alpha</span><span class="p">,</span> <span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_beta</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Gamma</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_alpha</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_beta</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">return</span> <span class="n">_Gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

<div class="viewcode-block" id="GammaLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.GammaLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_Gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span></div>


<div class="viewcode-block" id="GeometricLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.GeometricLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GeometricLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_p</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Geometric distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Geometric_distribution</span>

<span class="sd">        - Univariate discrete distribution</span>
<span class="sd">        - Support: :math:`\\mathbb{N}_0` (natural numbers including 0).</span>
<span class="sd">        - Parameter: success probability :math:`p \\in (0, 1)`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_p</span>
<span class="sd">            success probability :math:`p` of the prior geometric distribution (default: None)</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_p</span> <span class="o">=</span> <span class="n">prior_p</span>
        <span class="n">_check_in_open_0_1_intvl</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_p</span><span class="p">,</span> <span class="s2">&quot;p&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Geometric</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;p&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_p</span><span class="p">,)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">_Geometric</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<div class="viewcode-block" id="GeometricLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.GeometricLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_Geometric</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">model_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">p</span></div>


<div class="viewcode-block" id="GumbelLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.GumbelLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GumbelLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_mu</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_beta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gumbel distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Gumbel_distribution</span>

<span class="sd">        - Univariate continuous distribution</span>
<span class="sd">        - Support: :math:`\\mathbb{R}`.</span>
<span class="sd">        - Parameters: location :math:`\\mu \\in \\mathbb{R}` and scale :math:`\\beta &gt; 0`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_mu</span>
<span class="sd">            location :math:`\\mu` of the prior Gumbel distribution (default: None).</span>
<span class="sd">        prior_beta</span>
<span class="sd">            scale :math:`\\beta` of the prior Gumbel distribution (default: None).</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mu</span> <span class="o">=</span> <span class="n">prior_mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_beta</span> <span class="o">=</span> <span class="n">prior_beta</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_beta</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Gumbel</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_beta</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">return</span> <span class="n">_Gumbel</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

<div class="viewcode-block" id="GumbelLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.GumbelLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_Gumbel</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">beta</span></div>


<div class="viewcode-block" id="HalfNormalLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.HalfNormalLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">HalfNormalLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_sigma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Half-normal distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Half-normal_distribution</span>

<span class="sd">        - Univariate continuous distribution.</span>
<span class="sd">        - Support: :math:`\\mathbb{R}_{&gt;0}`.</span>
<span class="sd">        - Parameter: rate :math:`\\sigma &gt; 0`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_sigma</span>
<span class="sd">            standard deviation :math:`\\sigma` of the prior half-normal distribution (default: None).</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_sigma</span> <span class="o">=</span> <span class="n">prior_sigma</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_sigma</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_sigma</span><span class="p">,)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">_HalfNormal</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>

<div class="viewcode-block" id="HalfNormalLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.HalfNormalLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_HalfNormal</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">sigma</span></div>


<div class="viewcode-block" id="LaplaceLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.LaplaceLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">LaplaceLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_mu</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_b</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Laplace distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Laplace_distribution</span>

<span class="sd">        - Univariate continuous distribution</span>
<span class="sd">        - Support: :math:`\\mathbb{R}`.</span>
<span class="sd">        - Parameters: location :math:`\\mu \\in \\mathbb{R}` and scale :math:`b &gt; 0`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_mu</span>
<span class="sd">            location :math:`\\mu` of the prior Laplace distribution (default: None).</span>
<span class="sd">        prior_b</span>
<span class="sd">            scale :math:`b` of the prior Laplace distribution (default: None).</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mu</span> <span class="o">=</span> <span class="n">prior_mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_b</span> <span class="o">=</span> <span class="n">prior_b</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_b</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Laplace</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_b</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">return</span> <span class="n">_Laplace</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<div class="viewcode-block" id="LaplaceLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.LaplaceLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_Laplace</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">b</span></div>


<div class="viewcode-block" id="LogNormalLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.LogNormalLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">LogNormalLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_mu</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_sigma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Log-normal distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Log-normal_distribution</span>

<span class="sd">        - Univariate continuous distribution.</span>
<span class="sd">        - Support: :math:`\\mathbb{R}_{&gt;0}`.</span>
<span class="sd">        - Parameters: :math:`\\mu \\in \\mathbb{R}` and :math:`\\sigma &gt; 0`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_mu</span>
<span class="sd">            parameter :math:`\\mu` of the prior log-normal distribution (default: None).</span>
<span class="sd">        prior_sigma</span>
<span class="sd">            parameter :math:`\\sigma` of the prior log-normal distribution (default: None)</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mu</span> <span class="o">=</span> <span class="n">prior_mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_sigma</span> <span class="o">=</span> <span class="n">prior_sigma</span>
        <span class="n">_check_strict_positive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_sigma</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_sigma</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">return</span> <span class="n">_LogNormal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

<div class="viewcode-block" id="LogNormalLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.LogNormalLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_LogNormal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">):</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span></div>


<div class="viewcode-block" id="WeibullLikelihood"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.WeibullLikelihood">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">WeibullLikelihood</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Weibull distribution.</span>

<span class="sd">        https://en.wikipedia.org/wiki/Weibull_distribution</span>

<span class="sd">        - Univariate continuous distribution</span>
<span class="sd">        - Support: :math:`\\mathbb{R}_{&gt;0}`.</span>
<span class="sd">        - Parameters: scale :math:`\\lambda &gt; 0` and concentration :math:`k &gt; 0`.</span>

<span class="sd">        It does not support priors.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_strength</span>
<span class="sd">            strength of the loss regularisation induced by the prior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Weibull</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lambda&quot;</span><span class="p">,</span> <span class="s2">&quot;k&quot;</span><span class="p">],</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="n">prior_strength</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prior_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">lmba</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">return</span> <span class="n">_Weibull</span><span class="p">(</span><span class="n">lmba</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>

<div class="viewcode-block" id="WeibullLikelihood.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.WeibullLikelihood.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">lmbda</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_from_output</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
        <span class="n">distr</span> <span class="o">=</span> <span class="n">_Weibull</span><span class="p">(</span><span class="n">lmbda</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distr</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">lmbda</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">model_output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">lmbda</span><span class="p">,</span> <span class="n">k</span></div>


<div class="viewcode-block" id="QuantileRegression"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.QuantileRegression">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">QuantileRegression</span><span class="p">(</span><span class="n">TorchLikelihood</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quantiles</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The &quot;likelihood&quot; corresponding to quantile regression.</span>
<span class="sd">        It uses the Quantile Loss Metric for custom quantiles centered around q=0.5.</span>

<span class="sd">        This class can be used as any other Likelihood objects even though it is not</span>
<span class="sd">        representing the likelihood of a well defined distribution.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        quantiles</span>
<span class="sd">            list of quantiles</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">quantiles</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span> <span class="o">=</span> <span class="p">[</span>
                <span class="mf">0.01</span><span class="p">,</span>
                <span class="mf">0.05</span><span class="p">,</span>
                <span class="mf">0.1</span><span class="p">,</span>
                <span class="mf">0.15</span><span class="p">,</span>
                <span class="mf">0.2</span><span class="p">,</span>
                <span class="mf">0.25</span><span class="p">,</span>
                <span class="mf">0.3</span><span class="p">,</span>
                <span class="mf">0.4</span><span class="p">,</span>
                <span class="mf">0.5</span><span class="p">,</span>
                <span class="mf">0.6</span><span class="p">,</span>
                <span class="mf">0.7</span><span class="p">,</span>
                <span class="mf">0.75</span><span class="p">,</span>
                <span class="mf">0.8</span><span class="p">,</span>
                <span class="mf">0.85</span><span class="p">,</span>
                <span class="mf">0.9</span><span class="p">,</span>
                <span class="mf">0.95</span><span class="p">,</span>
                <span class="mf">0.99</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">quantiles</span><span class="p">)</span>
        <span class="n">_check_quantiles</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_median_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">first</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_tensor</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">likelihood_type</span><span class="o">=</span><span class="n">LikelihoodType</span><span class="o">.</span><span class="n">Quantile</span><span class="p">,</span>
            <span class="n">parameter_names</span><span class="o">=</span><span class="n">quantile_names</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">),</span>
            <span class="n">prior_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># ignore additional attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_attrs_equality</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;_median_idx&quot;</span><span class="p">,</span> <span class="s2">&quot;first&quot;</span><span class="p">,</span> <span class="s2">&quot;quantiles_tensor&quot;</span><span class="p">]</span>

<div class="viewcode-block" id="QuantileRegression.sample"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.QuantileRegression.sample">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sample uniformly between [0, 1] (for each batch example) and return the linear interpolation between the fitted</span>
<span class="sd">        quantiles closest to the sampled value.</span>

<span class="sd">        model_output is of shape (batch_size, n_timesteps, n_components, n_quantiles)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">model_output</span><span class="o">.</span><span class="n">device</span>
        <span class="n">num_samples</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span> <span class="n">n_quantiles</span> <span class="o">=</span> <span class="n">model_output</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># obtain samples</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="p">(</span>
                <span class="n">num_samples</span><span class="p">,</span>
                <span class="n">n_timesteps</span><span class="p">,</span>
                <span class="n">n_components</span><span class="p">,</span>
                <span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># add dummy dim</span>
        <span class="n">probas</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># tile and transpose</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">probas</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_quantiles</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="c1"># prepare quantiles</span>
        <span class="n">tquantiles</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># calculate index of biggest quantile smaller than the sampled value</span>
        <span class="n">left_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span> <span class="o">&gt;</span> <span class="n">tquantiles</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># obtain index of smallest quantile bigger than sampled value</span>
        <span class="n">right_idx</span> <span class="o">=</span> <span class="n">left_idx</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># repeat the model output on the edges</span>
        <span class="n">repeat_count</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_quantiles</span>
        <span class="n">repeat_count</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">repeat_count</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">repeat_count</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">repeat_count</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">shifted_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">model_output</span><span class="p">,</span> <span class="n">repeat_count</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># obtain model output values corresponding to the quantiles left and right of the sampled value</span>
        <span class="n">left_value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">shifted_output</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">left_idx</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">right_value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">shifted_output</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">right_idx</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># add 0 and 1 to quantiles</span>
        <span class="n">ext_quantiles</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span> <span class="o">+</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]</span>
        <span class="n">expanded_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ext_quantiles</span><span class="p">),</span> <span class="n">left_idx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># calculate closest quantiles to the sampled value</span>
        <span class="n">left_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">expanded_q</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">left_idx</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">right_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">expanded_q</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">right_idx</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># linear interpolation</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span><span class="n">probs</span> <span class="o">-</span> <span class="n">left_q</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">right_q</span> <span class="o">-</span> <span class="n">left_q</span><span class="p">)</span>
        <span class="n">inter</span> <span class="o">=</span> <span class="n">left_value</span> <span class="o">+</span> <span class="n">weights</span> <span class="o">*</span> <span class="p">(</span><span class="n">right_value</span> <span class="o">-</span> <span class="n">left_value</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">inter</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="QuantileRegression.predict_likelihood_parameters"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.QuantileRegression.predict_likelihood_parameters">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict_likelihood_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Overwrite parent method since QuantileRegression is not a Likelihood per-se and</span>
<span class="sd">        parameters must be extracted differently.&quot;&quot;&quot;</span>
        <span class="n">num_samples</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span> <span class="n">n_quantiles</span> <span class="o">=</span> <span class="n">model_output</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">model_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">num_samples</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">,</span> <span class="n">n_components</span> <span class="o">*</span> <span class="n">n_quantiles</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">params</span></div>

<div class="viewcode-block" id="QuantileRegression.compute_loss"><a class="viewcode-back" href="../../../../generated_api/darts.utils.likelihood_models.torch.html#darts.utils.likelihood_models.torch.QuantileRegression.compute_loss">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        We are re-defining a custom loss (which is not a likelihood loss) compared to Likelihood</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_output</span>
<span class="sd">            must be of shape (batch_size, n_timesteps, n_target_variables, n_quantiles)</span>
<span class="sd">        target</span>
<span class="sd">            must be of shape (n_samples, n_timesteps, n_target_variables)</span>
<span class="sd">        sample_weight</span>
<span class="sd">            must be of shape (n_samples, n_timesteps, n_target_variables)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dim_q</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">model_output</span><span class="o">.</span><span class="n">device</span>

        <span class="c1"># test if torch model forward produces correct output and store quantiles tensor</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">first</span><span class="p">:</span>
            <span class="n">raise_if_not</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">model_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
                <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
                <span class="ow">and</span> <span class="n">model_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span>
                <span class="s2">&quot;mismatch between predicted and target shape&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">raise_if_not</span><span class="p">(</span>
                <span class="n">model_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim_q</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">),</span>
                <span class="s2">&quot;mismatch between number of predicted quantiles and target quantiles&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">first</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">errors</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">model_output</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles_tensor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">errors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_tensor</span> <span class="o">*</span> <span class="n">errors</span>
        <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim_q</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="n">losses</span> <span class="o">*</span> <span class="n">sample_weight</span>
        <span class="k">return</span> <span class="n">losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_distr_from_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># This should not be called in this class (we are abusing Likelihood)</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_params_from_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># This should not be called in this class (we are abusing Likelihood)</span>
        <span class="k">return</span> <span class="kc">None</span></div>


<span class="sd">&quot;&quot;&quot; TODO</span>
<span class="sd">To make it work, we&#39;ll have to change our models so they optionally accept an absolute</span>
<span class="sd">number of parameters, instead of num_parameters per component.</span>

<span class="sd">from torch.distributions import MultivariateNormal as _MultivariateNormal</span>
<span class="sd">    class MultivariateNormal(Likelihood):</span>
<span class="sd">        def __init__(</span>
<span class="sd">            self, dim: int, prior_mu=None, prior_covmat=None, prior_strength=1.0</span>
<span class="sd">        ):</span>
<span class="sd">            self.dim = dim</span>
<span class="sd">            self.prior_mu = prior_mu</span>
<span class="sd">            self.prior_covmat = prior_covmat</span>
<span class="sd">            if self.prior_mu is not None:</span>
<span class="sd">                raise_if_not(</span>
<span class="sd">                    len(self.prior_mu) == self.dim,</span>
<span class="sd">                    &quot;The provided prior_mu must have a size matching the &quot;</span>
<span class="sd">                    &quot;provided dimension.&quot;,</span>
<span class="sd">                )</span>
<span class="sd">            if self.prior_covmat is not None:</span>
<span class="sd">                raise_if_not(</span>
<span class="sd">                    self.prior_covmat.shape == (self.dim, self.dim),</span>
<span class="sd">                    &quot;The provided prior on the covariaance &quot;</span>
<span class="sd">                    &quot;matrix must have size (dim, dim).&quot;,</span>
<span class="sd">                )</span>
<span class="sd">                _check_strict_positive(self.prior_covmat.flatten(), &quot;covariance matrix&quot;)</span>

<span class="sd">            self.softplus = nn.Softplus()</span>
<span class="sd">            super().__init__(prior_strength)</span>

<span class="sd">        @property</span>
<span class="sd">        def _prior_params(self):</span>
<span class="sd">            return self.prior_mu, self.prior_covmat</span>

<span class="sd">        def _distr_from_params(self, params: Tuple):</span>
<span class="sd">            mu, covmat = params</span>
<span class="sd">            return _MultivariateNormal(mu, covmat)</span>

<span class="sd">        def sample(self, model_output: torch.Tensor):</span>
<span class="sd">            mu, covmat = self._params_from_output(model_output)</span>
<span class="sd">            distr = _MultivariateNormal(mu, covmat)</span>
<span class="sd">            return distr.sample()</span>

<span class="sd">        @property</span>
<span class="sd">        def num_parameters(self) -&gt; int:</span>
<span class="sd">            return int(self.dim + (self.dim ** 2 - self.dim) / 2)</span>

<span class="sd">        def _params_from_output(self, model_output: torch.Tensor):</span>
<span class="sd">            device = model_output.device</span>
<span class="sd">            mu = model_output[:, :, : self.dim]</span>
<span class="sd">            covmat_coefs = self.softplus(model_output[:, :, self.dim :])</span>

<span class="sd">            print(&quot;model output: {}&quot;.format(model_output.shape))</span>

<span class="sd">            # build covariance matrix</span>
<span class="sd">            covmat = torch.zeros(</span>
<span class="sd">                (model_output.shape[0], model_output.shape[1], self.dim, self.dim)</span>
<span class="sd">            ).to(device)</span>
<span class="sd">            tril_indices = torch.tril_indices(</span>
<span class="sd">                row=self.dim, col=self.dim, offset=1, device=device</span>
<span class="sd">            )</span>
<span class="sd">            covmat[tril_indices[0], tril_indices[1]] = covmat_coefs</span>
<span class="sd">            covmat[tril_indices[1], tril_indices[0]] = covmat_coefs</span>
<span class="sd">            covmat[range(self.dim), range(self.dim)] = 1.0</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2020 - 2025, Unit8 SA (Apache 2.0 License).<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.0.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>