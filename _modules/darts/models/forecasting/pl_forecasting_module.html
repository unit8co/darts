
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>darts.models.forecasting.pl_forecasting_module &#8212; darts  documentation</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <link rel="shortcut icon" href="../../../../_static/docs-favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../../index.html">
  <img src="../../../../_static/darts-logo-trim.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../README.html">
  Home
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../quickstart/00-quickstart.html">
  Quickstart
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../userguide.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../generated_api/darts.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../examples.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../release_notes/RELEASE_NOTES.html">
  Release Notes
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/unit8co/darts" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/unit8co" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for darts.models.forecasting.pl_forecasting_module</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This file contains abstract classes for deterministic and probabilistic PyTorch Lightning Modules</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">wraps</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pytorch_lightning</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchmetrics</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">darts.logging</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_logger</span><span class="p">,</span> <span class="n">raise_if</span><span class="p">,</span> <span class="n">raise_log</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.models.components.layer_norm_variants</span><span class="w"> </span><span class="kn">import</span> <span class="n">RINorm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.utils.data.torch_datasets.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">PLModuleInput</span><span class="p">,</span>
    <span class="n">TorchBatch</span><span class="p">,</span>
    <span class="n">TorchInferenceBatch</span><span class="p">,</span>
    <span class="n">TorchTrainingBatch</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.utils.likelihood_models.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchLikelihood</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.utils.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">MonteCarloDropout</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="io_processor"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.io_processor">[docs]</a><span class="k">def</span><span class="w"> </span><span class="nf">io_processor</span><span class="p">(</span><span class="n">forward</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Applies some input / output processing to PLForecastingModule.forward.</span>
<span class="sd">    Note that this wrapper must be added to each of PLForecastinModule&#39;s subclasses forward methods.</span>
<span class="sd">    Here is an example how to add the decorator:</span>

<span class="sd">    ```python</span>
<span class="sd">        @io_processor</span>
<span class="sd">        def forward(self, *args, **kwargs)</span>
<span class="sd">            pass</span>
<span class="sd">    ```</span>

<span class="sd">    Applies</span>
<span class="sd">    -------</span>
<span class="sd">    Reversible Instance Normalization</span>
<span class="sd">        normalizes batch input target features, and inverse transform the forward output back to the original scale</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@wraps</span><span class="p">(</span><span class="n">forward</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward_wrapper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">:</span> <span class="n">PLModuleInput</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reversible_instance_norm</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># `x_in` is input batch tuple which by definition has the past features in the first element</span>
        <span class="c1"># starting with the first n target features; clone it to prevent target re-normalization</span>
        <span class="n">past_features</span> <span class="o">=</span> <span class="n">x_in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="c1"># apply reversible instance normalization</span>
        <span class="n">past_features</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_targets</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rin</span><span class="p">(</span>
            <span class="n">past_features</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_targets</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="c1"># run the forward pass</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">((</span><span class="n">past_features</span><span class="p">,</span> <span class="o">*</span><span class="n">x_in</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="o">*</span><span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># inverse transform target output back to original scale</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="c1"># RNNModel return tuple with hidden state</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rin</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="o">*</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># all other models return only the prediction</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rin</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">forward_wrapper</span></div>


<div class="viewcode-block" id="PLForecastingModule"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">PLForecastingModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_chunk_shift</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">train_sample_shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">_Loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span>
        <span class="n">torch_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="n">torchmetrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">,</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MetricCollection</span><span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">likelihood</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TorchLikelihood</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">optimizer_cls</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
        <span class="n">optimizer_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lr_scheduler_cls</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">_LRScheduler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lr_scheduler_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_reversible_instance_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        PyTorch Lightning-based Forecasting Module.</span>

<span class="sd">        This class is meant to be inherited to create a new PyTorch Lightning-based forecasting module.</span>
<span class="sd">        When subclassing this class, please make sure to add the following methods with the given signatures:</span>
<span class="sd">            - :func:`PLForecastingModule.__init__()`</span>
<span class="sd">            - :func:`PLForecastingModule.forward()`</span>
<span class="sd">            - :func:`PLForecastingModule._process_input_batch()`</span>
<span class="sd">            - :func:`PLForecastingModule._produce_train_output()`</span>
<span class="sd">            - :func:`PLForecastingModule._get_batch_prediction()`</span>

<span class="sd">        In subclass `MyModel`&#39;s :func:`__init__` function call ``super(MyModel, self).__init__(**kwargs)`` where</span>
<span class="sd">        ``kwargs`` are the parameters of :class:`PLForecastingModule`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_chunk_length</span>
<span class="sd">            Number of time steps in the past to take as a model input (per chunk). Applies to the target</span>
<span class="sd">            series, and past and/or future covariates (if the model supports it).</span>
<span class="sd">        output_chunk_length</span>
<span class="sd">            Number of time steps predicted at once (per chunk) by the internal model. Also, the number of future values</span>
<span class="sd">            from future covariates to use as a model input (if the model supports future covariates). It is not the same</span>
<span class="sd">            as forecast horizon `n` used in `predict()`, which is the desired number of prediction points generated</span>
<span class="sd">            using either a one-shot- or autoregressive forecast. Setting `n &lt;= output_chunk_length` prevents</span>
<span class="sd">            auto-regression. This is useful when the covariates don&#39;t extend far enough into the future, or to prohibit</span>
<span class="sd">            the model from using future values of past and / or future covariates for prediction (depending on the</span>
<span class="sd">            model&#39;s covariate support).</span>
<span class="sd">        train_sample_shape</span>
<span class="sd">            Shape of the model&#39;s input, used to instantiate model without calling ``fit_from_dataset`` and</span>
<span class="sd">            perform sanity check on new training/inference datasets used for re-training or prediction.</span>
<span class="sd">        loss_fn</span>
<span class="sd">            PyTorch loss function used for training.</span>
<span class="sd">            This parameter will be ignored for probabilistic models if the ``likelihood`` parameter is specified.</span>
<span class="sd">            Default: ``torch.nn.MSELoss()``.</span>
<span class="sd">        torch_metrics</span>
<span class="sd">            A torch metric or a ``MetricCollection`` used for evaluation. A full list of available metrics can be found</span>
<span class="sd">            at https://torchmetrics.readthedocs.io/en/latest/. Default: ``None``.</span>
<span class="sd">        likelihood</span>
<span class="sd">            One of Darts&#39; :meth:`Likelihood &lt;darts.utils.likelihood_models.torch.TorchLikelihood&gt;` models to be used for</span>
<span class="sd">            probabilistic forecasts. Default: ``None``.</span>
<span class="sd">        optimizer_cls</span>
<span class="sd">            The PyTorch optimizer class to be used. Default: ``torch.optim.Adam``.</span>
<span class="sd">        optimizer_kwargs</span>
<span class="sd">            Optionally, some keyword arguments for the PyTorch optimizer (e.g., ``{&#39;lr&#39;: 1e-3}``</span>
<span class="sd">            for specifying a learning rate). Otherwise the default values of the selected ``optimizer_cls``</span>
<span class="sd">            will be used. Default: ``None``.</span>
<span class="sd">        lr_scheduler_cls</span>
<span class="sd">            Optionally, the PyTorch learning rate scheduler class to be used. Specifying ``None`` corresponds</span>
<span class="sd">            to using a constant learning rate. Default: ``None``.</span>
<span class="sd">        lr_scheduler_kwargs</span>
<span class="sd">            Optionally, some keyword arguments for the PyTorch learning rate scheduler. Default: ``None``.</span>
<span class="sd">        use_reversible_instance_norm</span>
<span class="sd">            Whether to use reversible instance normalization `RINorm` against distribution shift as shown in [1]_.</span>
<span class="sd">            It is only applied to the features of the target series and not the covariates.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [1] T. Kim et al. &quot;Reversible Instance Normalization for Accurate Time-Series Forecasting against</span>
<span class="sd">                Distribution Shift&quot;, https://openreview.net/forum?id=cGDAkQo1C0p</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># save hyper parameters for saving/loading</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;loss_fn&quot;</span><span class="p">,</span> <span class="s2">&quot;torch_metrics&quot;</span><span class="p">])</span>

        <span class="n">raise_if</span><span class="p">(</span>
            <span class="n">input_chunk_length</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">output_chunk_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;Both `input_chunk_length` and `output_chunk_length` must be passed to `PLForecastingModule`&quot;</span><span class="p">,</span>
            <span class="n">logger</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_chunk_length</span> <span class="o">=</span> <span class="n">input_chunk_length</span>
        <span class="c1"># output_chunk_length is a property</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_chunk_length</span> <span class="o">=</span> <span class="n">output_chunk_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_shift</span> <span class="o">=</span> <span class="n">output_chunk_shift</span>

        <span class="c1"># define the loss function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_criterion</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_criterion</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)</span>
        <span class="c1"># reduction will be set to `None` when calling `TFM.fit()` with sample weights;</span>
        <span class="c1"># reset the actual criterion in method `on_fit_end()`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_criterion_reduction</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_criterion_reduction</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># by default models are deterministic (i.e. not probabilistic)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">likelihood</span>

        <span class="c1"># saved in checkpoint to be able to instantiate a model without calling fit_from_dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_sample_shape</span> <span class="o">=</span> <span class="n">train_sample_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_targets</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">train_sample_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">train_sample_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="p">)</span>

        <span class="c1"># persist optimiser and LR scheduler parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_cls</span> <span class="o">=</span> <span class="n">optimizer_cls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span> <span class="k">if</span> <span class="n">optimizer_kwargs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">optimizer_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_cls</span> <span class="o">=</span> <span class="n">lr_scheduler_cls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_kwargs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">dict</span><span class="p">()</span> <span class="k">if</span> <span class="n">lr_scheduler_kwargs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">lr_scheduler_kwargs</span>
        <span class="p">)</span>

        <span class="c1"># convert torch_metrics to torchmetrics.MetricCollection</span>
        <span class="n">torch_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">configure_torch_metrics</span><span class="p">(</span><span class="n">torch_metrics</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span> <span class="o">=</span> <span class="n">torch_metrics</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;train_&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_metrics</span> <span class="o">=</span> <span class="n">torch_metrics</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;val_&quot;</span><span class="p">)</span>

        <span class="c1"># reversible instance norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_reversible_instance_norm</span> <span class="o">=</span> <span class="n">use_reversible_instance_norm</span>
        <span class="k">if</span> <span class="n">use_reversible_instance_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rin</span> <span class="o">=</span> <span class="n">RINorm</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_targets</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rin</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># initialize prediction parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_n</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_num_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_roll_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predict_likelihood_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_mc_dropout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">first_prediction_index</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the index of the first predicted within the output of self.model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span>

<div class="viewcode-block" id="PLForecastingModule.forward"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.forward">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">:</span> <span class="n">PLModuleInput</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Same as :meth:`torch.nn.Module.forward`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_in</span>
<span class="sd">            ``(x_past, x_future, x_static)`` the past, future, and static features.</span>
<span class="sd">        *args</span>
<span class="sd">            Whatever you decide to pass into the forward method.</span>
<span class="sd">        **kwargs</span>
<span class="sd">            Keyword arguments are also possible.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Any</span>
<span class="sd">            The module&#39;s output.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="PLForecastingModule.training_step"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.training_step">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">train_batch</span><span class="p">:</span> <span class="n">TorchTrainingBatch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;performs the training step&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_val_step</span><span class="p">(</span>
            <span class="n">batch</span><span class="o">=</span><span class="n">train_batch</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
            <span class="n">criterion</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_criterion</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="PLForecastingModule.validation_step"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.validation_step">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">validation_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">val_batch</span><span class="p">:</span> <span class="n">TorchTrainingBatch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;performs the validation step&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_val_step</span><span class="p">(</span>
            <span class="n">batch</span><span class="o">=</span><span class="n">val_batch</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">,</span>
            <span class="n">criterion</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">val_criterion</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">val_metrics</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_train_val_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">TorchTrainingBatch</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">criterion</span><span class="p">,</span>
        <span class="n">metrics</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;performs a training or validation step&quot;&quot;&quot;</span>
        <span class="p">(</span>
            <span class="n">past_target</span><span class="p">,</span>
            <span class="n">past_covariates</span><span class="p">,</span>
            <span class="n">historic_future_covariates</span><span class="p">,</span>
            <span class="n">future_covariates</span><span class="p">,</span>
            <span class="n">static_covariates</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="p">,</span>
            <span class="n">future_target</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_produce_train_output</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">past_target</span><span class="p">,</span>
                <span class="n">past_covariates</span><span class="p">,</span>
                <span class="n">historic_future_covariates</span><span class="p">,</span>
                <span class="n">future_covariates</span><span class="p">,</span>
                <span class="n">static_covariates</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">future_target</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_loss&quot;</span><span class="p">,</span>
            <span class="n">loss</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">past_target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_metrics</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">future_target</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

<div class="viewcode-block" id="PLForecastingModule.on_fit_end"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_fit_end">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># revert the loss function reduction change when sample weights were used</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_criterion_reduction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_criterion</span><span class="o">.</span><span class="n">reduction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_criterion_reduction</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_criterion_reduction</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_criterion_reduction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_criterion</span><span class="o">.</span><span class="n">reduction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_criterion_reduction</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_criterion_reduction</span> <span class="o">=</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="PLForecastingModule.on_train_epoch_end"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_train_epoch_end">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_metrics</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="p">)</span></div>

<div class="viewcode-block" id="PLForecastingModule.on_validation_epoch_end"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_validation_epoch_end">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">on_validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_metrics</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_metrics</span><span class="p">)</span></div>

<div class="viewcode-block" id="PLForecastingModule.on_predict_start"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_start">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">on_predict_start</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># optionally, activate monte carlo dropout for prediction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_mc_dropout</span><span class="p">(</span><span class="n">active</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pred_mc_dropout</span><span class="p">)</span></div>

<div class="viewcode-block" id="PLForecastingModule.on_predict_end"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_predict_end">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># deactivate, monte carlo dropout for any downstream task</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_mc_dropout</span><span class="p">(</span><span class="n">active</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="PLForecastingModule.predict_step"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.predict_step">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">TorchInferenceBatch</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dataloader_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">Sequence</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span>
        <span class="n">Sequence</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
    <span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;performs the prediction step</span>

<span class="sd">        batch</span>
<span class="sd">            output of Darts&#39; :class:`TorchInferenceDataset` - tuple of ``(past target, past cov,</span>
<span class="sd">            future past cov, historic future cov, future cov, static cov, target series schema,</span>
<span class="sd">            prediction start time step)``</span>
<span class="sd">        batch_idx</span>
<span class="sd">            the batch index of the current batch</span>
<span class="sd">        dataloader_idx</span>
<span class="sd">            the dataloader index</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># batch has elements (past target, past cov, future past cov, historic future cov, future cov,</span>
        <span class="c1"># static cov, target series schema, pred start time)</span>
        <span class="n">input_data_tuple</span><span class="p">,</span> <span class="n">batch_series_schemas</span><span class="p">,</span> <span class="n">batch_pred_starts</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">batch</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span>
            <span class="n">batch</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span>
            <span class="n">batch</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="c1"># number of individual series to be predicted in current batch</span>
        <span class="n">num_series</span> <span class="o">=</span> <span class="n">input_data_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># number of times the input tensor should be tiled to produce predictions for multiple samples</span>
        <span class="c1"># this variable is larger than 1 only if the batch_size is at least twice as large as the number</span>
        <span class="c1"># of individual time series being predicted in current batch (`num_series`)</span>
        <span class="n">batch_sample_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
            <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pred_batch_size</span> <span class="o">//</span> <span class="n">num_series</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_num_samples</span>
        <span class="p">)</span>

        <span class="c1"># counts number of produced prediction samples for every series to be predicted in current batch</span>
        <span class="n">sample_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># repeat prediction procedure for every needed sample</span>
        <span class="n">batch_predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="n">sample_count</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_num_samples</span><span class="p">:</span>
            <span class="c1"># make sure we don&#39;t produce too many samples</span>
            <span class="k">if</span> <span class="n">sample_count</span> <span class="o">+</span> <span class="n">batch_sample_size</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_num_samples</span><span class="p">:</span>
                <span class="n">batch_sample_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_num_samples</span> <span class="o">-</span> <span class="n">sample_count</span>

            <span class="c1"># stack multiple copies of the tensors to produce probabilistic forecasts</span>
            <span class="n">input_data_tuple_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_tiling</span><span class="p">(</span>
                <span class="n">input_data_tuple</span><span class="p">,</span> <span class="n">batch_sample_size</span>
            <span class="p">)</span>

            <span class="c1"># get predictions for 1 whole batch (can include predictions of multiple series</span>
            <span class="c1"># and for multiple samples if a probabilistic forecast is produced)</span>
            <span class="n">batch_prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_batch_prediction</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pred_n</span><span class="p">,</span> <span class="n">input_data_tuple_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_roll_size</span>
            <span class="p">)</span>

            <span class="c1"># reshape from 3d tensor (num_series x batch_sample_size, ...)</span>
            <span class="c1"># into 4d tensor (batch_sample_size, num_series, ...), where dim 0 represents the samples</span>
            <span class="n">out_shape</span> <span class="o">=</span> <span class="n">batch_prediction</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">batch_prediction</span> <span class="o">=</span> <span class="n">batch_prediction</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">batch_sample_size</span><span class="p">,</span>
                    <span class="n">num_series</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="o">+</span> <span class="n">out_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="p">)</span>

            <span class="c1"># save all predictions and update the `sample_count` variable</span>
            <span class="n">batch_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_prediction</span><span class="p">)</span>
            <span class="n">sample_count</span> <span class="o">+=</span> <span class="n">batch_sample_size</span>

        <span class="c1"># concatenate the batch of samples, to form self.pred_num_samples samples</span>
        <span class="n">batch_predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">batch_predictions</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">batch_predictions</span><span class="p">,</span>
            <span class="n">batch_series_schemas</span><span class="p">,</span>
            <span class="n">batch_pred_starts</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="PLForecastingModule.set_predict_parameters"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_predict_parameters">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_predict_parameters</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">roll_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">predict_likelihood_parameters</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">mc_dropout</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;to be set from TorchForecastingModel before calling trainer.predict() and reset at self.on_predict_end()&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_num_samples</span> <span class="o">=</span> <span class="n">num_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_roll_size</span> <span class="o">=</span> <span class="n">roll_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predict_likelihood_parameters</span> <span class="o">=</span> <span class="n">predict_likelihood_parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_mc_dropout</span> <span class="o">=</span> <span class="n">mc_dropout</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>
        <span class="c1"># output is of shape (batch_size, n_timesteps, n_components, n_params)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If there&#39;s no likelihood, nr_params=1, and we need to squeeze out the</span>
            <span class="c1"># last dimension of model output, for properly computing the loss.</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span> <span class="o">*</span> <span class="n">sample_weight</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">metrics</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If there&#39;s no likelihood, nr_params=1, and we need to squeeze out the</span>
            <span class="c1"># last dimension of model output, for properly computing the metric.</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># torch metrics require 2D targets of shape (batch size * ocl, num targets)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_targets</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_targets</span><span class="p">)</span>

        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span>
            <span class="n">res</span><span class="p">,</span>
            <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">metrics</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<div class="viewcode-block" id="PLForecastingModule.configure_optimizers"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_optimizers">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;configures optimizers and learning rate schedulers for model optimization.&quot;&quot;&quot;</span>

        <span class="c1"># A utility function to create optimizer and lr scheduler from desired classes</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">_create_from_cls_and_kwargs</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">kws</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">kws</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">raise_log</span><span class="p">(</span>
                    <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;Error when building the optimizer or learning rate scheduler;&quot;</span>
                        <span class="s2">&quot;please check the provided class and arguments&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">class: </span><span class="si">{</span><span class="bp">cls</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">arguments (kwargs): </span><span class="si">{</span><span class="n">kws</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">error:</span><span class="se">\n</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">),</span>
                    <span class="n">logger</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># Create the optimizer and (optionally) the learning rate scheduler</span>
        <span class="c1"># we have to create copies because we cannot save model.parameters into object state (not serializable)</span>
        <span class="n">optimizer_kws</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">optimizer_kws</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">_create_from_cls_and_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_cls</span><span class="p">,</span> <span class="n">optimizer_kws</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_cls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lr_sched_kws</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="n">lr_sched_kws</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer</span>

            <span class="c1"># lr scheduler can be configured with lightning; defaults below</span>
            <span class="n">lr_config_params</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;monitor&quot;</span><span class="p">:</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
                <span class="s2">&quot;interval&quot;</span><span class="p">:</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
                <span class="s2">&quot;frequency&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="c1"># update config with user params</span>
            <span class="n">lr_config_params</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="p">(</span><span class="n">v</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">lr_sched_kws</span> <span class="k">else</span> <span class="n">lr_sched_kws</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">lr_config_params</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>

            <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">_create_from_cls_and_kwargs</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_cls</span><span class="p">,</span> <span class="n">lr_sched_kws</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="p">[</span><span class="n">optimizer</span><span class="p">],</span> <span class="nb">dict</span><span class="p">({</span><span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">lr_scheduler</span><span class="p">},</span> <span class="o">**</span><span class="n">lr_config_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">optimizer</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_produce_train_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">:</span> <span class="n">TorchBatch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generates train output.</span>

<span class="sd">        Feeds `PLForecastingModule` with (past target + past cov + historic future cov (concatenated), future cov,</span>
<span class="sd">        static cov)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_batch</span>
<span class="sd">            ``(past target, past cov, historic future cov, future cov, static cov)``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_process_input_batch</span><span class="p">(</span><span class="n">input_batch</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_process_input_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">:</span> <span class="n">TorchBatch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PLModuleInput</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Processes module input batch.</span>

<span class="sd">        Converts output of a dataset into a tuple of tensors (past target + past cov + historic future cov</span>
<span class="sd">        (concatenated), future cov, static cov)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_batch</span>
<span class="sd">            ``(past target, past cov, historic future cov, future cov, static cov)``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            ``(x_past, x_future, x_static)`` the past, future, and static features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">(</span>
            <span class="n">past_target</span><span class="p">,</span>
            <span class="n">past_covariates</span><span class="p">,</span>
            <span class="n">historic_future_covariates</span><span class="p">,</span>
            <span class="n">future_covariates</span><span class="p">,</span>
            <span class="n">static_covariates</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">input_batch</span>
        <span class="n">dim_comp</span> <span class="o">=</span> <span class="mi">2</span>

        <span class="n">x_past</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">tensor</span>
                <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="p">[</span>
                    <span class="n">past_target</span><span class="p">,</span>
                    <span class="n">past_covariates</span><span class="p">,</span>
                    <span class="n">historic_future_covariates</span><span class="p">,</span>
                <span class="p">]</span>
                <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">],</span>
            <span class="n">dim</span><span class="o">=</span><span class="n">dim_comp</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">x_past</span><span class="p">,</span> <span class="n">future_covariates</span><span class="p">,</span> <span class="n">static_covariates</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_batch_prediction</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="o">...</span><span class="p">],</span> <span class="n">roll_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generates batch predictions.</span>

<span class="sd">        Feeds `PLForecastingModule` with past, future, and static features to forecast the next ``n`` target values</span>
<span class="sd">        per target variable.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n</span>
<span class="sd">            prediction length</span>
<span class="sd">        input_batch</span>
<span class="sd">            (past target, past cov, future past cov, historic future cov, future cov, static cov)</span>
<span class="sd">        roll_size</span>
<span class="sd">            roll input arrays after every sequence by ``roll_size``. Initially, ``roll_size`` is equivalent to</span>
<span class="sd">            ``self.output_chunk_length``</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">dim_component</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="p">(</span>
            <span class="n">past_target</span><span class="p">,</span>
            <span class="n">past_covariates</span><span class="p">,</span>
            <span class="n">future_past_covariates</span><span class="p">,</span>
            <span class="n">historic_future_covariates</span><span class="p">,</span>
            <span class="n">future_covariates</span><span class="p">,</span>
            <span class="n">static_covariates</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">input_batch</span>

        <span class="n">n_targets</span> <span class="o">=</span> <span class="n">past_target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim_component</span><span class="p">]</span>
        <span class="n">n_past_covs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">past_covariates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim_component</span><span class="p">]</span> <span class="k">if</span> <span class="n">past_covariates</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>
        <span class="n">n_future_covs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">future_covariates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim_component</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">future_covariates</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>

        <span class="n">input_past</span><span class="p">,</span> <span class="n">input_future</span><span class="p">,</span> <span class="n">input_static</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input_batch</span><span class="p">((</span>
            <span class="n">past_target</span><span class="p">,</span>
            <span class="n">past_covariates</span><span class="p">,</span>
            <span class="n">historic_future_covariates</span><span class="p">,</span>
            <span class="p">(</span>
                <span class="n">future_covariates</span><span class="p">[:,</span> <span class="p">:</span><span class="n">roll_size</span><span class="p">,</span> <span class="p">:]</span>
                <span class="k">if</span> <span class="n">future_covariates</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">),</span>
            <span class="n">static_covariates</span><span class="p">,</span>
        <span class="p">))</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_produce_predict_output</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">(</span><span class="n">input_past</span><span class="p">,</span> <span class="n">input_future</span><span class="p">,</span> <span class="n">input_static</span><span class="p">))[</span>
            <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_prediction_index</span> <span class="p">:,</span> <span class="p">:</span>
        <span class="p">]</span>

        <span class="n">batch_prediction</span> <span class="o">=</span> <span class="p">[</span><span class="n">out</span><span class="p">[:,</span> <span class="p">:</span><span class="n">roll_size</span><span class="p">,</span> <span class="p">:]]</span>
        <span class="n">prediction_length</span> <span class="o">=</span> <span class="n">roll_size</span>

        <span class="c1"># predict at least `output_chunk_length` points, so that we use the most recent target values</span>
        <span class="n">min_n</span> <span class="o">=</span> <span class="n">n</span> <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span>
        <span class="k">while</span> <span class="n">prediction_length</span> <span class="o">&lt;</span> <span class="n">min_n</span><span class="p">:</span>
            <span class="c1"># we want the last prediction to end exactly at `min_n` into the future.</span>
            <span class="c1"># this means we may have to truncate the previous prediction and step</span>
            <span class="c1"># back the roll size for the last chunk</span>
            <span class="k">if</span> <span class="n">prediction_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span> <span class="o">&gt;</span> <span class="n">min_n</span><span class="p">:</span>
                <span class="n">spillover_prediction_length</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">prediction_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span> <span class="o">-</span> <span class="n">min_n</span>
                <span class="p">)</span>
                <span class="n">roll_size</span> <span class="o">-=</span> <span class="n">spillover_prediction_length</span>
                <span class="n">prediction_length</span> <span class="o">-=</span> <span class="n">spillover_prediction_length</span>
                <span class="n">batch_prediction</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_prediction</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:,</span> <span class="p">:</span><span class="n">roll_size</span><span class="p">,</span> <span class="p">:]</span>

            <span class="c1"># ==========&gt; PAST INPUT &lt;==========</span>
            <span class="c1"># roll over input series to contain the latest target and covariates</span>
            <span class="n">input_past</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">input_past</span><span class="p">,</span> <span class="o">-</span><span class="n">roll_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="c1"># update target input to include next `roll_size` predictions</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_chunk_length</span> <span class="o">&gt;=</span> <span class="n">roll_size</span><span class="p">:</span>
                <span class="n">input_past</span><span class="p">[:,</span> <span class="o">-</span><span class="n">roll_size</span><span class="p">:,</span> <span class="p">:</span><span class="n">n_targets</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span> <span class="p">:</span><span class="n">roll_size</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_past</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">n_targets</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">input_chunk_length</span> <span class="p">:,</span> <span class="p">:]</span>

            <span class="c1"># set left and right boundaries for extracting future elements</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_chunk_length</span> <span class="o">&gt;=</span> <span class="n">roll_size</span><span class="p">:</span>
                <span class="n">left_past</span><span class="p">,</span> <span class="n">right_past</span> <span class="o">=</span> <span class="n">prediction_length</span> <span class="o">-</span> <span class="n">roll_size</span><span class="p">,</span> <span class="n">prediction_length</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">left_past</span><span class="p">,</span> <span class="n">right_past</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">prediction_length</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_chunk_length</span><span class="p">,</span>
                    <span class="n">prediction_length</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="c1"># update past covariates to include next `roll_size` future past covariates elements</span>
            <span class="k">if</span> <span class="n">n_past_covs</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_chunk_length</span> <span class="o">&gt;=</span> <span class="n">roll_size</span><span class="p">:</span>
                <span class="n">input_past</span><span class="p">[:,</span> <span class="o">-</span><span class="n">roll_size</span><span class="p">:,</span> <span class="n">n_targets</span> <span class="p">:</span> <span class="n">n_targets</span> <span class="o">+</span> <span class="n">n_past_covs</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">future_past_covariates</span><span class="p">[:,</span> <span class="n">left_past</span><span class="p">:</span><span class="n">right_past</span><span class="p">,</span> <span class="p">:]</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">n_past_covs</span><span class="p">:</span>
                <span class="n">input_past</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">n_targets</span> <span class="p">:</span> <span class="n">n_targets</span> <span class="o">+</span> <span class="n">n_past_covs</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">future_past_covariates</span><span class="p">[:,</span> <span class="n">left_past</span><span class="p">:</span><span class="n">right_past</span><span class="p">,</span> <span class="p">:]</span>
                <span class="p">)</span>

            <span class="c1"># update historic future covariates to include next `roll_size` future covariates elements</span>
            <span class="k">if</span> <span class="n">n_future_covs</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_chunk_length</span> <span class="o">&gt;=</span> <span class="n">roll_size</span><span class="p">:</span>
                <span class="n">input_past</span><span class="p">[:,</span> <span class="o">-</span><span class="n">roll_size</span><span class="p">:,</span> <span class="n">n_targets</span> <span class="o">+</span> <span class="n">n_past_covs</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">future_covariates</span><span class="p">[:,</span> <span class="n">left_past</span><span class="p">:</span><span class="n">right_past</span><span class="p">,</span> <span class="p">:]</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">n_future_covs</span><span class="p">:</span>
                <span class="n">input_past</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">n_targets</span> <span class="o">+</span> <span class="n">n_past_covs</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">future_covariates</span><span class="p">[</span>
                    <span class="p">:,</span> <span class="n">left_past</span><span class="p">:</span><span class="n">right_past</span><span class="p">,</span> <span class="p">:</span>
                <span class="p">]</span>

            <span class="c1"># ==========&gt; FUTURE INPUT &lt;==========</span>
            <span class="n">left_future</span><span class="p">,</span> <span class="n">right_future</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">right_past</span><span class="p">,</span>
                <span class="n">right_past</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># update future covariates to include next `roll_size` future covariates elements</span>
            <span class="k">if</span> <span class="n">n_future_covs</span><span class="p">:</span>
                <span class="n">input_future</span> <span class="o">=</span> <span class="n">future_covariates</span><span class="p">[:,</span> <span class="n">left_future</span><span class="p">:</span><span class="n">right_future</span><span class="p">,</span> <span class="p">:]</span>

            <span class="c1"># take only last part of the output sequence where needed</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_produce_predict_output</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="p">(</span><span class="n">input_past</span><span class="p">,</span> <span class="n">input_future</span><span class="p">,</span> <span class="n">input_static</span><span class="p">)</span>
            <span class="p">)[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_prediction_index</span> <span class="p">:,</span> <span class="p">:]</span>

            <span class="n">batch_prediction</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="n">prediction_length</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span>

        <span class="c1"># bring predictions into desired format and drop unnecessary values</span>
        <span class="n">batch_prediction</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">batch_prediction</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">batch_prediction</span> <span class="o">=</span> <span class="n">batch_prediction</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="n">batch_prediction</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_tiling</span><span class="p">(</span>
        <span class="n">input_data_tuple</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="o">...</span><span class="p">],</span> <span class="n">batch_sample_size</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="o">...</span><span class="p">]:</span>
        <span class="n">tiled_input_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">input_data_tuple</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">tiled_input_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="n">batch_sample_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tiled_input_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tiled_input_data</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_mc_dropout_modules</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">set</span><span class="p">:</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">recurse_children</span><span class="p">(</span><span class="n">children</span><span class="p">,</span> <span class="n">acc</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">children</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">MonteCarloDropout</span><span class="p">):</span>
                    <span class="n">acc</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
                <span class="n">acc</span> <span class="o">=</span> <span class="n">recurse_children</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">children</span><span class="p">(),</span> <span class="n">acc</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">acc</span>

        <span class="k">return</span> <span class="n">recurse_children</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">(),</span> <span class="nb">set</span><span class="p">())</span>

<div class="viewcode-block" id="PLForecastingModule.set_mc_dropout"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.set_mc_dropout">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_mc_dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">active</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="c1"># optionally, activate dropout in all MonteCarloDropout modules</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_mc_dropout_modules</span><span class="p">():</span>
            <span class="n">module</span><span class="o">.</span><span class="n">_mc_dropout_enabled</span> <span class="o">=</span> <span class="n">active</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">supports_probabilistic_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_mc_dropout_modules</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_produce_predict_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_likelihood_parameters</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">predict_likelihood_parameters</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<div class="viewcode-block" id="PLForecastingModule.on_save_checkpoint"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_save_checkpoint">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">on_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># we must save the dtype for correct parameter precision at loading time</span>
        <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;model_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
        <span class="c1"># we must save the shape of the input to be able to instantiate the model without calling fit_from_dataset</span>
        <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;train_sample_shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_sample_shape</span>
        <span class="c1"># we must save the loss to properly restore it when resuming training</span>
        <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;loss_fn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span>
        <span class="c1"># we must save the metrics to continue logging them when resuming training</span>
        <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;torch_metrics_train&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span>
        <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;torch_metrics_val&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_metrics</span></div>

<div class="viewcode-block" id="PLForecastingModule.on_load_checkpoint"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.on_load_checkpoint">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">on_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># by default our models are initialized as float32. For other dtypes, we need to cast to the correct precision</span>
        <span class="c1"># before parameters are loaded by PyTorch-Lightning</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;model_dtype&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># restoring attributes necessary to resume from training properly</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;loss_fn&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;torch_metrics_train&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_metrics</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;torch_metrics_val&quot;</span><span class="p">]</span></div>

<div class="viewcode-block" id="PLForecastingModule.to_dtype"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.to_dtype">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">to_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Cast module precision (float32 by default) to another precision.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">raise_if</span><span class="p">(</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;Trying to load dtype `</span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2">`. Loading for this type is not implemented yet. Please report this &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;issue on https://github.com/unit8co/darts&quot;</span><span class="p">,</span>
                <span class="n">logger</span><span class="p">,</span>
            <span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">epochs_trained</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">output_chunk_length</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Number of time steps predicted at once by the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_chunk_length</span>

<div class="viewcode-block" id="PLForecastingModule.configure_torch_metrics"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.pl_forecasting_module.html#darts.models.forecasting.pl_forecasting_module.PLForecastingModule.configure_torch_metrics">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">configure_torch_metrics</span><span class="p">(</span>
        <span class="n">torch_metrics</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torchmetrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">,</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MetricCollection</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MetricCollection</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;process the torch_metrics parameter.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">torch_metrics</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">torch_metrics</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MetricCollection</span><span class="p">([])</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">torch_metrics</span><span class="p">,</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">):</span>
            <span class="n">torch_metrics</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MetricCollection</span><span class="p">([</span><span class="n">torch_metrics</span><span class="p">])</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">torch_metrics</span><span class="p">,</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MetricCollection</span><span class="p">):</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">raise_log</span><span class="p">(</span>
                <span class="ne">AttributeError</span><span class="p">(</span>
                    <span class="s2">&quot;`torch_metrics` only accepts type torchmetrics.Metric or torchmetrics.MetricCollection&quot;</span>
                <span class="p">),</span>
                <span class="n">logger</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">torch_metrics</span></div></div>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2020 - 2025, Unit8 SA (Apache 2.0 License).<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.0.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>