
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>darts.models.forecasting.global_baseline_models &#8212; darts  documentation</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <link rel="shortcut icon" href="../../../../_static/docs-favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../../index.html">
  <img src="../../../../_static/darts-logo-trim.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../README.html">
  Home
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../quickstart/00-quickstart.html">
  Quickstart
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../userguide.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../generated_api/darts.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../examples.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../release_notes/RELEASE_NOTES.html">
  Release Notes
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/unit8co/darts" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/unit8co" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for darts.models.forecasting.global_baseline_models</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Global Baseline Models (Naive)</span>
<span class="sd">------------------------------</span>

<span class="sd">A collection of simple benchmark models working with univariate, multivariate, single, and multiple series.</span>

<span class="sd">- :class:`GlobalNaiveAggregate`</span>
<span class="sd">- :class:`GlobalNaiveDrift`</span>
<span class="sd">- :class:`GlobalNaiveSeasonal`</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">darts</span><span class="w"> </span><span class="kn">import</span> <span class="n">TimeSeries</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.logging</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_logger</span><span class="p">,</span> <span class="n">raise_log</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.models.forecasting.pl_forecasting_module</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">PLForecastingModule</span><span class="p">,</span>
    <span class="n">io_processor</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.models.forecasting.torch_forecasting_model</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">MixedCovariatesTorchModel</span><span class="p">,</span>
    <span class="n">TorchForecastingModel</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">SequentialTorchTrainingDataset</span><span class="p">,</span>
    <span class="n">TorchTrainingDataset</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">darts.utils.data.torch_datasets.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchTrainingSample</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_extract_targets</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">n_targets</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extracts and returns the target components from an input batch</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    batch</span>
<span class="sd">        The input batch tuple for the forward method. Has elements `(x_past, x_future, x_static)`.</span>
<span class="sd">    n_targets</span>
<span class="sd">        The number of target components to extract.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">n_targets</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_repeat_along_output_chunk</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">ocl</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Expands a tensor `x` of shape (batch size, n components) to a tensor of shape</span>
<span class="sd">    (batch size, `ocl`, n target components, 1 (n samples)), by repeating the values</span>
<span class="sd">    along the `output_chunk_length` axis.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x</span>
<span class="sd">        An input tensor of shape (batch size, n target components)</span>
<span class="sd">    ocl</span>
<span class="sd">        The output_chunk_length.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ocl</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_GlobalNaiveModule</span><span class="p">(</span><span class="n">PLForecastingModule</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pytorch module for implementing naive models.</span>

<span class="sd">        Implement your own naive module by subclassing from `_GlobalNaiveModule`, and implement the</span>
<span class="sd">        logic for prediction in the private `_forward` method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@io_processor</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Naive model forward pass.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_in</span>
<span class="sd">            comes as tuple `(x_past, x_future, x_static)` where `x_past` is the input/past chunk and `x_future`</span>
<span class="sd">            is the output/future chunk. Input dimensions are `(batch_size, time_steps, components)`</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The output Tensor of shape `(batch_size, output_chunk_length, output_dim, nr_params)`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Private method to implement the forward method in the subclasses.&quot;&quot;&quot;</span>
        <span class="k">pass</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_GlobalNaiveModel</span><span class="p">(</span><span class="n">MixedCovariatesTorchModel</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_chunk_shift</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">use_static_covariates</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Base class for global naive models. The naive models inherit from `MixedCovariatesTorchModel` giving access</span>
<span class="sd">        to past, future, and static covariates in the model `forward()` method. This allows to create custom models</span>
<span class="sd">        naive models which can make use of the covariates. The built-in naive models will not use this information.</span>

<span class="sd">        The naive models do not have to be trained before generating predictions.</span>

<span class="sd">        To add a new naive model:</span>
<span class="sd">        - subclass from `_GlobalNaiveModel` with implementation of private method `_create_model` that creates an</span>
<span class="sd">            object of:</span>
<span class="sd">        - subclass from `_GlobalNaiveModule` with implementation of private method `_forward`</span>

<span class="sd">        .. note::</span>
<span class="sd">            - Model checkpointing with `save_checkpoints=True`, and checkpoint loading with `load_from_checkpoint()`</span>
<span class="sd">              and `load_weights_from_checkpoint()` are not supported for global naive models.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_chunk_length</span>
<span class="sd">            The length of the input sequence fed to the model.</span>
<span class="sd">        output_chunk_length</span>
<span class="sd">            The length of the emitted forecast and output sequence fed to the model.</span>
<span class="sd">        output_chunk_shift</span>
<span class="sd">            Optionally, the number of steps to shift the start of the output chunk into the future (relative to the</span>
<span class="sd">            input chunk end). This will create a gap between the input and output. If the model supports</span>
<span class="sd">            `future_covariates`, the future values are extracted from the shifted output chunk. Predictions will start</span>
<span class="sd">            `output_chunk_shift` steps after the end of the target `series`. If `output_chunk_shift` is set, the model</span>
<span class="sd">            cannot generate autoregressive predictions (`n &gt; output_chunk_length`).</span>
<span class="sd">        use_static_covariates</span>
<span class="sd">            Whether the model should use static covariate information in case the input `series` passed to ``fit()``</span>
<span class="sd">            contain static covariates. If ``True``, and static covariates are available at fitting time, will enforce</span>
<span class="sd">            that all target `series` have the same static covariate dimensionality in ``fit()`` and ``predict()``.</span>
<span class="sd">        **kwargs</span>
<span class="sd">            Optional arguments to initialize the pytorch_lightning.Module, pytorch_lightning.Trainer, and</span>
<span class="sd">            Darts&#39; :class:`TorchForecastingModel`.</span>
<span class="sd">            Since naive models are not trained, the following parameters will have no effect:</span>
<span class="sd">            `loss_fn`, `likelihood`, `optimizer_cls`, `optimizer_kwargs`, `lr_scheduler_cls`, `lr_scheduler_kwargs`,</span>
<span class="sd">            `n_epochs`, `save_checkpoints`, and some of `pl_trainer_kwargs`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_extract_torch_model_params</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">model_params</span><span class="p">))</span>

        <span class="c1"># extract pytorch lightning module kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pl_module_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_pl_module_params</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">model_params</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_considers_static_covariates</span> <span class="o">=</span> <span class="n">use_static_covariates</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">series</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TimeSeries</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">TimeSeries</span><span class="p">]],</span>
        <span class="n">past_covariates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">TimeSeries</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">TimeSeries</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">future_covariates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">TimeSeries</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">TimeSeries</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TorchForecastingModel</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit/train the model on a (or potentially multiple) series.</span>
<span class="sd">        This method is only implemented for naive baseline models to provide a unified fit/predict API with other</span>
<span class="sd">        forecasting models.</span>

<span class="sd">        The model is not really trained on the input, but `fit()` is used to setup the model based on the input series.</span>
<span class="sd">        Also, it stores the training `series` in case only a single `TimeSeries` was passed. This allows to call</span>
<span class="sd">        `predict()` without having to pass the single `series`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        series</span>
<span class="sd">            A series or sequence of series serving as target (i.e. what the model will be trained to forecast)</span>
<span class="sd">        past_covariates</span>
<span class="sd">            Optionally, a series or sequence of series specifying past-observed covariates</span>
<span class="sd">        future_covariates</span>
<span class="sd">            Optionally, a series or sequence of series specifying future-known covariates</span>
<span class="sd">        **kwargs</span>
<span class="sd">            Optionally, some keyword arguments.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">            Fitted model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">past_covariates</span><span class="p">,</span> <span class="n">future_covariates</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_from_checkpoint</span><span class="p">(</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">work_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">file_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;TorchForecastingModel&quot;</span><span class="p">:</span>
        <span class="n">raise_log</span><span class="p">(</span>
            <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;GlobalNaiveModels do not support loading from checkpoint since they are never trained.&quot;</span>
            <span class="p">),</span>
            <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_weights_from_checkpoint</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">work_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">file_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">load_encoders</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">skip_checks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">raise_log</span><span class="p">(</span>
            <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;GlobalNaiveModels do not support weights loading since they do not have any weights/parameters.&quot;</span>
            <span class="p">),</span>
            <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_verify_predict_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predict_sample</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="c1"># naive models do not have to be trained, predict sample does not</span>
        <span class="c1"># have to match the training sample</span>
        <span class="k">pass</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">supports_likelihood_parameter_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">supports_probabilistic_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">supports_static_covariates</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_requires_training</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="c1"># naive models do not have to be trained.</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_build_train_dataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">series</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">TimeSeries</span><span class="p">],</span>
        <span class="n">past_covariates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">TimeSeries</span><span class="p">]],</span>
        <span class="n">future_covariates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">TimeSeries</span><span class="p">]],</span>
        <span class="n">sample_weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">TimeSeries</span><span class="p">]],</span>
        <span class="n">max_samples_per_ts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TorchTrainingDataset</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SequentialTorchTrainingDataset</span><span class="p">(</span>
            <span class="n">series</span><span class="o">=</span><span class="n">series</span><span class="p">,</span>
            <span class="n">past_covariates</span><span class="o">=</span><span class="n">past_covariates</span><span class="p">,</span>
            <span class="n">future_covariates</span><span class="o">=</span><span class="n">future_covariates</span><span class="p">,</span>
            <span class="n">input_chunk_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">input_chunk_length</span><span class="p">,</span>
            <span class="n">output_chunk_length</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">output_chunk_shift</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_shift</span><span class="p">,</span>
            <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
            <span class="n">max_samples_per_ts</span><span class="o">=</span><span class="n">max_samples_per_ts</span><span class="p">,</span>
            <span class="n">use_static_covariates</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">uses_static_covariates</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_NoCovariatesMixin</span><span class="p">:</span>
    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">supports_static_covariates</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">supports_future_covariates</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">supports_past_covariates</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_GlobalNaiveAggregateModule</span><span class="p">(</span><span class="n">_GlobalNaiveModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">agg_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agg_fn</span> <span class="o">=</span> <span class="n">agg_fn</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">y_target</span> <span class="o">=</span> <span class="n">_extract_targets</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_targets</span><span class="p">)</span>
        <span class="n">aggregate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agg_fn</span><span class="p">(</span><span class="n">y_target</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_repeat_along_output_chunk</span><span class="p">(</span><span class="n">aggregate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span><span class="p">)</span>


<div class="viewcode-block" id="GlobalNaiveAggregate"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.global_baseline_models.html#darts.models.forecasting.global_baseline_models.GlobalNaiveAggregate">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GlobalNaiveAggregate</span><span class="p">(</span><span class="n">_NoCovariatesMixin</span><span class="p">,</span> <span class="n">_GlobalNaiveModel</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_chunk_shift</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">agg_fn</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Global Naive Aggregate Model.</span>

<span class="sd">        The model generates forecasts for each `series` as described below:</span>

<span class="sd">        - take an aggregate (computed with `agg_fn`, default: mean) from each target component over the last</span>
<span class="sd">          `input_chunk_length` points</span>
<span class="sd">        - the forecast is the component aggregate repeated `output_chunk_length` times</span>

<span class="sd">        Depending on the horizon `n` used when calling `model.predict()`, the forecasts are either:</span>

<span class="sd">        - a constant aggregate value (default: mean) if `n &lt;= output_chunk_length`, or</span>
<span class="sd">        - a moving aggregate if `n &gt; output_chunk_length`, as a result of the autoregressive prediction.</span>

<span class="sd">        This model is equivalent to:</span>

<span class="sd">        - :class:`~darts.models.forecasting.baselines.NaiveMean`, when `input_chunk_length` is equal to the length of</span>
<span class="sd">          the input target `series`, and `agg_fn=&#39;mean&#39;`.</span>
<span class="sd">        - :class:`~darts.models.forecasting.baselines.NaiveMovingAverage`, with identical `input_chunk_length`</span>
<span class="sd">          and `output_chunk_length=1`, and `agg_fn=&#39;mean&#39;`.</span>

<span class="sd">        .. note::</span>
<span class="sd">            - Model checkpointing with `save_checkpoints=True`, and checkpoint loading with `load_from_checkpoint()`</span>
<span class="sd">              and `load_weights_from_checkpoint()` are not supported for global naive models.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_chunk_length</span>
<span class="sd">            The length of the input sequence fed to the model.</span>
<span class="sd">        output_chunk_length</span>
<span class="sd">            The length of the emitted forecast and output sequence fed to the model.</span>
<span class="sd">        output_chunk_shift</span>
<span class="sd">            Optionally, the number of steps to shift the start of the output chunk into the future (relative to the</span>
<span class="sd">            input chunk end). This will create a gap between the input and output. If the model supports</span>
<span class="sd">            `future_covariates`, the future values are extracted from the shifted output chunk. Predictions will start</span>
<span class="sd">            `output_chunk_shift` steps after the end of the target `series`. If `output_chunk_shift` is set, the model</span>
<span class="sd">            cannot generate autoregressive predictions (`n &gt; output_chunk_length`).</span>
<span class="sd">        agg_fn</span>
<span class="sd">            The aggregation function to use. If a string, must be the name of `torch` function that can be imported</span>
<span class="sd">            directly from `torch` (e.g. `&quot;mean&quot;` for `torch.mean`, `&quot;sum&quot;` for `torch.sum`).</span>
<span class="sd">            The function must have the signature below. If a `Callable`, it must also have the signature below.</span>

<span class="sd">            .. highlight:: python</span>
<span class="sd">            .. code-block:: python</span>

<span class="sd">                def agg_fn(x: torch.Tensor, dim: int, *args, **kwargs) -&gt; torch.Tensor:</span>
<span class="sd">                    # x has shape `(batch size, input_chunk_length, n targets)`, `dim` is always `1`.</span>
<span class="sd">                    # function must return a tensor of shape `(batch size, n targets)`</span>
<span class="sd">                    return torch.mean(x, dim=dim)</span>
<span class="sd">            ..</span>
<span class="sd">        **kwargs</span>
<span class="sd">            Optional arguments to initialize the pytorch_lightning.Module, pytorch_lightning.Trainer, and</span>
<span class="sd">            Darts&#39; :class:`TorchForecastingModel`.</span>
<span class="sd">            Since naive models are not trained, the following parameters will have no effect:</span>
<span class="sd">            `loss_fn`, `likelihood`, `optimizer_cls`, `optimizer_kwargs`, `lr_scheduler_cls`, `lr_scheduler_kwargs`,</span>
<span class="sd">            `n_epochs`, `save_checkpoints`, and some of `pl_trainer_kwargs`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from darts.datasets import IceCreamHeaterDataset</span>
<span class="sd">        &gt;&gt;&gt; from darts.models import GlobalNaiveAggregate</span>
<span class="sd">        &gt;&gt;&gt; # create list of multivariate series</span>
<span class="sd">        &gt;&gt;&gt; series_1 = IceCreamHeaterDataset().load()</span>
<span class="sd">        &gt;&gt;&gt; series_2 = series_1 + 100.</span>
<span class="sd">        &gt;&gt;&gt; series = [series_1, series_2]</span>
<span class="sd">        &gt;&gt;&gt; # predict 3 months, take mean over last 60 months</span>
<span class="sd">        &gt;&gt;&gt; horizon, icl = 3, 60</span>
<span class="sd">        &gt;&gt;&gt; # naive mean over last 60 months (with `output_chunk_length = horizon`)</span>
<span class="sd">        &gt;&gt;&gt; model = GlobalNaiveAggregate(input_chunk_length=icl, output_chunk_length=horizon)</span>
<span class="sd">        &gt;&gt;&gt; # predict after end of each multivariate series</span>
<span class="sd">        &gt;&gt;&gt; pred = model.fit(series).predict(n=horizon, series=series)</span>
<span class="sd">        &gt;&gt;&gt; [p.values() for p in pred]</span>
<span class="sd">        [array([[29.666668, 50.983337],</span>
<span class="sd">               [29.666668, 50.983337],</span>
<span class="sd">               [29.666668, 50.983337]]), array([[129.66667, 150.98334],</span>
<span class="sd">               [129.66667, 150.98334],</span>
<span class="sd">               [129.66667, 150.98334]])]</span>
<span class="sd">        &gt;&gt;&gt; # naive moving mean (with `output_chunk_length &lt; horizon`)</span>
<span class="sd">        &gt;&gt;&gt; model = GlobalNaiveAggregate(input_chunk_length=icl, output_chunk_length=1, agg_fn=&quot;mean&quot;)</span>
<span class="sd">        &gt;&gt;&gt; pred = model.fit(series).predict(n=horizon, series=series)</span>
<span class="sd">        &gt;&gt;&gt; [p.values() for p in pred]</span>
<span class="sd">        [array([[29.666668, 50.983337],</span>
<span class="sd">               [29.894447, 50.88306 ],</span>
<span class="sd">               [30.109352, 50.98111 ]]), array([[129.66667, 150.98334],</span>
<span class="sd">               [129.89445, 150.88307],</span>
<span class="sd">               [130.10936, 150.98111]])]</span>
<span class="sd">        &gt;&gt;&gt; # naive moving sum (with `output_chunk_length &lt; horizon`)</span>
<span class="sd">        &gt;&gt;&gt; model = GlobalNaiveAggregate(input_chunk_length=icl, output_chunk_length=1, agg_fn=&quot;sum&quot;)</span>
<span class="sd">        &gt;&gt;&gt; pred = model.fit(series).predict(n=horizon, series=series)</span>
<span class="sd">        &gt;&gt;&gt; [p.values() for p in pred]</span>
<span class="sd">        [array([[ 1780.,  3059.],</span>
<span class="sd">               [ 3544.,  6061.],</span>
<span class="sd">               [ 7071., 12077.]]), array([[ 7780.,  9059.],</span>
<span class="sd">               [15444., 17961.],</span>
<span class="sd">               [30771., 35777.]])]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">input_chunk_length</span><span class="o">=</span><span class="n">input_chunk_length</span><span class="p">,</span>
            <span class="n">output_chunk_length</span><span class="o">=</span><span class="n">output_chunk_length</span><span class="p">,</span>
            <span class="n">output_chunk_shift</span><span class="o">=</span><span class="n">output_chunk_shift</span><span class="p">,</span>
            <span class="n">use_static_covariates</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">agg_fn</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">agg_fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">agg_fn</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">agg_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">raise_log</span><span class="p">(</span>
                    <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;When `agg_fn` is a string, must be the name of a PyTorch function that &quot;</span>
                        <span class="s2">&quot;can be imported directly from `torch`. E.g., `&#39;mean&#39;` for `torch.mean`&quot;</span>
                    <span class="p">),</span>
                    <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">agg_fn</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
            <span class="n">raise_log</span><span class="p">(</span>
                <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`agg_fn` must be a string or callable.&quot;</span><span class="p">),</span>
                <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># check that `agg_fn` returns the expected output</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_targets</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">))</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">agg</span> <span class="o">=</span> <span class="n">agg_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">agg</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">),</span> <span class="p">(</span>
                <span class="s2">&quot;`agg_fn` output must be a torch Tensor.&quot;</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="n">agg</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
                <span class="n">batch_size</span><span class="p">,</span>
                <span class="n">n_targets</span><span class="p">,</span>
            <span class="p">),</span> <span class="s2">&quot;Unexpected `agg_fn` output shape.&quot;</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
            <span class="n">raise_log</span><span class="p">(</span>
                <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`agg_fn` sanity check raised the following error: (</span><span class="si">{</span><span class="n">err</span><span class="si">}</span><span class="s2">) Read the parameter &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;description to properly define the aggregation function.&quot;</span>
                <span class="p">),</span>
                <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agg_fn</span> <span class="o">=</span> <span class="n">agg_fn</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_sample</span><span class="p">:</span> <span class="n">TorchTrainingSample</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_GlobalNaiveModule</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_GlobalNaiveAggregateModule</span><span class="p">(</span><span class="n">agg_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">agg_fn</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">pl_module_params</span><span class="p">)</span></div>


<span class="k">class</span><span class="w"> </span><span class="nc">_GlobalNaiveSeasonalModule</span><span class="p">(</span><span class="n">_GlobalNaiveModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">y_target</span> <span class="o">=</span> <span class="n">_extract_targets</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_targets</span><span class="p">)</span>
        <span class="n">season</span> <span class="o">=</span> <span class="n">y_target</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="n">_repeat_along_output_chunk</span><span class="p">(</span><span class="n">season</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span><span class="p">)</span>


<div class="viewcode-block" id="GlobalNaiveSeasonal"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.global_baseline_models.html#darts.models.forecasting.global_baseline_models.GlobalNaiveSeasonal">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GlobalNaiveSeasonal</span><span class="p">(</span><span class="n">_NoCovariatesMixin</span><span class="p">,</span> <span class="n">_GlobalNaiveModel</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_chunk_shift</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Global Naive Seasonal Model.</span>

<span class="sd">        The model generates forecasts for each `series` as described below:</span>

<span class="sd">        - take the value from each target component at the `input_chunk_length`th point before the end of the</span>
<span class="sd">          target `series`.</span>
<span class="sd">        - the forecast is the component value repeated `output_chunk_length` times.</span>

<span class="sd">        Depending on the horizon `n` used when calling `model.predict()`, the forecasts are either:</span>

<span class="sd">        - a constant value if `n &lt;= output_chunk_length`, or</span>
<span class="sd">        - a moving (seasonal) value if `n &gt; output_chunk_length`, as a result of the autoregressive prediction.</span>

<span class="sd">        This model is equivalent to:</span>

<span class="sd">        - :class:`~darts.models.forecasting.baselines.NaiveSeasonal`, when `input_chunk_length` is equal to the length</span>
<span class="sd">          of  the input target `series` and `output_chunk_length=1`.</span>

<span class="sd">        .. note::</span>
<span class="sd">            - Model checkpointing with `save_checkpoints=True`, and checkpoint loading with `load_from_checkpoint()`</span>
<span class="sd">              and `load_weights_from_checkpoint()` are not supported for global naive models.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_chunk_length</span>
<span class="sd">            The length of the input sequence fed to the model.</span>
<span class="sd">        output_chunk_length</span>
<span class="sd">            The length of the emitted forecast and output sequence fed to the model.</span>
<span class="sd">        output_chunk_shift</span>
<span class="sd">            Optionally, the number of steps to shift the start of the output chunk into the future (relative to the</span>
<span class="sd">            input chunk end). This will create a gap between the input and output. If the model supports</span>
<span class="sd">            `future_covariates`, the future values are extracted from the shifted output chunk. Predictions will start</span>
<span class="sd">            `output_chunk_shift` steps after the end of the target `series`. If `output_chunk_shift` is set, the model</span>
<span class="sd">            cannot generate autoregressive predictions (`n &gt; output_chunk_length`).</span>
<span class="sd">        **kwargs</span>
<span class="sd">            Optional arguments to initialize the pytorch_lightning.Module, pytorch_lightning.Trainer, and</span>
<span class="sd">            Darts&#39; :class:`TorchForecastingModel`.</span>
<span class="sd">            Since naive models are not trained, the following parameters will have no effect:</span>
<span class="sd">            `loss_fn`, `likelihood`, `optimizer_cls`, `optimizer_kwargs`, `lr_scheduler_cls`, `lr_scheduler_kwargs`,</span>
<span class="sd">            `n_epochs`, `save_checkpoints`, and some of `pl_trainer_kwargs`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from darts.datasets import IceCreamHeaterDataset</span>
<span class="sd">        &gt;&gt;&gt; from darts.models import GlobalNaiveSeasonal</span>
<span class="sd">        &gt;&gt;&gt; # create list of multivariate series</span>
<span class="sd">        &gt;&gt;&gt; series_1 = IceCreamHeaterDataset().load()</span>
<span class="sd">        &gt;&gt;&gt; series_2 = series_1 + 100.</span>
<span class="sd">        &gt;&gt;&gt; series = [series_1, series_2]</span>
<span class="sd">        &gt;&gt;&gt; # predict 3 months, use value from 12 months ago</span>
<span class="sd">        &gt;&gt;&gt; horizon, icl = 3, 12</span>
<span class="sd">        &gt;&gt;&gt; # repeated seasonal value (with `output_chunk_length = horizon`)</span>
<span class="sd">        &gt;&gt;&gt; model = GlobalNaiveSeasonal(input_chunk_length=icl, output_chunk_length=horizon)</span>
<span class="sd">        &gt;&gt;&gt; # predict after end of each multivariate series</span>
<span class="sd">        &gt;&gt;&gt; pred = model.fit(series).predict(n=horizon, series=series)</span>
<span class="sd">        &gt;&gt;&gt; [p.values() for p in pred]</span>
<span class="sd">        [array([[ 21., 100.],</span>
<span class="sd">               [ 21., 100.],</span>
<span class="sd">               [ 21., 100.]]), array([[121., 200.],</span>
<span class="sd">               [121., 200.],</span>
<span class="sd">               [121., 200.]])]</span>
<span class="sd">        &gt;&gt;&gt; # moving seasonal value (with `output_chunk_length &lt; horizon`)</span>
<span class="sd">        &gt;&gt;&gt; model = GlobalNaiveSeasonal(input_chunk_length=icl, output_chunk_length=1)</span>
<span class="sd">        &gt;&gt;&gt; pred = model.fit(series).predict(n=horizon, series=series)</span>
<span class="sd">        &gt;&gt;&gt; [p.values() for p in pred]</span>
<span class="sd">        [array([[ 21., 100.],</span>
<span class="sd">               [ 21.,  68.],</span>
<span class="sd">               [ 24.,  51.]]), array([[121., 200.],</span>
<span class="sd">               [121., 168.],</span>
<span class="sd">               [124., 151.]])]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">input_chunk_length</span><span class="o">=</span><span class="n">input_chunk_length</span><span class="p">,</span>
            <span class="n">output_chunk_length</span><span class="o">=</span><span class="n">output_chunk_length</span><span class="p">,</span>
            <span class="n">output_chunk_shift</span><span class="o">=</span><span class="n">output_chunk_shift</span><span class="p">,</span>
            <span class="n">use_static_covariates</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_sample</span><span class="p">:</span> <span class="n">TorchTrainingSample</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_GlobalNaiveModule</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_GlobalNaiveSeasonalModule</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">pl_module_params</span><span class="p">)</span></div>


<span class="k">class</span><span class="w"> </span><span class="nc">_GlobalNaiveDrift</span><span class="p">(</span><span class="n">_GlobalNaiveModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">y_target</span> <span class="o">=</span> <span class="n">_extract_targets</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_targets</span><span class="p">)</span>
        <span class="n">slope</span> <span class="o">=</span> <span class="n">_repeat_along_output_chunk</span><span class="p">(</span>
            <span class="p">(</span><span class="n">y_target</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">y_target</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:])</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_chunk_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="n">start</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_shift</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">end</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_shift</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_chunk_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">y_0</span> <span class="o">=</span> <span class="n">y_target</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">y_target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y_0</span>


<div class="viewcode-block" id="GlobalNaiveDrift"><a class="viewcode-back" href="../../../../generated_api/darts.models.forecasting.global_baseline_models.html#darts.models.forecasting.global_baseline_models.GlobalNaiveDrift">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GlobalNaiveDrift</span><span class="p">(</span><span class="n">_NoCovariatesMixin</span><span class="p">,</span> <span class="n">_GlobalNaiveModel</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_chunk_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_chunk_shift</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Global Naive Drift Model.</span>

<span class="sd">        The model generates forecasts for each `series` as described below:</span>

<span class="sd">        - take the slope `m` from each target component between the `input_chunk_length`th and last point before the</span>
<span class="sd">          end of the `series`.</span>
<span class="sd">        - the forecast is `m * x + c` per component where `x` are the values</span>
<span class="sd">          `range(1 + output_chunk_shift, 1 + output_chunk_length + output_chunk_shift)`, and `c` are the last values</span>
<span class="sd">          from each target component.</span>

<span class="sd">        Depending on the horizon `n` used when calling `model.predict()`, the forecasts are either:</span>

<span class="sd">        - a linear drift if `n &lt;= output_chunk_length`, or</span>
<span class="sd">        - a moving drift if `n &gt; output_chunk_length`, as a result of the autoregressive prediction.</span>

<span class="sd">        This model is equivalent to:</span>

<span class="sd">        - :class:`~darts.models.forecasting.baselines.NaiveDrift`, when `input_chunk_length` is equal to the length</span>
<span class="sd">          of  the input target `series` and `output_chunk_length=n`.</span>

<span class="sd">        .. note::</span>
<span class="sd">            - Model checkpointing with `save_checkpoints=True`, and checkpoint loading with `load_from_checkpoint()`</span>
<span class="sd">              and `load_weights_from_checkpoint()` are not supported for global naive models.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_chunk_length</span>
<span class="sd">            The length of the input sequence fed to the model.</span>
<span class="sd">        output_chunk_length</span>
<span class="sd">            The length of the emitted forecast and output sequence fed to the model.</span>
<span class="sd">        output_chunk_shift</span>
<span class="sd">            Optionally, the number of steps to shift the start of the output chunk into the future (relative to the</span>
<span class="sd">            input chunk end). This will create a gap between the input and output. If the model supports</span>
<span class="sd">            `future_covariates`, the future values are extracted from the shifted output chunk. Predictions will start</span>
<span class="sd">            `output_chunk_shift` steps after the end of the target `series`. If `output_chunk_shift` is set, the model</span>
<span class="sd">            cannot generate autoregressive predictions (`n &gt; output_chunk_length`).</span>
<span class="sd">        **kwargs</span>
<span class="sd">            Optional arguments to initialize the pytorch_lightning.Module, pytorch_lightning.Trainer, and</span>
<span class="sd">            Darts&#39; :class:`TorchForecastingModel`.</span>
<span class="sd">            Since naive models are not trained, the following parameters will have no effect:</span>
<span class="sd">            `loss_fn`, `likelihood`, `optimizer_cls`, `optimizer_kwargs`, `lr_scheduler_cls`, `lr_scheduler_kwargs`,</span>
<span class="sd">            `n_epochs`, `save_checkpoints`, and some of `pl_trainer_kwargs`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from darts.datasets import IceCreamHeaterDataset</span>
<span class="sd">        &gt;&gt;&gt; from darts.models import GlobalNaiveDrift</span>
<span class="sd">        &gt;&gt;&gt; # create list of multivariate series</span>
<span class="sd">        &gt;&gt;&gt; series_1 = IceCreamHeaterDataset().load()</span>
<span class="sd">        &gt;&gt;&gt; series_2 = series_1 + 100.</span>
<span class="sd">        &gt;&gt;&gt; series = [series_1, series_2]</span>
<span class="sd">        &gt;&gt;&gt; # predict 3 months, use drift over the last 60 months</span>
<span class="sd">        &gt;&gt;&gt; horizon, icl = 3, 60</span>
<span class="sd">        &gt;&gt;&gt; # linear drift (with `output_chunk_length = horizon`)</span>
<span class="sd">        &gt;&gt;&gt; model = GlobalNaiveDrift(input_chunk_length=icl, output_chunk_length=horizon)</span>
<span class="sd">        &gt;&gt;&gt; # predict after end of each multivariate series</span>
<span class="sd">        &gt;&gt;&gt; pred = model.fit(series).predict(n=horizon, series=series)</span>
<span class="sd">        &gt;&gt;&gt; [p.values() for p in pred]</span>
<span class="sd">        [array([[24.135593, 74.28814 ],</span>
<span class="sd">               [24.271187, 74.57627 ],</span>
<span class="sd">               [24.40678 , 74.86441 ]]), array([[124.13559, 174.28813],</span>
<span class="sd">               [124.27119, 174.57628],</span>
<span class="sd">               [124.40678, 174.86441]])]</span>
<span class="sd">        &gt;&gt;&gt; # moving drift (with `output_chunk_length &lt; horizon`)</span>
<span class="sd">        &gt;&gt;&gt; model = GlobalNaiveDrift(input_chunk_length=icl, output_chunk_length=1)</span>
<span class="sd">        &gt;&gt;&gt; pred = model.fit(series).predict(n=horizon, series=series)</span>
<span class="sd">        &gt;&gt;&gt; [p.values() for p in pred]</span>
<span class="sd">        [array([[24.135593, 74.28814 ],</span>
<span class="sd">               [24.256536, 74.784546],</span>
<span class="sd">               [24.34563 , 75.45886 ]]), array([[124.13559, 174.28813],</span>
<span class="sd">               [124.25653, 174.78455],</span>
<span class="sd">               [124.34563, 175.45886]])]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">input_chunk_length</span><span class="o">=</span><span class="n">input_chunk_length</span><span class="p">,</span>
            <span class="n">output_chunk_length</span><span class="o">=</span><span class="n">output_chunk_length</span><span class="p">,</span>
            <span class="n">output_chunk_shift</span><span class="o">=</span><span class="n">output_chunk_shift</span><span class="p">,</span>
            <span class="n">use_static_covariates</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_sample</span><span class="p">:</span> <span class="n">TorchTrainingSample</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_GlobalNaiveModule</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_GlobalNaiveDrift</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">pl_module_params</span><span class="p">)</span></div>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2020 - 2025, Unit8 SA (Apache 2.0 License).<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.0.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>